{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from dataclasses import dataclass\n",
    "import torch.nn as nn\n",
    "from scipy.special import hermite,factorial\n",
    "from numpy.polynomial import Chebyshev\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ProcessConfig:\n",
    "    \"\"\"configure the data generating process\"\"\"\n",
    "    seq_len: int = 2000\n",
    "    num_seeds: int = 3 \n",
    "    num_sampel_per_task: int = 100\n",
    "\n",
    "class DataGeneratingProcess:\n",
    "    \"\"\"data generating process\"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        self.seq_len = cfg.seq_len\n",
    "        self.num_seeds = cfg.num_seeds\n",
    "        self.num_sampel_per_task = cfg.num_sampel_per_task\n",
    "        \n",
    "\n",
    "    def generate_data(self):\n",
    "        \"\"\"generate data sequences over the specified number of seeds\"\"\"\n",
    "        xseq, yseq, taskseq = [], [], []\n",
    "        tseq = []\n",
    "        for _ in range(self.num_seeds):\n",
    "            dat = self.generate_sequence(np.random.randint(0, 1000))\n",
    "            xseq.append(dat[0])\n",
    "            yseq.append(dat[1])\n",
    "            taskseq.append(dat[2])\n",
    "            tseq.append(dat[2])\n",
    "            # tseq.append(np.arange(self.seq_len))\n",
    "            \n",
    "\n",
    "        xseq = np.array(xseq)\n",
    "        yseq = np.array(yseq)\n",
    "        tseq = np.array(tseq)\n",
    "        taskseq = np.array(taskseq)\n",
    "\n",
    "        self.data = {'x': xseq,\n",
    "                     'y': yseq,\n",
    "                     't': tseq,\n",
    "                     'task': taskseq}\n",
    "\n",
    "    def generate_sequence(self, seed):\n",
    "        \"\"\"generate a sequence of data\"\"\"\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        \n",
    "        mu0 = [i-5 for i in range(1,self.seq_len+1)]\n",
    "        mu1 = [i for i in range(1,self.seq_len+1)]\n",
    "        \n",
    "        X = []\n",
    "        t = []\n",
    "        Y = []\n",
    "        for i in range(self.seq_len):\n",
    "            # generate samples from N[t-1, 1] & N[t, 1]\n",
    "            x1 = np.random.normal(mu0[i],1,self.num_sampel_per_task)\n",
    "            x2 = np.random.normal(mu1[i],1,self.num_sampel_per_task)\n",
    "            # x1 = np.random.uniform(mu0[i],mu0[i]+1,self.num_sampel_per_task)\n",
    "            # x2 = np.random.uniform(mu1[i],mu1[i]+1,self.num_sampel_per_task)\n",
    "            # x1 = np.random.uniform(-1,0,self.num_sampel_per_task)\n",
    "            # x2 = np.random.uniform(0,1,self.num_sampel_per_task)\n",
    "            \n",
    "            X.append([x1,x2])\n",
    "            t.append([i*np.ones(self.num_sampel_per_task),i*np.ones(self.num_sampel_per_task)])\n",
    "            Y.append([np.ones(self.num_sampel_per_task),np.zeros(self.num_sampel_per_task)])\n",
    "        Xdat = np.array(X)\n",
    "        Xdat = Xdat.reshape(-1, 1)\n",
    "        \n",
    "        tind = np.array(t)\n",
    "        tind = tind.reshape(-1)\n",
    "        \n",
    "        Ydat = np.array(Y)\n",
    "        Ydat = Ydat.reshape(-1)\n",
    "        Ydat = Ydat.astype(int)\n",
    "\n",
    "        return Xdat, Ydat, tind\n",
    "    \n",
    "    def generate_at_time(self, t, num_samples):\n",
    "        \"\"\"generate a test sample of data (x, y) ~ p_t from the marginal \n",
    "        of the process at time t. This is used to evaluate the instantaneous\n",
    "        loss of the predictor\n",
    "        \"\"\"\n",
    "        # Generate samples from U[-2, -1] union U[1, 2]\n",
    "        x1 = np.random.normal(t-5,1,num_samples)\n",
    "        x2 = np.random.normal(t,1,num_samples)\n",
    "        # x1 = np.random.uniform(t-2,t-1,num_samples)\n",
    "        # x2 = np.random.uniform(t,t+1,num_samples)\n",
    "        # x1 = np.random.uniform(-1,0,num_samples)\n",
    "        # x2 = np.random.uniform(0,1,num_samples)\n",
    "        \n",
    "        Xdat = np.array([x1,x2]).reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        Ydat = np.array([np.ones(num_samples),np.zeros(num_samples)]).reshape(-1)\n",
    "        tdat = t * np.ones(2*num_samples).reshape(-1)\n",
    "        # Xdat = Xdat-tdat.reshape(-1,1)\n",
    "        # print(Xdat.shape,tdat.shape)\n",
    "        \n",
    "        x = torch.from_numpy(Xdat).float()\n",
    "        y = torch.from_numpy(Ydat).long()\n",
    "        t = torch.from_numpy(tdat).float()\n",
    "        \n",
    "        return x, y, t\n",
    "    \n",
    "class SyntheticDataset(Dataset):\n",
    "    \"\"\"Form the torch dataset\"\"\"\n",
    "    def __init__(self, data, idx, run_id, test):\n",
    "        self.x = torch.from_numpy(data['x']).float()\n",
    "        self.y = torch.from_numpy(data['y']).long()\n",
    "        self.t = torch.from_numpy(data['t']).float()\n",
    "        print(data['x'].shape,data['t'].shape)\n",
    "\n",
    "        if test:\n",
    "            # Use data from time 'idx' onwards for testing\n",
    "            self.x = self.x[run_id, idx:]\n",
    "            self.y = self.y[run_id, idx:]\n",
    "            self.t = self.t[run_id, idx:]\n",
    "        else:\n",
    "            # Use data up to time 'idx' onwards for training\n",
    "            self.x = self.x[run_id, :idx]\n",
    "            self.y = self.y[run_id, :idx]\n",
    "            self.t = self.t[run_id, :idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        t = self.t[idx]\n",
    "        return x, y, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding(nn.Module):\n",
    "    \"\"\"form the time-embedding\"\"\"\n",
    "    def __init__(self, tdim=10):\n",
    "        super(TimeEmbedding, self).__init__()\n",
    "        self.basis = [Chebyshev.basis(i) for i in range(1,tdim+1)]\n",
    "        \n",
    "    def forward(self, t):\n",
    "        emb = []\n",
    "        for i in range(len(self.basis)):\n",
    "            emb.append(torch.tensor(self.basis[i](t/2000),dtype=torch.float32))\n",
    "        return torch.cat(emb, dim=-1)\n",
    "\n",
    "# class TimeEmbedding(nn.Module):\n",
    "#     \"\"\"form the time-embedding\"\"\"\n",
    "#     def __init__(self, tdim=10):\n",
    "#         super(TimeEmbedding, self).__init__()\n",
    "#         self.basis = [hermite(i) for i in range(tdim)]\n",
    "        \n",
    "#     def forward(self, t):\n",
    "#         emb = []\n",
    "#         for i in range(len(self.basis)):\n",
    "#             Hi = self.basis[i](t)\n",
    "#             # norm = 1.0 / np.sqrt((2**i) * factorial(i) * np.sqrt(np.pi))\n",
    "#             # emb.append(torch.tensor(Hi,dtype=torch.float32))\n",
    "#             emb.append(torch.tensor(t,dtype=torch.float32))\n",
    "#         return torch.cat(emb, dim=-1)\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    \"\"\"a simple MLP architecture for implementing both vanilla-MLP and\n",
    "    prospective-MLP\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=1, out_dim=2, hidden_dim=32, tdim=50, prospective=False):\n",
    "        super(MLP, self).__init__()\n",
    "        self.prospective = prospective\n",
    "        if prospective:\n",
    "            self.time_embed = TimeEmbedding(tdim=tdim)\n",
    "            self.fc1 = nn.Linear(in_dim + tdim, hidden_dim)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        if self.prospective:\n",
    "            t = self.time_embed(t.unsqueeze(-1))\n",
    "            x = torch.cat([x, t], dim=-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seed(acorn):\n",
    "    \"\"\"set random seed\"\"\"\n",
    "    random.seed(acorn)\n",
    "    np.random.seed(acorn)\n",
    "    torch.manual_seed(acorn)\n",
    "    torch.cuda.manual_seed(acorn)\n",
    "    torch.cuda.manual_seed_all(acorn)\n",
    "\n",
    "def get_dataloaders(dp, t, seed):\n",
    "    \"\"\"obtain the dataloaders\"\"\"\n",
    "    train_dataset = SyntheticDataset(dp.data, t, seed, test=False)\n",
    "    test_dataset = SyntheticDataset(dp.data, t, seed, test=True)\n",
    "    ttest_dataset = TensorDataset(*dp.generate_at_time(t, 500))\n",
    "    trainloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    testloader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=100,\n",
    "        shuffle=False\n",
    "    )\n",
    "    ttestloader = DataLoader(\n",
    "        ttest_dataset, \n",
    "        batch_size=100,\n",
    "        shuffle=False\n",
    "    )\n",
    "    return trainloader, testloader, ttestloader\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"trainer class for the models\"\"\"\n",
    "    def __init__(self, model, train_loader, test_loader, ttest_loader, criterion, optimizer, device, verbose=False):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.ttest_loader = ttest_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def train_one_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for batch in self.train_loader:\n",
    "            batch = [b.to(self.device) for b in batch]\n",
    "            x, y, t = batch\n",
    "            outputs = self.model(x, t)\n",
    "            # print(outputs.shape,y.shape)\n",
    "\n",
    "            loss = self.criterion(outputs.squeeze(), y)\n",
    "\n",
    "            self.optimizer.zero_grad()  \n",
    "            loss.backward()            \n",
    "            self.optimizer.step() \n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        return total_loss / len(self.train_loader)\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        errs = []\n",
    "        with torch.no_grad():\n",
    "            for batch in self.test_loader:\n",
    "                batch = [b.to(self.device) for b in batch]\n",
    "                x, y, t = batch\n",
    "                logits = self.model(x, t)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                err = (probs.argmax(dim=1) != y).float()\n",
    "                errs.append(err.cpu().numpy())\n",
    "        ploss = np.concatenate(errs).mean()\n",
    "\n",
    "        errs = []\n",
    "        with torch.no_grad():\n",
    "            for batch in self.ttest_loader:\n",
    "                batch = [b.to(self.device) for b in batch]\n",
    "                x, y, t = batch\n",
    "                logits = self.model(x, t)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                err = (probs.argmax(dim=1) != y).float()\n",
    "                errs.append(err.cpu().numpy())\n",
    "        iloss = np.concatenate(errs).mean()\n",
    "        return iloss, ploss\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = self.train_one_epoch()\n",
    "            # if self.verbose:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "                f'Train Loss: {train_loss:.4f}, ')\n",
    "        print(f\"training loss at last epoch: {train_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'x')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = 2000\n",
    "\n",
    "cfg = ProcessConfig(\n",
    "    seq_len=seq_len,\n",
    "    num_seeds=1,\n",
    "    num_sampel_per_task = 20\n",
    ")\n",
    "\n",
    "dp = DataGeneratingProcess(cfg)\n",
    "dp.generate_data()\n",
    "\n",
    "x = dp.data['x']\n",
    "y = dp.data['y']\n",
    "t = dp.data['t']\n",
    "for t_i in np.unique(t):\n",
    "    if t_i in range(20):\n",
    "        x_0 = x[(t == t_i)&(y == 0)]\n",
    "        x_1 = x[(t == t_i)&(y == 1)]\n",
    "        plt.scatter(t_i*np.ones(x_0.shape[0]),x_0,color = 'blue',alpha = 0.1,label = 'class 0')\n",
    "        plt.scatter(t_i*np.ones(x_0.shape[0]),x_1,color = 'red',alpha = 0.1,label = 'class 1')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time t = 50\n",
      "seed = 0\n",
      "2000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 4.3496, \n",
      "Epoch [2/100], Train Loss: 1.1250, \n",
      "Epoch [3/100], Train Loss: 1.0140, \n",
      "Epoch [4/100], Train Loss: 0.8946, \n",
      "Epoch [5/100], Train Loss: 0.7828, \n",
      "Epoch [6/100], Train Loss: 0.7234, \n",
      "Epoch [7/100], Train Loss: 1.7999, \n",
      "Epoch [8/100], Train Loss: 1.6528, \n",
      "Epoch [9/100], Train Loss: 1.5842, \n",
      "Epoch [10/100], Train Loss: 1.3656, \n",
      "Epoch [11/100], Train Loss: 1.2393, \n",
      "Epoch [12/100], Train Loss: 1.1257, \n",
      "Epoch [13/100], Train Loss: 1.0510, \n",
      "Epoch [14/100], Train Loss: 0.9700, \n",
      "Epoch [15/100], Train Loss: 0.9105, \n",
      "Epoch [16/100], Train Loss: 0.8640, \n",
      "Epoch [17/100], Train Loss: 0.8954, \n",
      "Epoch [18/100], Train Loss: 0.8176, \n",
      "Epoch [19/100], Train Loss: 0.8392, \n",
      "Epoch [20/100], Train Loss: 0.7826, \n",
      "Epoch [21/100], Train Loss: 0.7766, \n",
      "Epoch [22/100], Train Loss: 0.7288, \n",
      "Epoch [23/100], Train Loss: 0.7506, \n",
      "Epoch [24/100], Train Loss: 0.7157, \n",
      "Epoch [25/100], Train Loss: 0.7341, \n",
      "Epoch [26/100], Train Loss: 0.7021, \n",
      "Epoch [27/100], Train Loss: 0.7305, \n",
      "Epoch [28/100], Train Loss: 0.8498, \n",
      "Epoch [29/100], Train Loss: 0.7506, \n",
      "Epoch [30/100], Train Loss: 0.7429, \n",
      "Epoch [31/100], Train Loss: 0.6953, \n",
      "Epoch [32/100], Train Loss: 0.7603, \n",
      "Epoch [33/100], Train Loss: 0.7280, \n",
      "Epoch [34/100], Train Loss: 0.7440, \n",
      "Epoch [35/100], Train Loss: 1.3867, \n",
      "Epoch [36/100], Train Loss: 1.2788, \n",
      "Epoch [37/100], Train Loss: 1.1762, \n",
      "Epoch [38/100], Train Loss: 1.0852, \n",
      "Epoch [39/100], Train Loss: 0.9931, \n",
      "Epoch [40/100], Train Loss: 0.9101, \n",
      "Epoch [41/100], Train Loss: 0.8369, \n",
      "Epoch [42/100], Train Loss: 0.7875, \n",
      "Epoch [43/100], Train Loss: 0.7942, \n",
      "Epoch [44/100], Train Loss: 0.7553, \n",
      "Epoch [45/100], Train Loss: 0.7793, \n",
      "Epoch [46/100], Train Loss: 0.7485, \n",
      "Epoch [47/100], Train Loss: 0.7388, \n",
      "Epoch [48/100], Train Loss: 0.7049, \n",
      "Epoch [49/100], Train Loss: 0.7319, \n",
      "Epoch [50/100], Train Loss: 0.6799, \n",
      "Epoch [51/100], Train Loss: 0.7411, \n",
      "Epoch [52/100], Train Loss: 0.7012, \n",
      "Epoch [53/100], Train Loss: 0.6934, \n",
      "Epoch [54/100], Train Loss: 0.6976, \n",
      "Epoch [55/100], Train Loss: 0.6945, \n",
      "Epoch [56/100], Train Loss: 0.6990, \n",
      "Epoch [57/100], Train Loss: 0.6824, \n",
      "Epoch [58/100], Train Loss: 0.7101, \n",
      "Epoch [59/100], Train Loss: 0.7079, \n",
      "Epoch [60/100], Train Loss: 0.6701, \n",
      "Epoch [61/100], Train Loss: 0.7101, \n",
      "Epoch [62/100], Train Loss: 0.6685, \n",
      "Epoch [63/100], Train Loss: 0.6975, \n",
      "Epoch [64/100], Train Loss: 0.6924, \n",
      "Epoch [65/100], Train Loss: 0.6961, \n",
      "Epoch [66/100], Train Loss: 0.6966, \n",
      "Epoch [67/100], Train Loss: 0.7250, \n",
      "Epoch [68/100], Train Loss: 0.6730, \n",
      "Epoch [69/100], Train Loss: 0.7249, \n",
      "Epoch [70/100], Train Loss: 0.6950, \n",
      "Epoch [71/100], Train Loss: 0.6970, \n",
      "Epoch [72/100], Train Loss: 0.7122, \n",
      "Epoch [73/100], Train Loss: 0.7079, \n",
      "Epoch [74/100], Train Loss: 0.6689, \n",
      "Epoch [75/100], Train Loss: 0.7017, \n",
      "Epoch [76/100], Train Loss: 0.6932, \n",
      "Epoch [77/100], Train Loss: 0.7144, \n",
      "Epoch [78/100], Train Loss: 0.7051, \n",
      "Epoch [79/100], Train Loss: 0.6996, \n",
      "Epoch [80/100], Train Loss: 0.6944, \n",
      "Epoch [81/100], Train Loss: 0.7073, \n",
      "Epoch [82/100], Train Loss: 0.7230, \n",
      "Epoch [83/100], Train Loss: 0.6656, \n",
      "Epoch [84/100], Train Loss: 0.7692, \n",
      "Epoch [85/100], Train Loss: 0.7029, \n",
      "Epoch [86/100], Train Loss: 0.7008, \n",
      "Epoch [87/100], Train Loss: 0.7164, \n",
      "Epoch [88/100], Train Loss: 0.6631, \n",
      "Epoch [89/100], Train Loss: 0.7088, \n",
      "Epoch [90/100], Train Loss: 0.7128, \n",
      "Epoch [91/100], Train Loss: 0.6992, \n",
      "Epoch [92/100], Train Loss: 0.7039, \n",
      "Epoch [93/100], Train Loss: 0.6808, \n",
      "Epoch [94/100], Train Loss: 0.6896, \n",
      "Epoch [95/100], Train Loss: 0.6909, \n",
      "Epoch [96/100], Train Loss: 0.7400, \n",
      "Epoch [97/100], Train Loss: 0.7089, \n",
      "Epoch [98/100], Train Loss: 0.6682, \n",
      "Epoch [99/100], Train Loss: 0.6818, \n",
      "Epoch [100/100], Train Loss: 0.7217, \n",
      "training loss at last epoch: 0.722\n",
      "Epoch [1/100], Train Loss: 0.7345, \n",
      "Epoch [2/100], Train Loss: 0.6629, \n",
      "Epoch [3/100], Train Loss: 0.6661, \n",
      "Epoch [4/100], Train Loss: 0.6672, \n",
      "Epoch [5/100], Train Loss: 0.6628, \n",
      "Epoch [6/100], Train Loss: 0.6611, \n",
      "Epoch [7/100], Train Loss: 0.6668, \n",
      "Epoch [8/100], Train Loss: 0.6657, \n",
      "Epoch [9/100], Train Loss: 0.6679, \n",
      "Epoch [10/100], Train Loss: 0.6633, \n",
      "Epoch [11/100], Train Loss: 0.6642, \n",
      "Epoch [12/100], Train Loss: 0.6645, \n",
      "Epoch [13/100], Train Loss: 0.6624, \n",
      "Epoch [14/100], Train Loss: 0.6676, \n",
      "Epoch [15/100], Train Loss: 0.6667, \n",
      "Epoch [16/100], Train Loss: 0.6644, \n",
      "Epoch [17/100], Train Loss: 0.6656, \n",
      "Epoch [18/100], Train Loss: 0.6616, \n",
      "Epoch [19/100], Train Loss: 0.6630, \n",
      "Epoch [20/100], Train Loss: 0.6649, \n",
      "Epoch [21/100], Train Loss: 0.6650, \n",
      "Epoch [22/100], Train Loss: 0.6648, \n",
      "Epoch [23/100], Train Loss: 0.6638, \n",
      "Epoch [24/100], Train Loss: 0.6664, \n",
      "Epoch [25/100], Train Loss: 0.6613, \n",
      "Epoch [26/100], Train Loss: 0.6635, \n",
      "Epoch [27/100], Train Loss: 0.6630, \n",
      "Epoch [28/100], Train Loss: 0.6726, \n",
      "Epoch [29/100], Train Loss: 0.6644, \n",
      "Epoch [30/100], Train Loss: 0.6636, \n",
      "Epoch [31/100], Train Loss: 0.6650, \n",
      "Epoch [32/100], Train Loss: 0.6644, \n",
      "Epoch [33/100], Train Loss: 0.6643, \n",
      "Epoch [34/100], Train Loss: 0.6633, \n",
      "Epoch [35/100], Train Loss: 0.6605, \n",
      "Epoch [36/100], Train Loss: 0.6637, \n",
      "Epoch [37/100], Train Loss: 0.6636, \n",
      "Epoch [38/100], Train Loss: 0.6633, \n",
      "Epoch [39/100], Train Loss: 0.6647, \n",
      "Epoch [40/100], Train Loss: 0.6687, \n",
      "Epoch [41/100], Train Loss: 0.6647, \n",
      "Epoch [42/100], Train Loss: 0.6667, \n",
      "Epoch [43/100], Train Loss: 0.6640, \n",
      "Epoch [44/100], Train Loss: 0.6635, \n",
      "Epoch [45/100], Train Loss: 0.6619, \n",
      "Epoch [46/100], Train Loss: 0.6626, \n",
      "Epoch [47/100], Train Loss: 0.6636, \n",
      "Epoch [48/100], Train Loss: 0.6661, \n",
      "Epoch [49/100], Train Loss: 0.6643, \n",
      "Epoch [50/100], Train Loss: 0.6632, \n",
      "Epoch [51/100], Train Loss: 0.6640, \n",
      "Epoch [52/100], Train Loss: 0.6629, \n",
      "Epoch [53/100], Train Loss: 0.6623, \n",
      "Epoch [54/100], Train Loss: 0.6600, \n",
      "Epoch [55/100], Train Loss: 0.6658, \n",
      "Epoch [56/100], Train Loss: 0.6628, \n",
      "Epoch [57/100], Train Loss: 0.6625, \n",
      "Epoch [58/100], Train Loss: 0.6606, \n",
      "Epoch [59/100], Train Loss: 0.6635, \n",
      "Epoch [60/100], Train Loss: 0.6611, \n",
      "Epoch [61/100], Train Loss: 0.6648, \n",
      "Epoch [62/100], Train Loss: 0.6635, \n",
      "Epoch [63/100], Train Loss: 0.6661, \n",
      "Epoch [64/100], Train Loss: 0.6622, \n",
      "Epoch [65/100], Train Loss: 0.6614, \n",
      "Epoch [66/100], Train Loss: 0.6615, \n",
      "Epoch [67/100], Train Loss: 0.6612, \n",
      "Epoch [68/100], Train Loss: 0.6587, \n",
      "Epoch [69/100], Train Loss: 0.6640, \n",
      "Epoch [70/100], Train Loss: 0.6566, \n",
      "Epoch [71/100], Train Loss: 0.6592, \n",
      "Epoch [72/100], Train Loss: 0.7202, \n",
      "Epoch [73/100], Train Loss: 0.6687, \n",
      "Epoch [74/100], Train Loss: 0.6677, \n",
      "Epoch [75/100], Train Loss: 0.6651, \n",
      "Epoch [76/100], Train Loss: 0.6652, \n",
      "Epoch [77/100], Train Loss: 0.6651, \n",
      "Epoch [78/100], Train Loss: 0.6637, \n",
      "Epoch [79/100], Train Loss: 0.6645, \n",
      "Epoch [80/100], Train Loss: 0.6659, \n",
      "Epoch [81/100], Train Loss: 0.6641, \n",
      "Epoch [82/100], Train Loss: 0.6655, \n",
      "Epoch [83/100], Train Loss: 0.6661, \n",
      "Epoch [84/100], Train Loss: 0.6678, \n",
      "Epoch [85/100], Train Loss: 0.6643, \n",
      "Epoch [86/100], Train Loss: 0.6650, \n",
      "Epoch [87/100], Train Loss: 0.6643, \n",
      "Epoch [88/100], Train Loss: 0.6661, \n",
      "Epoch [89/100], Train Loss: 0.6641, \n",
      "Epoch [90/100], Train Loss: 0.6628, \n",
      "Epoch [91/100], Train Loss: 0.6631, \n",
      "Epoch [92/100], Train Loss: 0.6630, \n",
      "Epoch [93/100], Train Loss: 0.6627, \n",
      "Epoch [94/100], Train Loss: 0.6655, \n",
      "Epoch [95/100], Train Loss: 0.6639, \n",
      "Epoch [96/100], Train Loss: 0.6624, \n",
      "Epoch [97/100], Train Loss: 0.6587, \n",
      "Epoch [98/100], Train Loss: 0.6750, \n",
      "Epoch [99/100], Train Loss: 0.6623, \n",
      "Epoch [100/100], Train Loss: 0.6625, \n",
      "training loss at last epoch: 0.662\n",
      "seed = 1\n",
      "2000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 3.8325, \n",
      "Epoch [2/100], Train Loss: 0.7980, \n",
      "Epoch [3/100], Train Loss: 0.7623, \n",
      "Epoch [4/100], Train Loss: 0.7322, \n",
      "Epoch [5/100], Train Loss: 0.7038, \n",
      "Epoch [6/100], Train Loss: 0.6987, \n",
      "Epoch [7/100], Train Loss: 0.6892, \n",
      "Epoch [8/100], Train Loss: 0.6791, \n",
      "Epoch [9/100], Train Loss: 0.6825, \n",
      "Epoch [10/100], Train Loss: 0.7196, \n",
      "Epoch [11/100], Train Loss: 0.6829, \n",
      "Epoch [12/100], Train Loss: 0.7051, \n",
      "Epoch [13/100], Train Loss: 0.6825, \n",
      "Epoch [14/100], Train Loss: 0.6881, \n",
      "Epoch [15/100], Train Loss: 0.6615, \n",
      "Epoch [16/100], Train Loss: 0.6910, \n",
      "Epoch [17/100], Train Loss: 0.6721, \n",
      "Epoch [18/100], Train Loss: 0.7117, \n",
      "Epoch [19/100], Train Loss: 0.6789, \n",
      "Epoch [20/100], Train Loss: 0.6849, \n",
      "Epoch [21/100], Train Loss: 0.7110, \n",
      "Epoch [22/100], Train Loss: 0.6796, \n",
      "Epoch [23/100], Train Loss: 0.8147, \n",
      "Epoch [24/100], Train Loss: 0.7761, \n",
      "Epoch [25/100], Train Loss: 0.7414, \n",
      "Epoch [26/100], Train Loss: 0.7110, \n",
      "Epoch [27/100], Train Loss: 0.6915, \n",
      "Epoch [28/100], Train Loss: 0.6845, \n",
      "Epoch [29/100], Train Loss: 0.8254, \n",
      "Epoch [30/100], Train Loss: 0.7884, \n",
      "Epoch [31/100], Train Loss: 0.7537, \n",
      "Epoch [32/100], Train Loss: 0.7251, \n",
      "Epoch [33/100], Train Loss: 0.6993, \n",
      "Epoch [34/100], Train Loss: 0.6895, \n",
      "Epoch [35/100], Train Loss: 0.6765, \n",
      "Epoch [36/100], Train Loss: 0.8466, \n",
      "Epoch [37/100], Train Loss: 0.8104, \n",
      "Epoch [38/100], Train Loss: 0.7773, \n",
      "Epoch [39/100], Train Loss: 0.7457, \n",
      "Epoch [40/100], Train Loss: 0.7153, \n",
      "Epoch [41/100], Train Loss: 0.7052, \n",
      "Epoch [42/100], Train Loss: 0.6825, \n",
      "Epoch [43/100], Train Loss: 0.6950, \n",
      "Epoch [44/100], Train Loss: 0.6727, \n",
      "Epoch [45/100], Train Loss: 0.6819, \n",
      "Epoch [46/100], Train Loss: 0.6863, \n",
      "Epoch [47/100], Train Loss: 0.6727, \n",
      "Epoch [48/100], Train Loss: 0.6942, \n",
      "Epoch [49/100], Train Loss: 0.6762, \n",
      "Epoch [50/100], Train Loss: 0.7175, \n",
      "Epoch [51/100], Train Loss: 0.6894, \n",
      "Epoch [52/100], Train Loss: 0.7046, \n",
      "Epoch [53/100], Train Loss: 1.2396, \n",
      "Epoch [54/100], Train Loss: 1.1816, \n",
      "Epoch [55/100], Train Loss: 1.1271, \n",
      "Epoch [56/100], Train Loss: 1.0730, \n",
      "Epoch [57/100], Train Loss: 1.0327, \n",
      "Epoch [58/100], Train Loss: 0.9856, \n",
      "Epoch [59/100], Train Loss: 0.9527, \n",
      "Epoch [60/100], Train Loss: 0.9158, \n",
      "Epoch [61/100], Train Loss: 0.8860, \n",
      "Epoch [62/100], Train Loss: 0.8595, \n",
      "Epoch [63/100], Train Loss: 0.8358, \n",
      "Epoch [64/100], Train Loss: 0.8135, \n",
      "Epoch [65/100], Train Loss: 0.7940, \n",
      "Epoch [66/100], Train Loss: 0.7707, \n",
      "Epoch [67/100], Train Loss: 0.7528, \n",
      "Epoch [68/100], Train Loss: 0.7338, \n",
      "Epoch [69/100], Train Loss: 0.7222, \n",
      "Epoch [70/100], Train Loss: 0.7174, \n",
      "Epoch [71/100], Train Loss: 0.7054, \n",
      "Epoch [72/100], Train Loss: 0.6998, \n",
      "Epoch [73/100], Train Loss: 0.6899, \n",
      "Epoch [74/100], Train Loss: 0.6878, \n",
      "Epoch [75/100], Train Loss: 0.6830, \n",
      "Epoch [76/100], Train Loss: 0.6795, \n",
      "Epoch [77/100], Train Loss: 0.6806, \n",
      "Epoch [78/100], Train Loss: 0.6729, \n",
      "Epoch [79/100], Train Loss: 0.6726, \n",
      "Epoch [80/100], Train Loss: 0.6699, \n",
      "Epoch [81/100], Train Loss: 0.6688, \n",
      "Epoch [82/100], Train Loss: 0.6679, \n",
      "Epoch [83/100], Train Loss: 0.6659, \n",
      "Epoch [84/100], Train Loss: 0.6655, \n",
      "Epoch [85/100], Train Loss: 0.6650, \n",
      "Epoch [86/100], Train Loss: 0.6636, \n",
      "Epoch [87/100], Train Loss: 0.6650, \n",
      "Epoch [88/100], Train Loss: 0.6648, \n",
      "Epoch [89/100], Train Loss: 0.6639, \n",
      "Epoch [90/100], Train Loss: 0.6643, \n",
      "Epoch [91/100], Train Loss: 0.6646, \n",
      "Epoch [92/100], Train Loss: 0.6653, \n",
      "Epoch [93/100], Train Loss: 0.6665, \n",
      "Epoch [94/100], Train Loss: 0.6635, \n",
      "Epoch [95/100], Train Loss: 0.6635, \n",
      "Epoch [96/100], Train Loss: 0.6637, \n",
      "Epoch [97/100], Train Loss: 0.6600, \n",
      "Epoch [98/100], Train Loss: 0.6638, \n",
      "Epoch [99/100], Train Loss: 0.6635, \n",
      "Epoch [100/100], Train Loss: 0.6651, \n",
      "training loss at last epoch: 0.665\n",
      "Epoch [1/100], Train Loss: 0.7814, \n",
      "Epoch [2/100], Train Loss: 0.6653, \n",
      "Epoch [3/100], Train Loss: 0.6630, \n",
      "Epoch [4/100], Train Loss: 0.6671, \n",
      "Epoch [5/100], Train Loss: 0.6654, \n",
      "Epoch [6/100], Train Loss: 0.6679, \n",
      "Epoch [7/100], Train Loss: 0.6631, \n",
      "Epoch [8/100], Train Loss: 0.6633, \n",
      "Epoch [9/100], Train Loss: 0.6667, \n",
      "Epoch [10/100], Train Loss: 0.6662, \n",
      "Epoch [11/100], Train Loss: 0.6629, \n",
      "Epoch [12/100], Train Loss: 0.6651, \n",
      "Epoch [13/100], Train Loss: 0.6624, \n",
      "Epoch [14/100], Train Loss: 0.6646, \n",
      "Epoch [15/100], Train Loss: 0.6667, \n",
      "Epoch [16/100], Train Loss: 0.6648, \n",
      "Epoch [17/100], Train Loss: 0.6644, \n",
      "Epoch [18/100], Train Loss: 0.6606, \n",
      "Epoch [19/100], Train Loss: 0.6625, \n",
      "Epoch [20/100], Train Loss: 0.6625, \n",
      "Epoch [21/100], Train Loss: 0.6653, \n",
      "Epoch [22/100], Train Loss: 0.6623, \n",
      "Epoch [23/100], Train Loss: 0.6609, \n",
      "Epoch [24/100], Train Loss: 0.6781, \n",
      "Epoch [25/100], Train Loss: 0.6696, \n",
      "Epoch [26/100], Train Loss: 0.6656, \n",
      "Epoch [27/100], Train Loss: 0.6647, \n",
      "Epoch [28/100], Train Loss: 0.6643, \n",
      "Epoch [29/100], Train Loss: 0.6655, \n",
      "Epoch [30/100], Train Loss: 0.6638, \n",
      "Epoch [31/100], Train Loss: 0.6722, \n",
      "Epoch [32/100], Train Loss: 0.6654, \n",
      "Epoch [33/100], Train Loss: 0.6699, \n",
      "Epoch [34/100], Train Loss: 0.6626, \n",
      "Epoch [35/100], Train Loss: 0.6629, \n",
      "Epoch [36/100], Train Loss: 0.6612, \n",
      "Epoch [37/100], Train Loss: 0.6658, \n",
      "Epoch [38/100], Train Loss: 0.6594, \n",
      "Epoch [39/100], Train Loss: 0.6670, \n",
      "Epoch [40/100], Train Loss: 0.6656, \n",
      "Epoch [41/100], Train Loss: 0.6628, \n",
      "Epoch [42/100], Train Loss: 0.6650, \n",
      "Epoch [43/100], Train Loss: 0.6669, \n",
      "Epoch [44/100], Train Loss: 0.6652, \n",
      "Epoch [45/100], Train Loss: 0.6630, \n",
      "Epoch [46/100], Train Loss: 0.6663, \n",
      "Epoch [47/100], Train Loss: 0.6648, \n",
      "Epoch [48/100], Train Loss: 0.6635, \n",
      "Epoch [49/100], Train Loss: 0.6643, \n",
      "Epoch [50/100], Train Loss: 0.6659, \n",
      "Epoch [51/100], Train Loss: 0.6635, \n",
      "Epoch [52/100], Train Loss: 0.6631, \n",
      "Epoch [53/100], Train Loss: 0.6625, \n",
      "Epoch [54/100], Train Loss: 0.6629, \n",
      "Epoch [55/100], Train Loss: 0.6621, \n",
      "Epoch [56/100], Train Loss: 0.6641, \n",
      "Epoch [57/100], Train Loss: 0.6638, \n",
      "Epoch [58/100], Train Loss: 0.6639, \n",
      "Epoch [59/100], Train Loss: 0.6653, \n",
      "Epoch [60/100], Train Loss: 0.6681, \n",
      "Epoch [61/100], Train Loss: 0.6654, \n",
      "Epoch [62/100], Train Loss: 0.6648, \n",
      "Epoch [63/100], Train Loss: 0.6671, \n",
      "Epoch [64/100], Train Loss: 0.6628, \n",
      "Epoch [65/100], Train Loss: 0.6630, \n",
      "Epoch [66/100], Train Loss: 0.6664, \n",
      "Epoch [67/100], Train Loss: 0.6627, \n",
      "Epoch [68/100], Train Loss: 0.6623, \n",
      "Epoch [69/100], Train Loss: 0.6645, \n",
      "Epoch [70/100], Train Loss: 0.6633, \n",
      "Epoch [71/100], Train Loss: 0.6617, \n",
      "Epoch [72/100], Train Loss: 0.6638, \n",
      "Epoch [73/100], Train Loss: 0.6626, \n",
      "Epoch [74/100], Train Loss: 0.6613, \n",
      "Epoch [75/100], Train Loss: 0.6617, \n",
      "Epoch [76/100], Train Loss: 0.6608, \n",
      "Epoch [77/100], Train Loss: 0.6631, \n",
      "Epoch [78/100], Train Loss: 0.6609, \n",
      "Epoch [79/100], Train Loss: 0.6596, \n",
      "Epoch [80/100], Train Loss: 0.6596, \n",
      "Epoch [81/100], Train Loss: 0.6622, \n",
      "Epoch [82/100], Train Loss: 0.6619, \n",
      "Epoch [83/100], Train Loss: 0.6631, \n",
      "Epoch [84/100], Train Loss: 0.6632, \n",
      "Epoch [85/100], Train Loss: 0.6590, \n",
      "Epoch [86/100], Train Loss: 0.6626, \n",
      "Epoch [87/100], Train Loss: 0.6623, \n",
      "Epoch [88/100], Train Loss: 0.6641, \n",
      "Epoch [89/100], Train Loss: 0.6628, \n",
      "Epoch [90/100], Train Loss: 0.6607, \n",
      "Epoch [91/100], Train Loss: 0.6618, \n",
      "Epoch [92/100], Train Loss: 0.6605, \n",
      "Epoch [93/100], Train Loss: 0.6599, \n",
      "Epoch [94/100], Train Loss: 0.7415, \n",
      "Epoch [95/100], Train Loss: 0.7064, \n",
      "Epoch [96/100], Train Loss: 0.6659, \n",
      "Epoch [97/100], Train Loss: 0.6666, \n",
      "Epoch [98/100], Train Loss: 0.6689, \n",
      "Epoch [99/100], Train Loss: 0.6685, \n",
      "Epoch [100/100], Train Loss: 0.6646, \n",
      "training loss at last epoch: 0.665\n",
      "seed = 2\n",
      "2000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 5.2788, \n",
      "Epoch [2/100], Train Loss: 1.0151, \n",
      "Epoch [3/100], Train Loss: 1.0783, \n",
      "Epoch [4/100], Train Loss: 0.9531, \n",
      "Epoch [5/100], Train Loss: 0.8644, \n",
      "Epoch [6/100], Train Loss: 0.7944, \n",
      "Epoch [7/100], Train Loss: 0.7360, \n",
      "Epoch [8/100], Train Loss: 0.7103, \n",
      "Epoch [9/100], Train Loss: 0.6905, \n",
      "Epoch [10/100], Train Loss: 0.6791, \n",
      "Epoch [11/100], Train Loss: 0.6736, \n",
      "Epoch [12/100], Train Loss: 0.6750, \n",
      "Epoch [13/100], Train Loss: 0.6674, \n",
      "Epoch [14/100], Train Loss: 0.6701, \n",
      "Epoch [15/100], Train Loss: 0.6684, \n",
      "Epoch [16/100], Train Loss: 0.6664, \n",
      "Epoch [17/100], Train Loss: 0.6650, \n",
      "Epoch [18/100], Train Loss: 0.6643, \n",
      "Epoch [19/100], Train Loss: 0.6611, \n",
      "Epoch [20/100], Train Loss: 0.6669, \n",
      "Epoch [21/100], Train Loss: 0.6655, \n",
      "Epoch [22/100], Train Loss: 0.6639, \n",
      "Epoch [23/100], Train Loss: 0.6648, \n",
      "Epoch [24/100], Train Loss: 0.6648, \n",
      "Epoch [25/100], Train Loss: 0.6652, \n",
      "Epoch [26/100], Train Loss: 0.6655, \n",
      "Epoch [27/100], Train Loss: 0.6634, \n",
      "Epoch [28/100], Train Loss: 0.6659, \n",
      "Epoch [29/100], Train Loss: 0.6623, \n",
      "Epoch [30/100], Train Loss: 0.6639, \n",
      "Epoch [31/100], Train Loss: 0.6658, \n",
      "Epoch [32/100], Train Loss: 0.6652, \n",
      "Epoch [33/100], Train Loss: 0.6651, \n",
      "Epoch [34/100], Train Loss: 0.6656, \n",
      "Epoch [35/100], Train Loss: 0.6653, \n",
      "Epoch [36/100], Train Loss: 0.6659, \n",
      "Epoch [37/100], Train Loss: 0.6649, \n",
      "Epoch [38/100], Train Loss: 0.6636, \n",
      "Epoch [39/100], Train Loss: 0.6653, \n",
      "Epoch [40/100], Train Loss: 0.6645, \n",
      "Epoch [41/100], Train Loss: 0.6644, \n",
      "Epoch [42/100], Train Loss: 0.6667, \n",
      "Epoch [43/100], Train Loss: 0.6628, \n",
      "Epoch [44/100], Train Loss: 0.6659, \n",
      "Epoch [45/100], Train Loss: 0.6640, \n",
      "Epoch [46/100], Train Loss: 0.6642, \n",
      "Epoch [47/100], Train Loss: 0.6678, \n",
      "Epoch [48/100], Train Loss: 0.6632, \n",
      "Epoch [49/100], Train Loss: 0.6640, \n",
      "Epoch [50/100], Train Loss: 0.6628, \n",
      "Epoch [51/100], Train Loss: 0.6639, \n",
      "Epoch [52/100], Train Loss: 0.6647, \n",
      "Epoch [53/100], Train Loss: 0.6633, \n",
      "Epoch [54/100], Train Loss: 0.6644, \n",
      "Epoch [55/100], Train Loss: 0.6640, \n",
      "Epoch [56/100], Train Loss: 0.6607, \n",
      "Epoch [57/100], Train Loss: 0.6681, \n",
      "Epoch [58/100], Train Loss: 0.6633, \n",
      "Epoch [59/100], Train Loss: 0.6643, \n",
      "Epoch [60/100], Train Loss: 0.6632, \n",
      "Epoch [61/100], Train Loss: 0.6654, \n",
      "Epoch [62/100], Train Loss: 0.6643, \n",
      "Epoch [63/100], Train Loss: 0.6634, \n",
      "Epoch [64/100], Train Loss: 0.6631, \n",
      "Epoch [65/100], Train Loss: 0.6643, \n",
      "Epoch [66/100], Train Loss: 0.6658, \n",
      "Epoch [67/100], Train Loss: 0.6639, \n",
      "Epoch [68/100], Train Loss: 0.6645, \n",
      "Epoch [69/100], Train Loss: 0.6652, \n",
      "Epoch [70/100], Train Loss: 0.6647, \n",
      "Epoch [71/100], Train Loss: 0.6628, \n",
      "Epoch [72/100], Train Loss: 0.6655, \n",
      "Epoch [73/100], Train Loss: 0.6609, \n",
      "Epoch [74/100], Train Loss: 0.6657, \n",
      "Epoch [75/100], Train Loss: 0.6637, \n",
      "Epoch [76/100], Train Loss: 0.6649, \n",
      "Epoch [77/100], Train Loss: 0.6643, \n",
      "Epoch [78/100], Train Loss: 0.6638, \n",
      "Epoch [79/100], Train Loss: 0.6662, \n",
      "Epoch [80/100], Train Loss: 0.6635, \n",
      "Epoch [81/100], Train Loss: 0.6631, \n",
      "Epoch [82/100], Train Loss: 0.6623, \n",
      "Epoch [83/100], Train Loss: 0.6632, \n",
      "Epoch [84/100], Train Loss: 0.6666, \n",
      "Epoch [85/100], Train Loss: 0.6642, \n",
      "Epoch [86/100], Train Loss: 0.6646, \n",
      "Epoch [87/100], Train Loss: 0.6654, \n",
      "Epoch [88/100], Train Loss: 0.6667, \n",
      "Epoch [89/100], Train Loss: 0.6647, \n",
      "Epoch [90/100], Train Loss: 0.6642, \n",
      "Epoch [91/100], Train Loss: 0.6655, \n",
      "Epoch [92/100], Train Loss: 0.6645, \n",
      "Epoch [93/100], Train Loss: 0.6656, \n",
      "Epoch [94/100], Train Loss: 0.6640, \n",
      "Epoch [95/100], Train Loss: 0.6648, \n",
      "Epoch [96/100], Train Loss: 0.6656, \n",
      "Epoch [97/100], Train Loss: 0.6662, \n",
      "Epoch [98/100], Train Loss: 0.6644, \n",
      "Epoch [99/100], Train Loss: 0.6642, \n",
      "Epoch [100/100], Train Loss: 0.6640, \n",
      "training loss at last epoch: 0.664\n",
      "Epoch [1/100], Train Loss: 0.7189, \n",
      "Epoch [2/100], Train Loss: 0.6716, \n",
      "Epoch [3/100], Train Loss: 0.6653, \n",
      "Epoch [4/100], Train Loss: 0.6666, \n",
      "Epoch [5/100], Train Loss: 0.6666, \n",
      "Epoch [6/100], Train Loss: 0.6641, \n",
      "Epoch [7/100], Train Loss: 0.6636, \n",
      "Epoch [8/100], Train Loss: 0.6650, \n",
      "Epoch [9/100], Train Loss: 0.6664, \n",
      "Epoch [10/100], Train Loss: 0.6676, \n",
      "Epoch [11/100], Train Loss: 0.6790, \n",
      "Epoch [12/100], Train Loss: 0.6639, \n",
      "Epoch [13/100], Train Loss: 0.6701, \n",
      "Epoch [14/100], Train Loss: 0.6642, \n",
      "Epoch [15/100], Train Loss: 0.6654, \n",
      "Epoch [16/100], Train Loss: 0.6650, \n",
      "Epoch [17/100], Train Loss: 0.6636, \n",
      "Epoch [18/100], Train Loss: 0.6624, \n",
      "Epoch [19/100], Train Loss: 0.6619, \n",
      "Epoch [20/100], Train Loss: 0.6641, \n",
      "Epoch [21/100], Train Loss: 0.6674, \n",
      "Epoch [22/100], Train Loss: 0.6664, \n",
      "Epoch [23/100], Train Loss: 0.6659, \n",
      "Epoch [24/100], Train Loss: 0.6663, \n",
      "Epoch [25/100], Train Loss: 0.6651, \n",
      "Epoch [26/100], Train Loss: 0.6642, \n",
      "Epoch [27/100], Train Loss: 0.6641, \n",
      "Epoch [28/100], Train Loss: 0.6632, \n",
      "Epoch [29/100], Train Loss: 0.6629, \n",
      "Epoch [30/100], Train Loss: 0.6652, \n",
      "Epoch [31/100], Train Loss: 0.6653, \n",
      "Epoch [32/100], Train Loss: 0.6638, \n",
      "Epoch [33/100], Train Loss: 0.6655, \n",
      "Epoch [34/100], Train Loss: 0.6642, \n",
      "Epoch [35/100], Train Loss: 0.6634, \n",
      "Epoch [36/100], Train Loss: 0.6635, \n",
      "Epoch [37/100], Train Loss: 0.6612, \n",
      "Epoch [38/100], Train Loss: 0.7199, \n",
      "Epoch [39/100], Train Loss: 0.6686, \n",
      "Epoch [40/100], Train Loss: 0.6664, \n",
      "Epoch [41/100], Train Loss: 0.6658, \n",
      "Epoch [42/100], Train Loss: 0.6676, \n",
      "Epoch [43/100], Train Loss: 0.6654, \n",
      "Epoch [44/100], Train Loss: 0.6704, \n",
      "Epoch [45/100], Train Loss: 0.6633, \n",
      "Epoch [46/100], Train Loss: 0.6639, \n",
      "Epoch [47/100], Train Loss: 0.6651, \n",
      "Epoch [48/100], Train Loss: 0.6666, \n",
      "Epoch [49/100], Train Loss: 0.6650, \n",
      "Epoch [50/100], Train Loss: 0.6641, \n",
      "Epoch [51/100], Train Loss: 0.6645, \n",
      "Epoch [52/100], Train Loss: 0.6632, \n",
      "Epoch [53/100], Train Loss: 0.6615, \n",
      "Epoch [54/100], Train Loss: 0.6654, \n",
      "Epoch [55/100], Train Loss: 0.6645, \n",
      "Epoch [56/100], Train Loss: 0.6628, \n",
      "Epoch [57/100], Train Loss: 0.6665, \n",
      "Epoch [58/100], Train Loss: 0.6668, \n",
      "Epoch [59/100], Train Loss: 0.6670, \n",
      "Epoch [60/100], Train Loss: 0.6664, \n",
      "Epoch [61/100], Train Loss: 0.6666, \n",
      "Epoch [62/100], Train Loss: 0.6657, \n",
      "Epoch [63/100], Train Loss: 0.6627, \n",
      "Epoch [64/100], Train Loss: 0.6627, \n",
      "Epoch [65/100], Train Loss: 0.6661, \n",
      "Epoch [66/100], Train Loss: 0.6696, \n",
      "Epoch [67/100], Train Loss: 0.6670, \n",
      "Epoch [68/100], Train Loss: 0.6659, \n",
      "Epoch [69/100], Train Loss: 0.6633, \n",
      "Epoch [70/100], Train Loss: 0.6636, \n",
      "Epoch [71/100], Train Loss: 0.6681, \n",
      "Epoch [72/100], Train Loss: 0.6664, \n",
      "Epoch [73/100], Train Loss: 0.6656, \n",
      "Epoch [74/100], Train Loss: 0.6684, \n",
      "Epoch [75/100], Train Loss: 0.6664, \n",
      "Epoch [76/100], Train Loss: 0.6636, \n",
      "Epoch [77/100], Train Loss: 0.6638, \n",
      "Epoch [78/100], Train Loss: 0.6654, \n",
      "Epoch [79/100], Train Loss: 0.6640, \n",
      "Epoch [80/100], Train Loss: 0.6637, \n",
      "Epoch [81/100], Train Loss: 0.6645, \n",
      "Epoch [82/100], Train Loss: 0.6616, \n",
      "Epoch [83/100], Train Loss: 0.6632, \n",
      "Epoch [84/100], Train Loss: 0.6619, \n",
      "Epoch [85/100], Train Loss: 0.6625, \n",
      "Epoch [86/100], Train Loss: 0.6639, \n",
      "Epoch [87/100], Train Loss: 0.6602, \n",
      "Epoch [88/100], Train Loss: 0.6979, \n",
      "Epoch [89/100], Train Loss: 0.6671, \n",
      "Epoch [90/100], Train Loss: 0.6654, \n",
      "Epoch [91/100], Train Loss: 0.6665, \n",
      "Epoch [92/100], Train Loss: 0.6663, \n",
      "Epoch [93/100], Train Loss: 0.6653, \n",
      "Epoch [94/100], Train Loss: 0.6676, \n",
      "Epoch [95/100], Train Loss: 0.6650, \n",
      "Epoch [96/100], Train Loss: 0.6657, \n",
      "Epoch [97/100], Train Loss: 0.6657, \n",
      "Epoch [98/100], Train Loss: 0.6657, \n",
      "Epoch [99/100], Train Loss: 0.6656, \n",
      "Epoch [100/100], Train Loss: 0.6670, \n",
      "training loss at last epoch: 0.667\n",
      "time t = 100\n",
      "seed = 0\n",
      "4000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 16.9098, \n",
      "Epoch [2/100], Train Loss: 3.5926, \n",
      "Epoch [3/100], Train Loss: 2.8752, \n",
      "Epoch [4/100], Train Loss: 2.1938, \n",
      "Epoch [5/100], Train Loss: 1.5680, \n",
      "Epoch [6/100], Train Loss: 1.0661, \n",
      "Epoch [7/100], Train Loss: 2.9197, \n",
      "Epoch [8/100], Train Loss: 1.8350, \n",
      "Epoch [9/100], Train Loss: 1.7308, \n",
      "Epoch [10/100], Train Loss: 2.4863, \n",
      "Epoch [11/100], Train Loss: 1.5321, \n",
      "Epoch [12/100], Train Loss: 2.8731, \n",
      "Epoch [13/100], Train Loss: 1.7477, \n",
      "Epoch [14/100], Train Loss: 2.2873, \n",
      "Epoch [15/100], Train Loss: 1.4588, \n",
      "Epoch [16/100], Train Loss: 6.8894, \n",
      "Epoch [17/100], Train Loss: 5.6795, \n",
      "Epoch [18/100], Train Loss: 4.5566, \n",
      "Epoch [19/100], Train Loss: 3.4858, \n",
      "Epoch [20/100], Train Loss: 2.4749, \n",
      "Epoch [21/100], Train Loss: 2.0220, \n",
      "Epoch [22/100], Train Loss: 1.7963, \n",
      "Epoch [23/100], Train Loss: 1.5456, \n",
      "Epoch [24/100], Train Loss: 1.5316, \n",
      "Epoch [25/100], Train Loss: 4.4588, \n",
      "Epoch [26/100], Train Loss: 3.4708, \n",
      "Epoch [27/100], Train Loss: 2.5144, \n",
      "Epoch [28/100], Train Loss: 1.9656, \n",
      "Epoch [29/100], Train Loss: 1.4344, \n",
      "Epoch [30/100], Train Loss: 1.6515, \n",
      "Epoch [31/100], Train Loss: 1.5831, \n",
      "Epoch [32/100], Train Loss: 1.7071, \n",
      "Epoch [33/100], Train Loss: 1.3160, \n",
      "Epoch [34/100], Train Loss: 3.4868, \n",
      "Epoch [35/100], Train Loss: 2.5983, \n",
      "Epoch [36/100], Train Loss: 1.8120, \n",
      "Epoch [37/100], Train Loss: 1.6175, \n",
      "Epoch [38/100], Train Loss: 1.6763, \n",
      "Epoch [39/100], Train Loss: 15.7611, \n",
      "Epoch [40/100], Train Loss: 14.1548, \n",
      "Epoch [41/100], Train Loss: 12.6988, \n",
      "Epoch [42/100], Train Loss: 11.3661, \n",
      "Epoch [43/100], Train Loss: 10.1728, \n",
      "Epoch [44/100], Train Loss: 9.1012, \n",
      "Epoch [45/100], Train Loss: 8.1386, \n",
      "Epoch [46/100], Train Loss: 7.2612, \n",
      "Epoch [47/100], Train Loss: 6.4621, \n",
      "Epoch [48/100], Train Loss: 5.7324, \n",
      "Epoch [49/100], Train Loss: 5.0699, \n",
      "Epoch [50/100], Train Loss: 4.4617, \n",
      "Epoch [51/100], Train Loss: 3.8913, \n",
      "Epoch [52/100], Train Loss: 3.3909, \n",
      "Epoch [53/100], Train Loss: 2.8825, \n",
      "Epoch [54/100], Train Loss: 2.4225, \n",
      "Epoch [55/100], Train Loss: 2.0294, \n",
      "Epoch [56/100], Train Loss: 1.7473, \n",
      "Epoch [57/100], Train Loss: 1.4863, \n",
      "Epoch [58/100], Train Loss: 1.2476, \n",
      "Epoch [59/100], Train Loss: 1.0941, \n",
      "Epoch [60/100], Train Loss: 0.9736, \n",
      "Epoch [61/100], Train Loss: 0.8706, \n",
      "Epoch [62/100], Train Loss: 0.8804, \n",
      "Epoch [63/100], Train Loss: 0.8316, \n",
      "Epoch [64/100], Train Loss: 0.8252, \n",
      "Epoch [65/100], Train Loss: 0.8097, \n",
      "Epoch [66/100], Train Loss: 0.8228, \n",
      "Epoch [67/100], Train Loss: 0.8153, \n",
      "Epoch [68/100], Train Loss: 0.7813, \n",
      "Epoch [69/100], Train Loss: 0.8036, \n",
      "Epoch [70/100], Train Loss: 0.7919, \n",
      "Epoch [71/100], Train Loss: 0.8500, \n",
      "Epoch [72/100], Train Loss: 0.8139, \n",
      "Epoch [73/100], Train Loss: 0.7930, \n",
      "Epoch [74/100], Train Loss: 0.7634, \n",
      "Epoch [75/100], Train Loss: 0.7050, \n",
      "Epoch [76/100], Train Loss: 0.7724, \n",
      "Epoch [77/100], Train Loss: 0.7657, \n",
      "Epoch [78/100], Train Loss: 0.7642, \n",
      "Epoch [79/100], Train Loss: 0.8299, \n",
      "Epoch [80/100], Train Loss: 0.7749, \n",
      "Epoch [81/100], Train Loss: 0.7535, \n",
      "Epoch [82/100], Train Loss: 0.7265, \n",
      "Epoch [83/100], Train Loss: 0.7603, \n",
      "Epoch [84/100], Train Loss: 0.7350, \n",
      "Epoch [85/100], Train Loss: 0.8041, \n",
      "Epoch [86/100], Train Loss: 0.7712, \n",
      "Epoch [87/100], Train Loss: 0.7792, \n",
      "Epoch [88/100], Train Loss: 0.7692, \n",
      "Epoch [89/100], Train Loss: 0.7484, \n",
      "Epoch [90/100], Train Loss: 0.7074, \n",
      "Epoch [91/100], Train Loss: 0.7637, \n",
      "Epoch [92/100], Train Loss: 0.7525, \n",
      "Epoch [93/100], Train Loss: 0.7497, \n",
      "Epoch [94/100], Train Loss: 0.7071, \n",
      "Epoch [95/100], Train Loss: 0.7213, \n",
      "Epoch [96/100], Train Loss: 0.7449, \n",
      "Epoch [97/100], Train Loss: 0.6907, \n",
      "Epoch [98/100], Train Loss: 0.7597, \n",
      "Epoch [99/100], Train Loss: 0.7533, \n",
      "Epoch [100/100], Train Loss: 0.7336, \n",
      "training loss at last epoch: 0.734\n",
      "Epoch [1/100], Train Loss: 1.3632, \n",
      "Epoch [2/100], Train Loss: 0.7644, \n",
      "Epoch [3/100], Train Loss: 0.7405, \n",
      "Epoch [4/100], Train Loss: 0.6824, \n",
      "Epoch [5/100], Train Loss: 0.6810, \n",
      "Epoch [6/100], Train Loss: 0.6808, \n",
      "Epoch [7/100], Train Loss: 0.6811, \n",
      "Epoch [8/100], Train Loss: 0.6805, \n",
      "Epoch [9/100], Train Loss: 0.6790, \n",
      "Epoch [10/100], Train Loss: 0.6785, \n",
      "Epoch [11/100], Train Loss: 0.6792, \n",
      "Epoch [12/100], Train Loss: 0.6786, \n",
      "Epoch [13/100], Train Loss: 0.7563, \n",
      "Epoch [14/100], Train Loss: 0.7365, \n",
      "Epoch [15/100], Train Loss: 0.6966, \n",
      "Epoch [16/100], Train Loss: 0.6824, \n",
      "Epoch [17/100], Train Loss: 0.6808, \n",
      "Epoch [18/100], Train Loss: 0.6807, \n",
      "Epoch [19/100], Train Loss: 0.6808, \n",
      "Epoch [20/100], Train Loss: 0.6806, \n",
      "Epoch [21/100], Train Loss: 0.6803, \n",
      "Epoch [22/100], Train Loss: 0.6814, \n",
      "Epoch [23/100], Train Loss: 0.6803, \n",
      "Epoch [24/100], Train Loss: 0.6813, \n",
      "Epoch [25/100], Train Loss: 0.6805, \n",
      "Epoch [26/100], Train Loss: 0.6817, \n",
      "Epoch [27/100], Train Loss: 0.6809, \n",
      "Epoch [28/100], Train Loss: 0.6815, \n",
      "Epoch [29/100], Train Loss: 0.6814, \n",
      "Epoch [30/100], Train Loss: 0.6827, \n",
      "Epoch [31/100], Train Loss: 0.6797, \n",
      "Epoch [32/100], Train Loss: 0.6804, \n",
      "Epoch [33/100], Train Loss: 0.6804, \n",
      "Epoch [34/100], Train Loss: 0.6806, \n",
      "Epoch [35/100], Train Loss: 0.6813, \n",
      "Epoch [36/100], Train Loss: 0.6816, \n",
      "Epoch [37/100], Train Loss: 0.6800, \n",
      "Epoch [38/100], Train Loss: 0.6800, \n",
      "Epoch [39/100], Train Loss: 0.6811, \n",
      "Epoch [40/100], Train Loss: 0.6810, \n",
      "Epoch [41/100], Train Loss: 0.6792, \n",
      "Epoch [42/100], Train Loss: 0.6804, \n",
      "Epoch [43/100], Train Loss: 0.6817, \n",
      "Epoch [44/100], Train Loss: 0.6799, \n",
      "Epoch [45/100], Train Loss: 0.6802, \n",
      "Epoch [46/100], Train Loss: 0.6806, \n",
      "Epoch [47/100], Train Loss: 0.6811, \n",
      "Epoch [48/100], Train Loss: 0.6810, \n",
      "Epoch [49/100], Train Loss: 0.6802, \n",
      "Epoch [50/100], Train Loss: 0.6782, \n",
      "Epoch [51/100], Train Loss: 0.6812, \n",
      "Epoch [52/100], Train Loss: 0.6796, \n",
      "Epoch [53/100], Train Loss: 0.6804, \n",
      "Epoch [54/100], Train Loss: 0.6819, \n",
      "Epoch [55/100], Train Loss: 0.6787, \n",
      "Epoch [56/100], Train Loss: 0.6804, \n",
      "Epoch [57/100], Train Loss: 0.6807, \n",
      "Epoch [58/100], Train Loss: 0.6797, \n",
      "Epoch [59/100], Train Loss: 0.6807, \n",
      "Epoch [60/100], Train Loss: 0.6794, \n",
      "Epoch [61/100], Train Loss: 0.6802, \n",
      "Epoch [62/100], Train Loss: 0.6813, \n",
      "Epoch [63/100], Train Loss: 0.6805, \n",
      "Epoch [64/100], Train Loss: 0.6799, \n",
      "Epoch [65/100], Train Loss: 0.6802, \n",
      "Epoch [66/100], Train Loss: 0.6804, \n",
      "Epoch [67/100], Train Loss: 0.6802, \n",
      "Epoch [68/100], Train Loss: 0.6795, \n",
      "Epoch [69/100], Train Loss: 0.6810, \n",
      "Epoch [70/100], Train Loss: 0.6792, \n",
      "Epoch [71/100], Train Loss: 0.6783, \n",
      "Epoch [72/100], Train Loss: 0.6795, \n",
      "Epoch [73/100], Train Loss: 0.6804, \n",
      "Epoch [74/100], Train Loss: 0.6805, \n",
      "Epoch [75/100], Train Loss: 0.6807, \n",
      "Epoch [76/100], Train Loss: 0.6801, \n",
      "Epoch [77/100], Train Loss: 0.6808, \n",
      "Epoch [78/100], Train Loss: 0.6791, \n",
      "Epoch [79/100], Train Loss: 0.6786, \n",
      "Epoch [80/100], Train Loss: 0.6801, \n",
      "Epoch [81/100], Train Loss: 0.6809, \n",
      "Epoch [82/100], Train Loss: 0.6797, \n",
      "Epoch [83/100], Train Loss: 0.6806, \n",
      "Epoch [84/100], Train Loss: 0.6808, \n",
      "Epoch [85/100], Train Loss: 0.6794, \n",
      "Epoch [86/100], Train Loss: 0.6780, \n",
      "Epoch [87/100], Train Loss: 0.6795, \n",
      "Epoch [88/100], Train Loss: 0.6798, \n",
      "Epoch [89/100], Train Loss: 0.6796, \n",
      "Epoch [90/100], Train Loss: 0.6790, \n",
      "Epoch [91/100], Train Loss: 0.6809, \n",
      "Epoch [92/100], Train Loss: 0.6810, \n",
      "Epoch [93/100], Train Loss: 0.6783, \n",
      "Epoch [94/100], Train Loss: 0.6798, \n",
      "Epoch [95/100], Train Loss: 0.6798, \n",
      "Epoch [96/100], Train Loss: 0.6799, \n",
      "Epoch [97/100], Train Loss: 0.6784, \n",
      "Epoch [98/100], Train Loss: 0.6794, \n",
      "Epoch [99/100], Train Loss: 0.6803, \n",
      "Epoch [100/100], Train Loss: 0.6804, \n",
      "training loss at last epoch: 0.680\n",
      "seed = 1\n",
      "4000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 23.1652, \n",
      "Epoch [2/100], Train Loss: 3.2947, \n",
      "Epoch [3/100], Train Loss: 1.9846, \n",
      "Epoch [4/100], Train Loss: 1.7822, \n",
      "Epoch [5/100], Train Loss: 2.0820, \n",
      "Epoch [6/100], Train Loss: 1.9774, \n",
      "Epoch [7/100], Train Loss: 6.8417, \n",
      "Epoch [8/100], Train Loss: 5.5344, \n",
      "Epoch [9/100], Train Loss: 4.2600, \n",
      "Epoch [10/100], Train Loss: 3.0821, \n",
      "Epoch [11/100], Train Loss: 2.1395, \n",
      "Epoch [12/100], Train Loss: 2.4673, \n",
      "Epoch [13/100], Train Loss: 19.2287, \n",
      "Epoch [14/100], Train Loss: 17.3261, \n",
      "Epoch [15/100], Train Loss: 15.5600, \n",
      "Epoch [16/100], Train Loss: 14.5491, \n",
      "Epoch [17/100], Train Loss: 12.5684, \n",
      "Epoch [18/100], Train Loss: 11.2586, \n",
      "Epoch [19/100], Train Loss: 10.1942, \n",
      "Epoch [20/100], Train Loss: 9.0485, \n",
      "Epoch [21/100], Train Loss: 8.0908, \n",
      "Epoch [22/100], Train Loss: 7.2152, \n",
      "Epoch [23/100], Train Loss: 6.4018, \n",
      "Epoch [24/100], Train Loss: 5.6594, \n",
      "Epoch [25/100], Train Loss: 4.9825, \n",
      "Epoch [26/100], Train Loss: 4.3731, \n",
      "Epoch [27/100], Train Loss: 3.8397, \n",
      "Epoch [28/100], Train Loss: 3.3677, \n",
      "Epoch [29/100], Train Loss: 2.9549, \n",
      "Epoch [30/100], Train Loss: 2.5213, \n",
      "Epoch [31/100], Train Loss: 2.4608, \n",
      "Epoch [32/100], Train Loss: 2.0535, \n",
      "Epoch [33/100], Train Loss: 2.1019, \n",
      "Epoch [34/100], Train Loss: 1.8814, \n",
      "Epoch [35/100], Train Loss: 1.8755, \n",
      "Epoch [36/100], Train Loss: 1.7131, \n",
      "Epoch [37/100], Train Loss: 1.5757, \n",
      "Epoch [38/100], Train Loss: 1.5112, \n",
      "Epoch [39/100], Train Loss: 1.2288, \n",
      "Epoch [40/100], Train Loss: 1.3605, \n",
      "Epoch [41/100], Train Loss: 1.3522, \n",
      "Epoch [42/100], Train Loss: 1.1115, \n",
      "Epoch [43/100], Train Loss: 1.1905, \n",
      "Epoch [44/100], Train Loss: 1.1224, \n",
      "Epoch [45/100], Train Loss: 1.0264, \n",
      "Epoch [46/100], Train Loss: 1.0215, \n",
      "Epoch [47/100], Train Loss: 0.9939, \n",
      "Epoch [48/100], Train Loss: 0.9301, \n",
      "Epoch [49/100], Train Loss: 0.8803, \n",
      "Epoch [50/100], Train Loss: 0.7579, \n",
      "Epoch [51/100], Train Loss: 0.8124, \n",
      "Epoch [52/100], Train Loss: 0.9500, \n",
      "Epoch [53/100], Train Loss: 0.7915, \n",
      "Epoch [54/100], Train Loss: 0.8933, \n",
      "Epoch [55/100], Train Loss: 0.6864, \n",
      "Epoch [56/100], Train Loss: 0.8069, \n",
      "Epoch [57/100], Train Loss: 0.8567, \n",
      "Epoch [58/100], Train Loss: 0.8329, \n",
      "Epoch [59/100], Train Loss: 0.8866, \n",
      "Epoch [60/100], Train Loss: 0.6841, \n",
      "Epoch [61/100], Train Loss: 0.6800, \n",
      "Epoch [62/100], Train Loss: 0.6812, \n",
      "Epoch [63/100], Train Loss: 0.6785, \n",
      "Epoch [64/100], Train Loss: 0.6811, \n",
      "Epoch [65/100], Train Loss: 0.6804, \n",
      "Epoch [66/100], Train Loss: 0.6790, \n",
      "Epoch [67/100], Train Loss: 0.6789, \n",
      "Epoch [68/100], Train Loss: 0.6798, \n",
      "Epoch [69/100], Train Loss: 0.6792, \n",
      "Epoch [70/100], Train Loss: 0.6794, \n",
      "Epoch [71/100], Train Loss: 0.6794, \n",
      "Epoch [72/100], Train Loss: 0.6776, \n",
      "Epoch [73/100], Train Loss: 0.6799, \n",
      "Epoch [74/100], Train Loss: 0.6793, \n",
      "Epoch [75/100], Train Loss: 0.6789, \n",
      "Epoch [76/100], Train Loss: 0.6802, \n",
      "Epoch [77/100], Train Loss: 0.6802, \n",
      "Epoch [78/100], Train Loss: 0.6794, \n",
      "Epoch [79/100], Train Loss: 0.6792, \n",
      "Epoch [80/100], Train Loss: 0.6789, \n",
      "Epoch [81/100], Train Loss: 0.6789, \n",
      "Epoch [82/100], Train Loss: 0.6801, \n",
      "Epoch [83/100], Train Loss: 0.6797, \n",
      "Epoch [84/100], Train Loss: 0.6796, \n",
      "Epoch [85/100], Train Loss: 0.6800, \n",
      "Epoch [86/100], Train Loss: 0.6789, \n",
      "Epoch [87/100], Train Loss: 0.6789, \n",
      "Epoch [88/100], Train Loss: 0.6796, \n",
      "Epoch [89/100], Train Loss: 0.6802, \n",
      "Epoch [90/100], Train Loss: 0.6807, \n",
      "Epoch [91/100], Train Loss: 0.6791, \n",
      "Epoch [92/100], Train Loss: 0.6813, \n",
      "Epoch [93/100], Train Loss: 0.6800, \n",
      "Epoch [94/100], Train Loss: 0.6807, \n",
      "Epoch [95/100], Train Loss: 0.6795, \n",
      "Epoch [96/100], Train Loss: 0.6799, \n",
      "Epoch [97/100], Train Loss: 0.6792, \n",
      "Epoch [98/100], Train Loss: 0.6796, \n",
      "Epoch [99/100], Train Loss: 0.6802, \n",
      "Epoch [100/100], Train Loss: 0.6802, \n",
      "training loss at last epoch: 0.680\n",
      "Epoch [1/100], Train Loss: 0.9151, \n",
      "Epoch [2/100], Train Loss: 0.6855, \n",
      "Epoch [3/100], Train Loss: 0.6819, \n",
      "Epoch [4/100], Train Loss: 0.6817, \n",
      "Epoch [5/100], Train Loss: 0.6822, \n",
      "Epoch [6/100], Train Loss: 0.6829, \n",
      "Epoch [7/100], Train Loss: 0.6820, \n",
      "Epoch [8/100], Train Loss: 0.6815, \n",
      "Epoch [9/100], Train Loss: 0.6809, \n",
      "Epoch [10/100], Train Loss: 0.6821, \n",
      "Epoch [11/100], Train Loss: 0.6815, \n",
      "Epoch [12/100], Train Loss: 0.6806, \n",
      "Epoch [13/100], Train Loss: 0.6828, \n",
      "Epoch [14/100], Train Loss: 0.6820, \n",
      "Epoch [15/100], Train Loss: 0.6842, \n",
      "Epoch [16/100], Train Loss: 0.6821, \n",
      "Epoch [17/100], Train Loss: 0.6827, \n",
      "Epoch [18/100], Train Loss: 0.6844, \n",
      "Epoch [19/100], Train Loss: 0.6811, \n",
      "Epoch [20/100], Train Loss: 0.6822, \n",
      "Epoch [21/100], Train Loss: 0.6804, \n",
      "Epoch [22/100], Train Loss: 0.6815, \n",
      "Epoch [23/100], Train Loss: 0.6821, \n",
      "Epoch [24/100], Train Loss: 0.6826, \n",
      "Epoch [25/100], Train Loss: 0.6818, \n",
      "Epoch [26/100], Train Loss: 0.6826, \n",
      "Epoch [27/100], Train Loss: 0.6816, \n",
      "Epoch [28/100], Train Loss: 0.6809, \n",
      "Epoch [29/100], Train Loss: 0.6814, \n",
      "Epoch [30/100], Train Loss: 0.6824, \n",
      "Epoch [31/100], Train Loss: 0.6823, \n",
      "Epoch [32/100], Train Loss: 0.6806, \n",
      "Epoch [33/100], Train Loss: 0.6809, \n",
      "Epoch [34/100], Train Loss: 0.6818, \n",
      "Epoch [35/100], Train Loss: 0.6813, \n",
      "Epoch [36/100], Train Loss: 0.6825, \n",
      "Epoch [37/100], Train Loss: 0.6822, \n",
      "Epoch [38/100], Train Loss: 0.6833, \n",
      "Epoch [39/100], Train Loss: 0.6829, \n",
      "Epoch [40/100], Train Loss: 0.6816, \n",
      "Epoch [41/100], Train Loss: 0.6804, \n",
      "Epoch [42/100], Train Loss: 0.6820, \n",
      "Epoch [43/100], Train Loss: 0.6826, \n",
      "Epoch [44/100], Train Loss: 0.6810, \n",
      "Epoch [45/100], Train Loss: 0.6828, \n",
      "Epoch [46/100], Train Loss: 0.6807, \n",
      "Epoch [47/100], Train Loss: 0.6820, \n",
      "Epoch [48/100], Train Loss: 0.6808, \n",
      "Epoch [49/100], Train Loss: 0.6802, \n",
      "Epoch [50/100], Train Loss: 0.6824, \n",
      "Epoch [51/100], Train Loss: 0.6802, \n",
      "Epoch [52/100], Train Loss: 0.6798, \n",
      "Epoch [53/100], Train Loss: 0.6798, \n",
      "Epoch [54/100], Train Loss: 0.6804, \n",
      "Epoch [55/100], Train Loss: 0.6803, \n",
      "Epoch [56/100], Train Loss: 0.6790, \n",
      "Epoch [57/100], Train Loss: 0.6790, \n",
      "Epoch [58/100], Train Loss: 0.7127, \n",
      "Epoch [59/100], Train Loss: 0.6865, \n",
      "Epoch [60/100], Train Loss: 0.6836, \n",
      "Epoch [61/100], Train Loss: 0.6814, \n",
      "Epoch [62/100], Train Loss: 0.6826, \n",
      "Epoch [63/100], Train Loss: 0.6825, \n",
      "Epoch [64/100], Train Loss: 0.6820, \n",
      "Epoch [65/100], Train Loss: 0.6813, \n",
      "Epoch [66/100], Train Loss: 0.6804, \n",
      "Epoch [67/100], Train Loss: 0.6822, \n",
      "Epoch [68/100], Train Loss: 0.6809, \n",
      "Epoch [69/100], Train Loss: 0.6813, \n",
      "Epoch [70/100], Train Loss: 0.6811, \n",
      "Epoch [71/100], Train Loss: 0.6818, \n",
      "Epoch [72/100], Train Loss: 0.6820, \n",
      "Epoch [73/100], Train Loss: 0.6801, \n",
      "Epoch [74/100], Train Loss: 0.6805, \n",
      "Epoch [75/100], Train Loss: 0.6824, \n",
      "Epoch [76/100], Train Loss: 0.6822, \n",
      "Epoch [77/100], Train Loss: 0.6827, \n",
      "Epoch [78/100], Train Loss: 0.6816, \n",
      "Epoch [79/100], Train Loss: 0.6816, \n",
      "Epoch [80/100], Train Loss: 0.6833, \n",
      "Epoch [81/100], Train Loss: 0.6811, \n",
      "Epoch [82/100], Train Loss: 0.6809, \n",
      "Epoch [83/100], Train Loss: 0.6820, \n",
      "Epoch [84/100], Train Loss: 0.6828, \n",
      "Epoch [85/100], Train Loss: 0.6827, \n",
      "Epoch [86/100], Train Loss: 0.6804, \n",
      "Epoch [87/100], Train Loss: 0.6835, \n",
      "Epoch [88/100], Train Loss: 0.6806, \n",
      "Epoch [89/100], Train Loss: 0.6813, \n",
      "Epoch [90/100], Train Loss: 0.6806, \n",
      "Epoch [91/100], Train Loss: 0.6829, \n",
      "Epoch [92/100], Train Loss: 0.6817, \n",
      "Epoch [93/100], Train Loss: 0.6813, \n",
      "Epoch [94/100], Train Loss: 0.6817, \n",
      "Epoch [95/100], Train Loss: 0.6806, \n",
      "Epoch [96/100], Train Loss: 0.6816, \n",
      "Epoch [97/100], Train Loss: 0.6808, \n",
      "Epoch [98/100], Train Loss: 0.6809, \n",
      "Epoch [99/100], Train Loss: 0.6807, \n",
      "Epoch [100/100], Train Loss: 0.6822, \n",
      "training loss at last epoch: 0.682\n",
      "seed = 2\n",
      "4000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 9.5167, \n",
      "Epoch [2/100], Train Loss: 2.2997, \n",
      "Epoch [3/100], Train Loss: 3.9067, \n",
      "Epoch [4/100], Train Loss: 10.2896, \n",
      "Epoch [5/100], Train Loss: 9.4924, \n",
      "Epoch [6/100], Train Loss: 5.2333, \n",
      "Epoch [7/100], Train Loss: 1.7172, \n",
      "Epoch [8/100], Train Loss: 1.6005, \n",
      "Epoch [9/100], Train Loss: 1.5025, \n",
      "Epoch [10/100], Train Loss: 2.1054, \n",
      "Epoch [11/100], Train Loss: 1.7837, \n",
      "Epoch [12/100], Train Loss: 1.9332, \n",
      "Epoch [13/100], Train Loss: 3.4691, \n",
      "Epoch [14/100], Train Loss: 5.5116, \n",
      "Epoch [15/100], Train Loss: 2.5979, \n",
      "Epoch [16/100], Train Loss: 1.6895, \n",
      "Epoch [17/100], Train Loss: 1.7412, \n",
      "Epoch [18/100], Train Loss: 1.1972, \n",
      "Epoch [19/100], Train Loss: 1.5691, \n",
      "Epoch [20/100], Train Loss: 1.4568, \n",
      "Epoch [21/100], Train Loss: 1.0683, \n",
      "Epoch [22/100], Train Loss: 3.6775, \n",
      "Epoch [23/100], Train Loss: 8.3984, \n",
      "Epoch [24/100], Train Loss: 5.7491, \n",
      "Epoch [25/100], Train Loss: 3.4955, \n",
      "Epoch [26/100], Train Loss: 1.7177, \n",
      "Epoch [27/100], Train Loss: 1.3194, \n",
      "Epoch [28/100], Train Loss: 1.5077, \n",
      "Epoch [29/100], Train Loss: 1.2355, \n",
      "Epoch [30/100], Train Loss: 1.1138, \n",
      "Epoch [31/100], Train Loss: 1.0599, \n",
      "Epoch [32/100], Train Loss: 1.1459, \n",
      "Epoch [33/100], Train Loss: 1.1865, \n",
      "Epoch [34/100], Train Loss: 1.2117, \n",
      "Epoch [35/100], Train Loss: 0.9420, \n",
      "Epoch [36/100], Train Loss: 1.2829, \n",
      "Epoch [37/100], Train Loss: 1.0899, \n",
      "Epoch [38/100], Train Loss: 1.0307, \n",
      "Epoch [39/100], Train Loss: 0.8033, \n",
      "Epoch [40/100], Train Loss: 0.9080, \n",
      "Epoch [41/100], Train Loss: 0.9142, \n",
      "Epoch [42/100], Train Loss: 0.9262, \n",
      "Epoch [43/100], Train Loss: 0.8491, \n",
      "Epoch [44/100], Train Loss: 1.0215, \n",
      "Epoch [45/100], Train Loss: 0.9960, \n",
      "Epoch [46/100], Train Loss: 1.1370, \n",
      "Epoch [47/100], Train Loss: 0.8180, \n",
      "Epoch [48/100], Train Loss: 0.8559, \n",
      "Epoch [49/100], Train Loss: 0.8966, \n",
      "Epoch [50/100], Train Loss: 0.8814, \n",
      "Epoch [51/100], Train Loss: 0.9493, \n",
      "Epoch [52/100], Train Loss: 0.9494, \n",
      "Epoch [53/100], Train Loss: 0.9901, \n",
      "Epoch [54/100], Train Loss: 0.8987, \n",
      "Epoch [55/100], Train Loss: 1.2829, \n",
      "Epoch [56/100], Train Loss: 0.8849, \n",
      "Epoch [57/100], Train Loss: 0.8205, \n",
      "Epoch [58/100], Train Loss: 0.8187, \n",
      "Epoch [59/100], Train Loss: 0.7609, \n",
      "Epoch [60/100], Train Loss: 1.0008, \n",
      "Epoch [61/100], Train Loss: 1.0548, \n",
      "Epoch [62/100], Train Loss: 0.9925, \n",
      "Epoch [63/100], Train Loss: 0.9218, \n",
      "Epoch [64/100], Train Loss: 0.9811, \n",
      "Epoch [65/100], Train Loss: 0.7793, \n",
      "Epoch [66/100], Train Loss: 1.0024, \n",
      "Epoch [67/100], Train Loss: 0.8527, \n",
      "Epoch [68/100], Train Loss: 0.7995, \n",
      "Epoch [69/100], Train Loss: 0.8954, \n",
      "Epoch [70/100], Train Loss: 0.8278, \n",
      "Epoch [71/100], Train Loss: 0.8333, \n",
      "Epoch [72/100], Train Loss: 0.9309, \n",
      "Epoch [73/100], Train Loss: 0.8348, \n",
      "Epoch [74/100], Train Loss: 0.8163, \n",
      "Epoch [75/100], Train Loss: 0.8046, \n",
      "Epoch [76/100], Train Loss: 0.8781, \n",
      "Epoch [77/100], Train Loss: 0.8380, \n",
      "Epoch [78/100], Train Loss: 0.7327, \n",
      "Epoch [79/100], Train Loss: 0.8393, \n",
      "Epoch [80/100], Train Loss: 0.7869, \n",
      "Epoch [81/100], Train Loss: 0.8079, \n",
      "Epoch [82/100], Train Loss: 0.7451, \n",
      "Epoch [83/100], Train Loss: 0.7690, \n",
      "Epoch [84/100], Train Loss: 0.8060, \n",
      "Epoch [85/100], Train Loss: 0.8767, \n",
      "Epoch [86/100], Train Loss: 0.8329, \n",
      "Epoch [87/100], Train Loss: 0.7370, \n",
      "Epoch [88/100], Train Loss: 0.7973, \n",
      "Epoch [89/100], Train Loss: 0.8383, \n",
      "Epoch [90/100], Train Loss: 0.8641, \n",
      "Epoch [91/100], Train Loss: 0.7344, \n",
      "Epoch [92/100], Train Loss: 0.8186, \n",
      "Epoch [93/100], Train Loss: 0.7944, \n",
      "Epoch [94/100], Train Loss: 0.8365, \n",
      "Epoch [95/100], Train Loss: 0.8087, \n",
      "Epoch [96/100], Train Loss: 0.8053, \n",
      "Epoch [97/100], Train Loss: 0.9467, \n",
      "Epoch [98/100], Train Loss: 0.8050, \n",
      "Epoch [99/100], Train Loss: 0.7446, \n",
      "Epoch [100/100], Train Loss: 0.7463, \n",
      "training loss at last epoch: 0.746\n",
      "Epoch [1/100], Train Loss: 1.7032, \n",
      "Epoch [2/100], Train Loss: 0.7329, \n",
      "Epoch [3/100], Train Loss: 0.6967, \n",
      "Epoch [4/100], Train Loss: 0.6827, \n",
      "Epoch [5/100], Train Loss: 0.6816, \n",
      "Epoch [6/100], Train Loss: 0.6811, \n",
      "Epoch [7/100], Train Loss: 0.6809, \n",
      "Epoch [8/100], Train Loss: 0.6817, \n",
      "Epoch [9/100], Train Loss: 0.6801, \n",
      "Epoch [10/100], Train Loss: 0.6818, \n",
      "Epoch [11/100], Train Loss: 0.6794, \n",
      "Epoch [12/100], Train Loss: 0.6804, \n",
      "Epoch [13/100], Train Loss: 0.6809, \n",
      "Epoch [14/100], Train Loss: 0.6821, \n",
      "Epoch [15/100], Train Loss: 0.6813, \n",
      "Epoch [16/100], Train Loss: 0.6796, \n",
      "Epoch [17/100], Train Loss: 0.6808, \n",
      "Epoch [18/100], Train Loss: 0.6798, \n",
      "Epoch [19/100], Train Loss: 0.6801, \n",
      "Epoch [20/100], Train Loss: 0.6812, \n",
      "Epoch [21/100], Train Loss: 0.6775, \n",
      "Epoch [22/100], Train Loss: 0.6828, \n",
      "Epoch [23/100], Train Loss: 0.6804, \n",
      "Epoch [24/100], Train Loss: 0.6804, \n",
      "Epoch [25/100], Train Loss: 0.6807, \n",
      "Epoch [26/100], Train Loss: 0.6805, \n",
      "Epoch [27/100], Train Loss: 0.6818, \n",
      "Epoch [28/100], Train Loss: 0.6791, \n",
      "Epoch [29/100], Train Loss: 0.7107, \n",
      "Epoch [30/100], Train Loss: 0.6815, \n",
      "Epoch [31/100], Train Loss: 0.6797, \n",
      "Epoch [32/100], Train Loss: 0.6799, \n",
      "Epoch [33/100], Train Loss: 0.6837, \n",
      "Epoch [34/100], Train Loss: 0.6813, \n",
      "Epoch [35/100], Train Loss: 0.6805, \n",
      "Epoch [36/100], Train Loss: 0.6802, \n",
      "Epoch [37/100], Train Loss: 0.6798, \n",
      "Epoch [38/100], Train Loss: 0.6797, \n",
      "Epoch [39/100], Train Loss: 0.6804, \n",
      "Epoch [40/100], Train Loss: 0.6814, \n",
      "Epoch [41/100], Train Loss: 0.6790, \n",
      "Epoch [42/100], Train Loss: 0.7065, \n",
      "Epoch [43/100], Train Loss: 0.6911, \n",
      "Epoch [44/100], Train Loss: 0.6829, \n",
      "Epoch [45/100], Train Loss: 0.6830, \n",
      "Epoch [46/100], Train Loss: 0.6820, \n",
      "Epoch [47/100], Train Loss: 0.6814, \n",
      "Epoch [48/100], Train Loss: 0.6816, \n",
      "Epoch [49/100], Train Loss: 0.6818, \n",
      "Epoch [50/100], Train Loss: 0.6818, \n",
      "Epoch [51/100], Train Loss: 0.6803, \n",
      "Epoch [52/100], Train Loss: 0.6821, \n",
      "Epoch [53/100], Train Loss: 0.6799, \n",
      "Epoch [54/100], Train Loss: 0.6804, \n",
      "Epoch [55/100], Train Loss: 0.6793, \n",
      "Epoch [56/100], Train Loss: 0.6796, \n",
      "Epoch [57/100], Train Loss: 0.6808, \n",
      "Epoch [58/100], Train Loss: 0.6791, \n",
      "Epoch [59/100], Train Loss: 0.6801, \n",
      "Epoch [60/100], Train Loss: 0.7018, \n",
      "Epoch [61/100], Train Loss: 0.6815, \n",
      "Epoch [62/100], Train Loss: 0.6818, \n",
      "Epoch [63/100], Train Loss: 0.6823, \n",
      "Epoch [64/100], Train Loss: 0.6822, \n",
      "Epoch [65/100], Train Loss: 0.6815, \n",
      "Epoch [66/100], Train Loss: 0.6806, \n",
      "Epoch [67/100], Train Loss: 0.6808, \n",
      "Epoch [68/100], Train Loss: 0.6803, \n",
      "Epoch [69/100], Train Loss: 0.6806, \n",
      "Epoch [70/100], Train Loss: 0.6818, \n",
      "Epoch [71/100], Train Loss: 0.6814, \n",
      "Epoch [72/100], Train Loss: 0.6834, \n",
      "Epoch [73/100], Train Loss: 0.6801, \n",
      "Epoch [74/100], Train Loss: 0.6819, \n",
      "Epoch [75/100], Train Loss: 0.6819, \n",
      "Epoch [76/100], Train Loss: 0.6809, \n",
      "Epoch [77/100], Train Loss: 0.6845, \n",
      "Epoch [78/100], Train Loss: 0.6815, \n",
      "Epoch [79/100], Train Loss: 0.6807, \n",
      "Epoch [80/100], Train Loss: 0.6792, \n",
      "Epoch [81/100], Train Loss: 0.6798, \n",
      "Epoch [82/100], Train Loss: 0.6815, \n",
      "Epoch [83/100], Train Loss: 0.6831, \n",
      "Epoch [84/100], Train Loss: 0.6820, \n",
      "Epoch [85/100], Train Loss: 0.6832, \n",
      "Epoch [86/100], Train Loss: 0.6816, \n",
      "Epoch [87/100], Train Loss: 0.6809, \n",
      "Epoch [88/100], Train Loss: 0.6805, \n",
      "Epoch [89/100], Train Loss: 0.6813, \n",
      "Epoch [90/100], Train Loss: 0.6802, \n",
      "Epoch [91/100], Train Loss: 0.6806, \n",
      "Epoch [92/100], Train Loss: 0.6827, \n",
      "Epoch [93/100], Train Loss: 0.6808, \n",
      "Epoch [94/100], Train Loss: 0.6810, \n",
      "Epoch [95/100], Train Loss: 0.6831, \n",
      "Epoch [96/100], Train Loss: 0.6831, \n",
      "Epoch [97/100], Train Loss: 0.6824, \n",
      "Epoch [98/100], Train Loss: 0.6820, \n",
      "Epoch [99/100], Train Loss: 0.6813, \n",
      "Epoch [100/100], Train Loss: 0.6819, \n",
      "training loss at last epoch: 0.682\n",
      "time t = 150\n",
      "seed = 0\n",
      "6000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 393.6723, \n",
      "Epoch [2/100], Train Loss: 311.5133, \n",
      "Epoch [3/100], Train Loss: 253.4124, \n",
      "Epoch [4/100], Train Loss: 198.9186, \n",
      "Epoch [5/100], Train Loss: 148.2152, \n",
      "Epoch [6/100], Train Loss: 98.5285, \n",
      "Epoch [7/100], Train Loss: 51.2646, \n",
      "Epoch [8/100], Train Loss: 44.0694, \n",
      "Epoch [9/100], Train Loss: 142.7992, \n",
      "Epoch [10/100], Train Loss: 96.1047, \n",
      "Epoch [11/100], Train Loss: 51.2114, \n",
      "Epoch [12/100], Train Loss: 29.4882, \n",
      "Epoch [13/100], Train Loss: 41.8019, \n",
      "Epoch [14/100], Train Loss: 117.0505, \n",
      "Epoch [15/100], Train Loss: 73.6213, \n",
      "Epoch [16/100], Train Loss: 39.7915, \n",
      "Epoch [17/100], Train Loss: 157.7768, \n",
      "Epoch [18/100], Train Loss: 114.9331, \n",
      "Epoch [19/100], Train Loss: 74.1524, \n",
      "Epoch [20/100], Train Loss: 43.7734, \n",
      "Epoch [21/100], Train Loss: 36.6034, \n",
      "Epoch [22/100], Train Loss: 108.9768, \n",
      "Epoch [23/100], Train Loss: 70.0866, \n",
      "Epoch [24/100], Train Loss: 41.1165, \n",
      "Epoch [25/100], Train Loss: 31.6568, \n",
      "Epoch [26/100], Train Loss: 50.9552, \n",
      "Epoch [27/100], Train Loss: 36.9212, \n",
      "Epoch [28/100], Train Loss: 19.2694, \n",
      "Epoch [29/100], Train Loss: 118.7702, \n",
      "Epoch [30/100], Train Loss: 82.2706, \n",
      "Epoch [31/100], Train Loss: 49.3882, \n",
      "Epoch [32/100], Train Loss: 47.0771, \n",
      "Epoch [33/100], Train Loss: 65.2560, \n",
      "Epoch [34/100], Train Loss: 32.0658, \n",
      "Epoch [35/100], Train Loss: 37.7203, \n",
      "Epoch [36/100], Train Loss: 23.1285, \n",
      "Epoch [37/100], Train Loss: 69.0097, \n",
      "Epoch [38/100], Train Loss: 39.6139, \n",
      "Epoch [39/100], Train Loss: 38.2938, \n",
      "Epoch [40/100], Train Loss: 27.8344, \n",
      "Epoch [41/100], Train Loss: 34.0714, \n",
      "Epoch [42/100], Train Loss: 21.1239, \n",
      "Epoch [43/100], Train Loss: 12.4682, \n",
      "Epoch [44/100], Train Loss: 47.0479, \n",
      "Epoch [45/100], Train Loss: 20.0982, \n",
      "Epoch [46/100], Train Loss: 30.9351, \n",
      "Epoch [47/100], Train Loss: 253.5067, \n",
      "Epoch [48/100], Train Loss: 218.2423, \n",
      "Epoch [49/100], Train Loss: 185.8393, \n",
      "Epoch [50/100], Train Loss: 155.9648, \n",
      "Epoch [51/100], Train Loss: 127.9509, \n",
      "Epoch [52/100], Train Loss: 101.6526, \n",
      "Epoch [53/100], Train Loss: 76.7557, \n",
      "Epoch [54/100], Train Loss: 53.2003, \n",
      "Epoch [55/100], Train Loss: 30.6128, \n",
      "Epoch [56/100], Train Loss: 11.2057, \n",
      "Epoch [57/100], Train Loss: 34.6835, \n",
      "Epoch [58/100], Train Loss: 10.5775, \n",
      "Epoch [59/100], Train Loss: 23.8328, \n",
      "Epoch [60/100], Train Loss: 17.8837, \n",
      "Epoch [61/100], Train Loss: 20.2923, \n",
      "Epoch [62/100], Train Loss: 14.5317, \n",
      "Epoch [63/100], Train Loss: 23.2233, \n",
      "Epoch [64/100], Train Loss: 15.8087, \n",
      "Epoch [65/100], Train Loss: 21.7095, \n",
      "Epoch [66/100], Train Loss: 18.5529, \n",
      "Epoch [67/100], Train Loss: 10.3425, \n",
      "Epoch [68/100], Train Loss: 24.0276, \n",
      "Epoch [69/100], Train Loss: 0.6852, \n",
      "Epoch [70/100], Train Loss: 18.1875, \n",
      "Epoch [71/100], Train Loss: 19.8043, \n",
      "Epoch [72/100], Train Loss: 16.9775, \n",
      "Epoch [73/100], Train Loss: 12.5017, \n",
      "Epoch [74/100], Train Loss: 15.7152, \n",
      "Epoch [75/100], Train Loss: 12.2519, \n",
      "Epoch [76/100], Train Loss: 13.5324, \n",
      "Epoch [77/100], Train Loss: 21.7179, \n",
      "Epoch [78/100], Train Loss: 7.6558, \n",
      "Epoch [79/100], Train Loss: 17.4773, \n",
      "Epoch [80/100], Train Loss: 13.3784, \n",
      "Epoch [81/100], Train Loss: 14.6796, \n",
      "Epoch [82/100], Train Loss: 7.3644, \n",
      "Epoch [83/100], Train Loss: 8.5805, \n",
      "Epoch [84/100], Train Loss: 13.0932, \n",
      "Epoch [85/100], Train Loss: 2.9549, \n",
      "Epoch [86/100], Train Loss: 18.8521, \n",
      "Epoch [87/100], Train Loss: 14.1640, \n",
      "Epoch [88/100], Train Loss: 8.3424, \n",
      "Epoch [89/100], Train Loss: 10.3001, \n",
      "Epoch [90/100], Train Loss: 6.2412, \n",
      "Epoch [91/100], Train Loss: 9.3986, \n",
      "Epoch [92/100], Train Loss: 8.7174, \n",
      "Epoch [93/100], Train Loss: 17.3557, \n",
      "Epoch [94/100], Train Loss: 7.6018, \n",
      "Epoch [95/100], Train Loss: 16.7945, \n",
      "Epoch [96/100], Train Loss: 5.4674, \n",
      "Epoch [97/100], Train Loss: 21.4560, \n",
      "Epoch [98/100], Train Loss: 13.2353, \n",
      "Epoch [99/100], Train Loss: 14.0551, \n",
      "Epoch [100/100], Train Loss: 8.3801, \n",
      "training loss at last epoch: 8.380\n",
      "Epoch [1/100], Train Loss: 1.2106, \n",
      "Epoch [2/100], Train Loss: 0.6885, \n",
      "Epoch [3/100], Train Loss: 0.6874, \n",
      "Epoch [4/100], Train Loss: 0.6868, \n",
      "Epoch [5/100], Train Loss: 0.6859, \n",
      "Epoch [6/100], Train Loss: 0.6866, \n",
      "Epoch [7/100], Train Loss: 0.6874, \n",
      "Epoch [8/100], Train Loss: 0.6870, \n",
      "Epoch [9/100], Train Loss: 0.6864, \n",
      "Epoch [10/100], Train Loss: 0.6863, \n",
      "Epoch [11/100], Train Loss: 0.6865, \n",
      "Epoch [12/100], Train Loss: 0.6870, \n",
      "Epoch [13/100], Train Loss: 0.6853, \n",
      "Epoch [14/100], Train Loss: 0.6854, \n",
      "Epoch [15/100], Train Loss: 0.6852, \n",
      "Epoch [16/100], Train Loss: 0.6854, \n",
      "Epoch [17/100], Train Loss: 0.6861, \n",
      "Epoch [18/100], Train Loss: 0.6848, \n",
      "Epoch [19/100], Train Loss: 0.6855, \n",
      "Epoch [20/100], Train Loss: 0.6872, \n",
      "Epoch [21/100], Train Loss: 0.6850, \n",
      "Epoch [22/100], Train Loss: 0.6860, \n",
      "Epoch [23/100], Train Loss: 0.6867, \n",
      "Epoch [24/100], Train Loss: 0.6866, \n",
      "Epoch [25/100], Train Loss: 0.6856, \n",
      "Epoch [26/100], Train Loss: 0.6863, \n",
      "Epoch [27/100], Train Loss: 0.6857, \n",
      "Epoch [28/100], Train Loss: 0.6843, \n",
      "Epoch [29/100], Train Loss: 0.6856, \n",
      "Epoch [30/100], Train Loss: 0.6867, \n",
      "Epoch [31/100], Train Loss: 0.6862, \n",
      "Epoch [32/100], Train Loss: 0.6858, \n",
      "Epoch [33/100], Train Loss: 0.6854, \n",
      "Epoch [34/100], Train Loss: 0.6850, \n",
      "Epoch [35/100], Train Loss: 0.6851, \n",
      "Epoch [36/100], Train Loss: 0.6860, \n",
      "Epoch [37/100], Train Loss: 0.6852, \n",
      "Epoch [38/100], Train Loss: 0.6872, \n",
      "Epoch [39/100], Train Loss: 0.6863, \n",
      "Epoch [40/100], Train Loss: 0.6848, \n",
      "Epoch [41/100], Train Loss: 0.6876, \n",
      "Epoch [42/100], Train Loss: 0.6856, \n",
      "Epoch [43/100], Train Loss: 0.6849, \n",
      "Epoch [44/100], Train Loss: 0.6866, \n",
      "Epoch [45/100], Train Loss: 0.6841, \n",
      "Epoch [46/100], Train Loss: 0.6848, \n",
      "Epoch [47/100], Train Loss: 0.6844, \n",
      "Epoch [48/100], Train Loss: 0.6831, \n",
      "Epoch [49/100], Train Loss: 0.6855, \n",
      "Epoch [50/100], Train Loss: 0.6832, \n",
      "Epoch [51/100], Train Loss: 0.7055, \n",
      "Epoch [52/100], Train Loss: 0.6860, \n",
      "Epoch [53/100], Train Loss: 0.6884, \n",
      "Epoch [54/100], Train Loss: 0.6881, \n",
      "Epoch [55/100], Train Loss: 0.6881, \n",
      "Epoch [56/100], Train Loss: 0.6879, \n",
      "Epoch [57/100], Train Loss: 0.6885, \n",
      "Epoch [58/100], Train Loss: 0.6877, \n",
      "Epoch [59/100], Train Loss: 0.6857, \n",
      "Epoch [60/100], Train Loss: 0.6868, \n",
      "Epoch [61/100], Train Loss: 0.6894, \n",
      "Epoch [62/100], Train Loss: 0.6876, \n",
      "Epoch [63/100], Train Loss: 0.6870, \n",
      "Epoch [64/100], Train Loss: 0.6879, \n",
      "Epoch [65/100], Train Loss: 0.6862, \n",
      "Epoch [66/100], Train Loss: 0.6872, \n",
      "Epoch [67/100], Train Loss: 0.6882, \n",
      "Epoch [68/100], Train Loss: 0.6882, \n",
      "Epoch [69/100], Train Loss: 0.6872, \n",
      "Epoch [70/100], Train Loss: 0.6877, \n",
      "Epoch [71/100], Train Loss: 0.6869, \n",
      "Epoch [72/100], Train Loss: 0.6869, \n",
      "Epoch [73/100], Train Loss: 0.6900, \n",
      "Epoch [74/100], Train Loss: 0.6860, \n",
      "Epoch [75/100], Train Loss: 0.6884, \n",
      "Epoch [76/100], Train Loss: 0.6881, \n",
      "Epoch [77/100], Train Loss: 0.6884, \n",
      "Epoch [78/100], Train Loss: 0.6867, \n",
      "Epoch [79/100], Train Loss: 0.6875, \n",
      "Epoch [80/100], Train Loss: 0.6866, \n",
      "Epoch [81/100], Train Loss: 0.6867, \n",
      "Epoch [82/100], Train Loss: 0.6869, \n",
      "Epoch [83/100], Train Loss: 0.6884, \n",
      "Epoch [84/100], Train Loss: 0.6873, \n",
      "Epoch [85/100], Train Loss: 0.6873, \n",
      "Epoch [86/100], Train Loss: 0.6870, \n",
      "Epoch [87/100], Train Loss: 0.6875, \n",
      "Epoch [88/100], Train Loss: 0.6867, \n",
      "Epoch [89/100], Train Loss: 0.6885, \n",
      "Epoch [90/100], Train Loss: 0.6868, \n",
      "Epoch [91/100], Train Loss: 0.6874, \n",
      "Epoch [92/100], Train Loss: 0.6876, \n",
      "Epoch [93/100], Train Loss: 0.6854, \n",
      "Epoch [94/100], Train Loss: 0.6880, \n",
      "Epoch [95/100], Train Loss: 0.6859, \n",
      "Epoch [96/100], Train Loss: 0.6862, \n",
      "Epoch [97/100], Train Loss: 0.6871, \n",
      "Epoch [98/100], Train Loss: 0.6879, \n",
      "Epoch [99/100], Train Loss: 0.6857, \n",
      "Epoch [100/100], Train Loss: 0.6879, \n",
      "training loss at last epoch: 0.688\n",
      "seed = 1\n",
      "6000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 39.7471, \n",
      "Epoch [2/100], Train Loss: 11.1618, \n",
      "Epoch [3/100], Train Loss: 9.3620, \n",
      "Epoch [4/100], Train Loss: 7.6513, \n",
      "Epoch [5/100], Train Loss: 6.0251, \n",
      "Epoch [6/100], Train Loss: 4.4968, \n",
      "Epoch [7/100], Train Loss: 3.1999, \n",
      "Epoch [8/100], Train Loss: 1.8251, \n",
      "Epoch [9/100], Train Loss: 4.2542, \n",
      "Epoch [10/100], Train Loss: 3.1212, \n",
      "Epoch [11/100], Train Loss: 2.2437, \n",
      "Epoch [12/100], Train Loss: 2.0052, \n",
      "Epoch [13/100], Train Loss: 12.7099, \n",
      "Epoch [14/100], Train Loss: 11.0631, \n",
      "Epoch [15/100], Train Loss: 9.5365, \n",
      "Epoch [16/100], Train Loss: 8.1299, \n",
      "Epoch [17/100], Train Loss: 6.8449, \n",
      "Epoch [18/100], Train Loss: 5.6584, \n",
      "Epoch [19/100], Train Loss: 4.5806, \n",
      "Epoch [20/100], Train Loss: 3.7448, \n",
      "Epoch [21/100], Train Loss: 3.0343, \n",
      "Epoch [22/100], Train Loss: 2.5529, \n",
      "Epoch [23/100], Train Loss: 1.9101, \n",
      "Epoch [24/100], Train Loss: 1.2097, \n",
      "Epoch [25/100], Train Loss: 4.2755, \n",
      "Epoch [26/100], Train Loss: 3.2740, \n",
      "Epoch [27/100], Train Loss: 2.5347, \n",
      "Epoch [28/100], Train Loss: 1.9367, \n",
      "Epoch [29/100], Train Loss: 1.4772, \n",
      "Epoch [30/100], Train Loss: 1.4459, \n",
      "Epoch [31/100], Train Loss: 1.6120, \n",
      "Epoch [32/100], Train Loss: 1.7335, \n",
      "Epoch [33/100], Train Loss: 1.7492, \n",
      "Epoch [34/100], Train Loss: 4.6628, \n",
      "Epoch [35/100], Train Loss: 3.6943, \n",
      "Epoch [36/100], Train Loss: 2.7792, \n",
      "Epoch [37/100], Train Loss: 2.1106, \n",
      "Epoch [38/100], Train Loss: 1.6356, \n",
      "Epoch [39/100], Train Loss: 1.4010, \n",
      "Epoch [40/100], Train Loss: 1.2625, \n",
      "Epoch [41/100], Train Loss: 1.5116, \n",
      "Epoch [42/100], Train Loss: 1.6360, \n",
      "Epoch [43/100], Train Loss: 9.0420, \n",
      "Epoch [44/100], Train Loss: 8.4986, \n",
      "Epoch [45/100], Train Loss: 7.0010, \n",
      "Epoch [46/100], Train Loss: 6.1215, \n",
      "Epoch [47/100], Train Loss: 5.3138, \n",
      "Epoch [48/100], Train Loss: 4.5451, \n",
      "Epoch [49/100], Train Loss: 3.8338, \n",
      "Epoch [50/100], Train Loss: 3.1526, \n",
      "Epoch [51/100], Train Loss: 2.5980, \n",
      "Epoch [52/100], Train Loss: 2.1183, \n",
      "Epoch [53/100], Train Loss: 1.7102, \n",
      "Epoch [54/100], Train Loss: 1.5304, \n",
      "Epoch [55/100], Train Loss: 1.2846, \n",
      "Epoch [56/100], Train Loss: 1.3931, \n",
      "Epoch [57/100], Train Loss: 1.1341, \n",
      "Epoch [58/100], Train Loss: 0.8201, \n",
      "Epoch [59/100], Train Loss: 1.0774, \n",
      "Epoch [60/100], Train Loss: 3.8442, \n",
      "Epoch [61/100], Train Loss: 3.2552, \n",
      "Epoch [62/100], Train Loss: 2.7196, \n",
      "Epoch [63/100], Train Loss: 2.1976, \n",
      "Epoch [64/100], Train Loss: 1.7067, \n",
      "Epoch [65/100], Train Loss: 1.3119, \n",
      "Epoch [66/100], Train Loss: 1.4887, \n",
      "Epoch [67/100], Train Loss: 1.2532, \n",
      "Epoch [68/100], Train Loss: 1.2898, \n",
      "Epoch [69/100], Train Loss: 1.0940, \n",
      "Epoch [70/100], Train Loss: 1.1608, \n",
      "Epoch [71/100], Train Loss: 1.2023, \n",
      "Epoch [72/100], Train Loss: 1.1654, \n",
      "Epoch [73/100], Train Loss: 0.9950, \n",
      "Epoch [74/100], Train Loss: 0.9997, \n",
      "Epoch [75/100], Train Loss: 1.5955, \n",
      "Epoch [76/100], Train Loss: 1.1526, \n",
      "Epoch [77/100], Train Loss: 0.9988, \n",
      "Epoch [78/100], Train Loss: 1.1524, \n",
      "Epoch [79/100], Train Loss: 1.0055, \n",
      "Epoch [80/100], Train Loss: 0.7924, \n",
      "Epoch [81/100], Train Loss: 1.1177, \n",
      "Epoch [82/100], Train Loss: 1.2705, \n",
      "Epoch [83/100], Train Loss: 2.3316, \n",
      "Epoch [84/100], Train Loss: 1.9020, \n",
      "Epoch [85/100], Train Loss: 1.4984, \n",
      "Epoch [86/100], Train Loss: 1.1189, \n",
      "Epoch [87/100], Train Loss: 0.9735, \n",
      "Epoch [88/100], Train Loss: 1.3293, \n",
      "Epoch [89/100], Train Loss: 0.9334, \n",
      "Epoch [90/100], Train Loss: 1.3825, \n",
      "Epoch [91/100], Train Loss: 1.0068, \n",
      "Epoch [92/100], Train Loss: 0.8554, \n",
      "Epoch [93/100], Train Loss: 1.0216, \n",
      "Epoch [94/100], Train Loss: 1.0876, \n",
      "Epoch [95/100], Train Loss: 1.0631, \n",
      "Epoch [96/100], Train Loss: 0.8689, \n",
      "Epoch [97/100], Train Loss: 1.2941, \n",
      "Epoch [98/100], Train Loss: 0.9398, \n",
      "Epoch [99/100], Train Loss: 1.0832, \n",
      "Epoch [100/100], Train Loss: 0.7485, \n",
      "training loss at last epoch: 0.749\n",
      "Epoch [1/100], Train Loss: 1.6368, \n",
      "Epoch [2/100], Train Loss: 0.6905, \n",
      "Epoch [3/100], Train Loss: 0.6880, \n",
      "Epoch [4/100], Train Loss: 0.6872, \n",
      "Epoch [5/100], Train Loss: 0.6867, \n",
      "Epoch [6/100], Train Loss: 0.6869, \n",
      "Epoch [7/100], Train Loss: 0.6866, \n",
      "Epoch [8/100], Train Loss: 0.6865, \n",
      "Epoch [9/100], Train Loss: 0.6853, \n",
      "Epoch [10/100], Train Loss: 0.6866, \n",
      "Epoch [11/100], Train Loss: 0.6859, \n",
      "Epoch [12/100], Train Loss: 0.6865, \n",
      "Epoch [13/100], Train Loss: 0.6868, \n",
      "Epoch [14/100], Train Loss: 0.6859, \n",
      "Epoch [15/100], Train Loss: 0.6883, \n",
      "Epoch [16/100], Train Loss: 0.6855, \n",
      "Epoch [17/100], Train Loss: 0.6863, \n",
      "Epoch [18/100], Train Loss: 0.6860, \n",
      "Epoch [19/100], Train Loss: 0.6859, \n",
      "Epoch [20/100], Train Loss: 0.6870, \n",
      "Epoch [21/100], Train Loss: 0.6878, \n",
      "Epoch [22/100], Train Loss: 0.6864, \n",
      "Epoch [23/100], Train Loss: 0.6863, \n",
      "Epoch [24/100], Train Loss: 0.6858, \n",
      "Epoch [25/100], Train Loss: 0.6866, \n",
      "Epoch [26/100], Train Loss: 0.6851, \n",
      "Epoch [27/100], Train Loss: 0.6880, \n",
      "Epoch [28/100], Train Loss: 0.6876, \n",
      "Epoch [29/100], Train Loss: 0.6858, \n",
      "Epoch [30/100], Train Loss: 0.6882, \n",
      "Epoch [31/100], Train Loss: 0.6863, \n",
      "Epoch [32/100], Train Loss: 0.6851, \n",
      "Epoch [33/100], Train Loss: 0.6854, \n",
      "Epoch [34/100], Train Loss: 0.6864, \n",
      "Epoch [35/100], Train Loss: 0.6871, \n",
      "Epoch [36/100], Train Loss: 0.6877, \n",
      "Epoch [37/100], Train Loss: 0.6853, \n",
      "Epoch [38/100], Train Loss: 0.6863, \n",
      "Epoch [39/100], Train Loss: 0.6864, \n",
      "Epoch [40/100], Train Loss: 0.6868, \n",
      "Epoch [41/100], Train Loss: 0.6859, \n",
      "Epoch [42/100], Train Loss: 0.6872, \n",
      "Epoch [43/100], Train Loss: 0.6860, \n",
      "Epoch [44/100], Train Loss: 0.6867, \n",
      "Epoch [45/100], Train Loss: 0.6869, \n",
      "Epoch [46/100], Train Loss: 0.6875, \n",
      "Epoch [47/100], Train Loss: 0.6851, \n",
      "Epoch [48/100], Train Loss: 0.6865, \n",
      "Epoch [49/100], Train Loss: 0.6865, \n",
      "Epoch [50/100], Train Loss: 0.6855, \n",
      "Epoch [51/100], Train Loss: 0.6862, \n",
      "Epoch [52/100], Train Loss: 0.6870, \n",
      "Epoch [53/100], Train Loss: 0.6866, \n",
      "Epoch [54/100], Train Loss: 0.6854, \n",
      "Epoch [55/100], Train Loss: 0.6870, \n",
      "Epoch [56/100], Train Loss: 0.6864, \n",
      "Epoch [57/100], Train Loss: 0.6858, \n",
      "Epoch [58/100], Train Loss: 0.6853, \n",
      "Epoch [59/100], Train Loss: 0.6865, \n",
      "Epoch [60/100], Train Loss: 0.6861, \n",
      "Epoch [61/100], Train Loss: 0.6859, \n",
      "Epoch [62/100], Train Loss: 0.6861, \n",
      "Epoch [63/100], Train Loss: 0.6853, \n",
      "Epoch [64/100], Train Loss: 0.6879, \n",
      "Epoch [65/100], Train Loss: 0.6859, \n",
      "Epoch [66/100], Train Loss: 0.6867, \n",
      "Epoch [67/100], Train Loss: 0.6872, \n",
      "Epoch [68/100], Train Loss: 0.6859, \n",
      "Epoch [69/100], Train Loss: 0.6851, \n",
      "Epoch [70/100], Train Loss: 0.6883, \n",
      "Epoch [71/100], Train Loss: 0.6856, \n",
      "Epoch [72/100], Train Loss: 0.6876, \n",
      "Epoch [73/100], Train Loss: 0.6868, \n",
      "Epoch [74/100], Train Loss: 0.6869, \n",
      "Epoch [75/100], Train Loss: 0.6874, \n",
      "Epoch [76/100], Train Loss: 0.6868, \n",
      "Epoch [77/100], Train Loss: 0.6854, \n",
      "Epoch [78/100], Train Loss: 0.6870, \n",
      "Epoch [79/100], Train Loss: 0.6868, \n",
      "Epoch [80/100], Train Loss: 0.6860, \n",
      "Epoch [81/100], Train Loss: 0.6866, \n",
      "Epoch [82/100], Train Loss: 0.6852, \n",
      "Epoch [83/100], Train Loss: 0.6867, \n",
      "Epoch [84/100], Train Loss: 0.6867, \n",
      "Epoch [85/100], Train Loss: 0.6876, \n",
      "Epoch [86/100], Train Loss: 0.6853, \n",
      "Epoch [87/100], Train Loss: 0.6865, \n",
      "Epoch [88/100], Train Loss: 0.6870, \n",
      "Epoch [89/100], Train Loss: 0.6857, \n",
      "Epoch [90/100], Train Loss: 0.6873, \n",
      "Epoch [91/100], Train Loss: 0.6865, \n",
      "Epoch [92/100], Train Loss: 0.6864, \n",
      "Epoch [93/100], Train Loss: 0.6872, \n",
      "Epoch [94/100], Train Loss: 0.6864, \n",
      "Epoch [95/100], Train Loss: 0.6865, \n",
      "Epoch [96/100], Train Loss: 0.6864, \n",
      "Epoch [97/100], Train Loss: 0.6873, \n",
      "Epoch [98/100], Train Loss: 0.6878, \n",
      "Epoch [99/100], Train Loss: 0.6858, \n",
      "Epoch [100/100], Train Loss: 0.6872, \n",
      "training loss at last epoch: 0.687\n",
      "seed = 2\n",
      "6000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 77.5511, \n",
      "Epoch [2/100], Train Loss: 20.5578, \n",
      "Epoch [3/100], Train Loss: 23.7541, \n",
      "Epoch [4/100], Train Loss: 45.1967, \n",
      "Epoch [5/100], Train Loss: 13.4797, \n",
      "Epoch [6/100], Train Loss: 44.9379, \n",
      "Epoch [7/100], Train Loss: 24.9243, \n",
      "Epoch [8/100], Train Loss: 74.0350, \n",
      "Epoch [9/100], Train Loss: 29.8069, \n",
      "Epoch [10/100], Train Loss: 10.5572, \n",
      "Epoch [11/100], Train Loss: 14.7960, \n",
      "Epoch [12/100], Train Loss: 43.8689, \n",
      "Epoch [13/100], Train Loss: 14.2970, \n",
      "Epoch [14/100], Train Loss: 10.7170, \n",
      "Epoch [15/100], Train Loss: 47.2111, \n",
      "Epoch [16/100], Train Loss: 17.9242, \n",
      "Epoch [17/100], Train Loss: 7.8078, \n",
      "Epoch [18/100], Train Loss: 9.3163, \n",
      "Epoch [19/100], Train Loss: 9.6683, \n",
      "Epoch [20/100], Train Loss: 29.2645, \n",
      "Epoch [21/100], Train Loss: 6.2095, \n",
      "Epoch [22/100], Train Loss: 8.5264, \n",
      "Epoch [23/100], Train Loss: 7.0884, \n",
      "Epoch [24/100], Train Loss: 9.8108, \n",
      "Epoch [25/100], Train Loss: 48.4992, \n",
      "Epoch [26/100], Train Loss: 25.4806, \n",
      "Epoch [27/100], Train Loss: 8.6155, \n",
      "Epoch [28/100], Train Loss: 8.9187, \n",
      "Epoch [29/100], Train Loss: 8.1831, \n",
      "Epoch [30/100], Train Loss: 6.5851, \n",
      "Epoch [31/100], Train Loss: 5.8283, \n",
      "Epoch [32/100], Train Loss: 6.2861, \n",
      "Epoch [33/100], Train Loss: 6.8746, \n",
      "Epoch [34/100], Train Loss: 9.4654, \n",
      "Epoch [35/100], Train Loss: 6.4211, \n",
      "Epoch [36/100], Train Loss: 6.5749, \n",
      "Epoch [37/100], Train Loss: 2.9406, \n",
      "Epoch [38/100], Train Loss: 5.3223, \n",
      "Epoch [39/100], Train Loss: 3.9255, \n",
      "Epoch [40/100], Train Loss: 2.9776, \n",
      "Epoch [41/100], Train Loss: 7.0580, \n",
      "Epoch [42/100], Train Loss: 3.7493, \n",
      "Epoch [43/100], Train Loss: 3.2154, \n",
      "Epoch [44/100], Train Loss: 1.3691, \n",
      "Epoch [45/100], Train Loss: 2.9222, \n",
      "Epoch [46/100], Train Loss: 2.6245, \n",
      "Epoch [47/100], Train Loss: 2.8254, \n",
      "Epoch [48/100], Train Loss: 3.0444, \n",
      "Epoch [49/100], Train Loss: 2.5240, \n",
      "Epoch [50/100], Train Loss: 2.4416, \n",
      "Epoch [51/100], Train Loss: 3.5149, \n",
      "Epoch [52/100], Train Loss: 2.4544, \n",
      "Epoch [53/100], Train Loss: 1.8358, \n",
      "Epoch [54/100], Train Loss: 4.8050, \n",
      "Epoch [55/100], Train Loss: 4.2438, \n",
      "Epoch [56/100], Train Loss: 4.9121, \n",
      "Epoch [57/100], Train Loss: 3.0783, \n",
      "Epoch [58/100], Train Loss: 3.4202, \n",
      "Epoch [59/100], Train Loss: 2.9671, \n",
      "Epoch [60/100], Train Loss: 2.4287, \n",
      "Epoch [61/100], Train Loss: 2.7085, \n",
      "Epoch [62/100], Train Loss: 3.7820, \n",
      "Epoch [63/100], Train Loss: 3.3354, \n",
      "Epoch [64/100], Train Loss: 1.8305, \n",
      "Epoch [65/100], Train Loss: 3.4772, \n",
      "Epoch [66/100], Train Loss: 4.6685, \n",
      "Epoch [67/100], Train Loss: 3.1937, \n",
      "Epoch [68/100], Train Loss: 2.7072, \n",
      "Epoch [69/100], Train Loss: 2.5673, \n",
      "Epoch [70/100], Train Loss: 4.3296, \n",
      "Epoch [71/100], Train Loss: 2.2004, \n",
      "Epoch [72/100], Train Loss: 4.1115, \n",
      "Epoch [73/100], Train Loss: 2.2363, \n",
      "Epoch [74/100], Train Loss: 2.1746, \n",
      "Epoch [75/100], Train Loss: 2.4585, \n",
      "Epoch [76/100], Train Loss: 2.8607, \n",
      "Epoch [77/100], Train Loss: 1.2481, \n",
      "Epoch [78/100], Train Loss: 3.5804, \n",
      "Epoch [79/100], Train Loss: 2.5335, \n",
      "Epoch [80/100], Train Loss: 3.0299, \n",
      "Epoch [81/100], Train Loss: 2.5058, \n",
      "Epoch [82/100], Train Loss: 1.2627, \n",
      "Epoch [83/100], Train Loss: 1.9471, \n",
      "Epoch [84/100], Train Loss: 1.8167, \n",
      "Epoch [85/100], Train Loss: 2.5668, \n",
      "Epoch [86/100], Train Loss: 1.5700, \n",
      "Epoch [87/100], Train Loss: 1.9633, \n",
      "Epoch [88/100], Train Loss: 2.7348, \n",
      "Epoch [89/100], Train Loss: 2.4130, \n",
      "Epoch [90/100], Train Loss: 2.4729, \n",
      "Epoch [91/100], Train Loss: 2.6980, \n",
      "Epoch [92/100], Train Loss: 2.8898, \n",
      "Epoch [93/100], Train Loss: 1.6837, \n",
      "Epoch [94/100], Train Loss: 1.8088, \n",
      "Epoch [95/100], Train Loss: 2.7439, \n",
      "Epoch [96/100], Train Loss: 2.1765, \n",
      "Epoch [97/100], Train Loss: 2.4033, \n",
      "Epoch [98/100], Train Loss: 1.4624, \n",
      "Epoch [99/100], Train Loss: 2.8313, \n",
      "Epoch [100/100], Train Loss: 2.2565, \n",
      "training loss at last epoch: 2.256\n",
      "Epoch [1/100], Train Loss: 4.8496, \n",
      "Epoch [2/100], Train Loss: 0.7084, \n",
      "Epoch [3/100], Train Loss: 0.6862, \n",
      "Epoch [4/100], Train Loss: 0.6864, \n",
      "Epoch [5/100], Train Loss: 0.6869, \n",
      "Epoch [6/100], Train Loss: 0.6856, \n",
      "Epoch [7/100], Train Loss: 0.6870, \n",
      "Epoch [8/100], Train Loss: 0.6861, \n",
      "Epoch [9/100], Train Loss: 0.6852, \n",
      "Epoch [10/100], Train Loss: 0.6867, \n",
      "Epoch [11/100], Train Loss: 0.6866, \n",
      "Epoch [12/100], Train Loss: 0.6863, \n",
      "Epoch [13/100], Train Loss: 0.6853, \n",
      "Epoch [14/100], Train Loss: 0.6865, \n",
      "Epoch [15/100], Train Loss: 0.6848, \n",
      "Epoch [16/100], Train Loss: 0.6850, \n",
      "Epoch [17/100], Train Loss: 0.6858, \n",
      "Epoch [18/100], Train Loss: 0.6859, \n",
      "Epoch [19/100], Train Loss: 0.6854, \n",
      "Epoch [20/100], Train Loss: 0.6857, \n",
      "Epoch [21/100], Train Loss: 0.6867, \n",
      "Epoch [22/100], Train Loss: 0.6858, \n",
      "Epoch [23/100], Train Loss: 0.6854, \n",
      "Epoch [24/100], Train Loss: 0.6842, \n",
      "Epoch [25/100], Train Loss: 0.6848, \n",
      "Epoch [26/100], Train Loss: 0.6858, \n",
      "Epoch [27/100], Train Loss: 0.6863, \n",
      "Epoch [28/100], Train Loss: 0.6860, \n",
      "Epoch [29/100], Train Loss: 0.6867, \n",
      "Epoch [30/100], Train Loss: 0.6858, \n",
      "Epoch [31/100], Train Loss: 0.6857, \n",
      "Epoch [32/100], Train Loss: 0.6841, \n",
      "Epoch [33/100], Train Loss: 0.6863, \n",
      "Epoch [34/100], Train Loss: 0.6855, \n",
      "Epoch [35/100], Train Loss: 0.6852, \n",
      "Epoch [36/100], Train Loss: 0.6850, \n",
      "Epoch [37/100], Train Loss: 0.6867, \n",
      "Epoch [38/100], Train Loss: 0.6856, \n",
      "Epoch [39/100], Train Loss: 0.6863, \n",
      "Epoch [40/100], Train Loss: 0.6871, \n",
      "Epoch [41/100], Train Loss: 0.6863, \n",
      "Epoch [42/100], Train Loss: 0.6868, \n",
      "Epoch [43/100], Train Loss: 0.6853, \n",
      "Epoch [44/100], Train Loss: 0.6849, \n",
      "Epoch [45/100], Train Loss: 0.6861, \n",
      "Epoch [46/100], Train Loss: 0.6860, \n",
      "Epoch [47/100], Train Loss: 0.6855, \n",
      "Epoch [48/100], Train Loss: 0.6855, \n",
      "Epoch [49/100], Train Loss: 0.6866, \n",
      "Epoch [50/100], Train Loss: 0.6850, \n",
      "Epoch [51/100], Train Loss: 0.6869, \n",
      "Epoch [52/100], Train Loss: 0.6857, \n",
      "Epoch [53/100], Train Loss: 0.6857, \n",
      "Epoch [54/100], Train Loss: 0.6878, \n",
      "Epoch [55/100], Train Loss: 0.6857, \n",
      "Epoch [56/100], Train Loss: 0.6851, \n",
      "Epoch [57/100], Train Loss: 0.6840, \n",
      "Epoch [58/100], Train Loss: 0.6845, \n",
      "Epoch [59/100], Train Loss: 0.6853, \n",
      "Epoch [60/100], Train Loss: 0.6861, \n",
      "Epoch [61/100], Train Loss: 0.6848, \n",
      "Epoch [62/100], Train Loss: 0.6836, \n",
      "Epoch [63/100], Train Loss: 0.6862, \n",
      "Epoch [64/100], Train Loss: 0.6842, \n",
      "Epoch [65/100], Train Loss: 0.6817, \n",
      "Epoch [66/100], Train Loss: 0.6855, \n",
      "Epoch [67/100], Train Loss: 0.6858, \n",
      "Epoch [68/100], Train Loss: 0.6872, \n",
      "Epoch [69/100], Train Loss: 0.6850, \n",
      "Epoch [70/100], Train Loss: 0.6849, \n",
      "Epoch [71/100], Train Loss: 0.6834, \n",
      "Epoch [72/100], Train Loss: 0.6835, \n",
      "Epoch [73/100], Train Loss: 0.6865, \n",
      "Epoch [74/100], Train Loss: 0.6854, \n",
      "Epoch [75/100], Train Loss: 0.6869, \n",
      "Epoch [76/100], Train Loss: 0.6868, \n",
      "Epoch [77/100], Train Loss: 0.6862, \n",
      "Epoch [78/100], Train Loss: 0.6871, \n",
      "Epoch [79/100], Train Loss: 0.6867, \n",
      "Epoch [80/100], Train Loss: 0.6869, \n",
      "Epoch [81/100], Train Loss: 0.6841, \n",
      "Epoch [82/100], Train Loss: 0.6868, \n",
      "Epoch [83/100], Train Loss: 0.6857, \n",
      "Epoch [84/100], Train Loss: 0.6855, \n",
      "Epoch [85/100], Train Loss: 0.6845, \n",
      "Epoch [86/100], Train Loss: 0.6869, \n",
      "Epoch [87/100], Train Loss: 0.6850, \n",
      "Epoch [88/100], Train Loss: 0.6874, \n",
      "Epoch [89/100], Train Loss: 0.6857, \n",
      "Epoch [90/100], Train Loss: 0.6860, \n",
      "Epoch [91/100], Train Loss: 0.6881, \n",
      "Epoch [92/100], Train Loss: 0.6857, \n",
      "Epoch [93/100], Train Loss: 0.6876, \n",
      "Epoch [94/100], Train Loss: 0.6866, \n",
      "Epoch [95/100], Train Loss: 0.6879, \n",
      "Epoch [96/100], Train Loss: 0.6849, \n",
      "Epoch [97/100], Train Loss: 0.6861, \n",
      "Epoch [98/100], Train Loss: 0.6856, \n",
      "Epoch [99/100], Train Loss: 0.6864, \n",
      "Epoch [100/100], Train Loss: 0.6868, \n",
      "training loss at last epoch: 0.687\n",
      "time t = 200\n",
      "seed = 0\n",
      "8000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 40.9828, \n",
      "Epoch [2/100], Train Loss: 11.1111, \n",
      "Epoch [3/100], Train Loss: 6.9285, \n",
      "Epoch [4/100], Train Loss: 54.9574, \n",
      "Epoch [5/100], Train Loss: 110.8143, \n",
      "Epoch [6/100], Train Loss: 111.2026, \n",
      "Epoch [7/100], Train Loss: 375.6627, \n",
      "Epoch [8/100], Train Loss: 274.9168, \n",
      "Epoch [9/100], Train Loss: 177.8699, \n",
      "Epoch [10/100], Train Loss: 87.3104, \n",
      "Epoch [11/100], Train Loss: 147.5854, \n",
      "Epoch [12/100], Train Loss: 95.8054, \n",
      "Epoch [13/100], Train Loss: 393.8015, \n",
      "Epoch [14/100], Train Loss: 300.4825, \n",
      "Epoch [15/100], Train Loss: 212.0235, \n",
      "Epoch [16/100], Train Loss: 126.9762, \n",
      "Epoch [17/100], Train Loss: 52.1778, \n",
      "Epoch [18/100], Train Loss: 436.0992, \n",
      "Epoch [19/100], Train Loss: 349.6229, \n",
      "Epoch [20/100], Train Loss: 266.2230, \n",
      "Epoch [21/100], Train Loss: 188.6579, \n",
      "Epoch [22/100], Train Loss: 113.5450, \n",
      "Epoch [23/100], Train Loss: 62.7714, \n",
      "Epoch [24/100], Train Loss: 137.9825, \n",
      "Epoch [25/100], Train Loss: 66.8415, \n",
      "Epoch [26/100], Train Loss: 94.5731, \n",
      "Epoch [27/100], Train Loss: 25.4398, \n",
      "Epoch [28/100], Train Loss: 40.3839, \n",
      "Epoch [29/100], Train Loss: 126.5998, \n",
      "Epoch [30/100], Train Loss: 62.6886, \n",
      "Epoch [31/100], Train Loss: 65.8685, \n",
      "Epoch [32/100], Train Loss: 46.2698, \n",
      "Epoch [33/100], Train Loss: 77.0681, \n",
      "Epoch [34/100], Train Loss: 50.2691, \n",
      "Epoch [35/100], Train Loss: 91.0754, \n",
      "Epoch [36/100], Train Loss: 60.3265, \n",
      "Epoch [37/100], Train Loss: 122.7401, \n",
      "Epoch [38/100], Train Loss: 67.2540, \n",
      "Epoch [39/100], Train Loss: 28.3518, \n",
      "Epoch [40/100], Train Loss: 61.0566, \n",
      "Epoch [41/100], Train Loss: 40.1410, \n",
      "Epoch [42/100], Train Loss: 188.0814, \n",
      "Epoch [43/100], Train Loss: 127.8467, \n",
      "Epoch [44/100], Train Loss: 70.1195, \n",
      "Epoch [45/100], Train Loss: 25.6281, \n",
      "Epoch [46/100], Train Loss: 356.9695, \n",
      "Epoch [47/100], Train Loss: 294.5879, \n",
      "Epoch [48/100], Train Loss: 236.2492, \n",
      "Epoch [49/100], Train Loss: 181.7254, \n",
      "Epoch [50/100], Train Loss: 129.5026, \n",
      "Epoch [51/100], Train Loss: 79.7740, \n",
      "Epoch [52/100], Train Loss: 43.3312, \n",
      "Epoch [53/100], Train Loss: 31.7760, \n",
      "Epoch [54/100], Train Loss: 53.0225, \n",
      "Epoch [55/100], Train Loss: 25.1166, \n",
      "Epoch [56/100], Train Loss: 22.7545, \n",
      "Epoch [57/100], Train Loss: 38.1862, \n",
      "Epoch [58/100], Train Loss: 32.5277, \n",
      "Epoch [59/100], Train Loss: 23.4001, \n",
      "Epoch [60/100], Train Loss: 51.1209, \n",
      "Epoch [61/100], Train Loss: 35.2330, \n",
      "Epoch [62/100], Train Loss: 80.8036, \n",
      "Epoch [63/100], Train Loss: 40.4898, \n",
      "Epoch [64/100], Train Loss: 34.5821, \n",
      "Epoch [65/100], Train Loss: 29.5993, \n",
      "Epoch [66/100], Train Loss: 63.4548, \n",
      "Epoch [67/100], Train Loss: 23.1813, \n",
      "Epoch [68/100], Train Loss: 40.0127, \n",
      "Epoch [69/100], Train Loss: 80.7371, \n",
      "Epoch [70/100], Train Loss: 41.0827, \n",
      "Epoch [71/100], Train Loss: 6.9385, \n",
      "Epoch [72/100], Train Loss: 34.4689, \n",
      "Epoch [73/100], Train Loss: 32.2007, \n",
      "Epoch [74/100], Train Loss: 22.9639, \n",
      "Epoch [75/100], Train Loss: 33.9964, \n",
      "Epoch [76/100], Train Loss: 15.6366, \n",
      "Epoch [77/100], Train Loss: 50.5863, \n",
      "Epoch [78/100], Train Loss: 30.3049, \n",
      "Epoch [79/100], Train Loss: 33.4192, \n",
      "Epoch [80/100], Train Loss: 35.5840, \n",
      "Epoch [81/100], Train Loss: 13.4634, \n",
      "Epoch [82/100], Train Loss: 70.8171, \n",
      "Epoch [83/100], Train Loss: 35.1918, \n",
      "Epoch [84/100], Train Loss: 27.5724, \n",
      "Epoch [85/100], Train Loss: 45.0513, \n",
      "Epoch [86/100], Train Loss: 13.6162, \n",
      "Epoch [87/100], Train Loss: 27.1733, \n",
      "Epoch [88/100], Train Loss: 33.8214, \n",
      "Epoch [89/100], Train Loss: 32.7570, \n",
      "Epoch [90/100], Train Loss: 22.0227, \n",
      "Epoch [91/100], Train Loss: 24.0967, \n",
      "Epoch [92/100], Train Loss: 7.3100, \n",
      "Epoch [93/100], Train Loss: 23.9417, \n",
      "Epoch [94/100], Train Loss: 14.7266, \n",
      "Epoch [95/100], Train Loss: 25.3474, \n",
      "Epoch [96/100], Train Loss: 31.4020, \n",
      "Epoch [97/100], Train Loss: 52.7134, \n",
      "Epoch [98/100], Train Loss: 24.3885, \n",
      "Epoch [99/100], Train Loss: 18.4385, \n",
      "Epoch [100/100], Train Loss: 22.1564, \n",
      "training loss at last epoch: 22.156\n",
      "Epoch [1/100], Train Loss: 3.9812, \n",
      "Epoch [2/100], Train Loss: 0.8000, \n",
      "Epoch [3/100], Train Loss: 0.6960, \n",
      "Epoch [4/100], Train Loss: 0.6892, \n",
      "Epoch [5/100], Train Loss: 0.6888, \n",
      "Epoch [6/100], Train Loss: 0.6890, \n",
      "Epoch [7/100], Train Loss: 0.6881, \n",
      "Epoch [8/100], Train Loss: 0.6886, \n",
      "Epoch [9/100], Train Loss: 0.6883, \n",
      "Epoch [10/100], Train Loss: 0.6883, \n",
      "Epoch [11/100], Train Loss: 0.6896, \n",
      "Epoch [12/100], Train Loss: 0.6885, \n",
      "Epoch [13/100], Train Loss: 0.6886, \n",
      "Epoch [14/100], Train Loss: 0.6879, \n",
      "Epoch [15/100], Train Loss: 0.6890, \n",
      "Epoch [16/100], Train Loss: 0.6885, \n",
      "Epoch [17/100], Train Loss: 0.6877, \n",
      "Epoch [18/100], Train Loss: 0.6877, \n",
      "Epoch [19/100], Train Loss: 0.6896, \n",
      "Epoch [20/100], Train Loss: 0.6878, \n",
      "Epoch [21/100], Train Loss: 0.6886, \n",
      "Epoch [22/100], Train Loss: 0.7419, \n",
      "Epoch [23/100], Train Loss: 0.6893, \n",
      "Epoch [24/100], Train Loss: 0.6880, \n",
      "Epoch [25/100], Train Loss: 0.6888, \n",
      "Epoch [26/100], Train Loss: 0.6884, \n",
      "Epoch [27/100], Train Loss: 0.6879, \n",
      "Epoch [28/100], Train Loss: 0.6882, \n",
      "Epoch [29/100], Train Loss: 0.6900, \n",
      "Epoch [30/100], Train Loss: 0.6880, \n",
      "Epoch [31/100], Train Loss: 0.6883, \n",
      "Epoch [32/100], Train Loss: 0.6881, \n",
      "Epoch [33/100], Train Loss: 0.6876, \n",
      "Epoch [34/100], Train Loss: 0.6899, \n",
      "Epoch [35/100], Train Loss: 0.6895, \n",
      "Epoch [36/100], Train Loss: 0.6889, \n",
      "Epoch [37/100], Train Loss: 0.6892, \n",
      "Epoch [38/100], Train Loss: 0.6878, \n",
      "Epoch [39/100], Train Loss: 0.6893, \n",
      "Epoch [40/100], Train Loss: 0.6887, \n",
      "Epoch [41/100], Train Loss: 0.6880, \n",
      "Epoch [42/100], Train Loss: 0.6885, \n",
      "Epoch [43/100], Train Loss: 0.6890, \n",
      "Epoch [44/100], Train Loss: 0.6876, \n",
      "Epoch [45/100], Train Loss: 0.6887, \n",
      "Epoch [46/100], Train Loss: 0.6879, \n",
      "Epoch [47/100], Train Loss: 0.6877, \n",
      "Epoch [48/100], Train Loss: 0.6878, \n",
      "Epoch [49/100], Train Loss: 0.6888, \n",
      "Epoch [50/100], Train Loss: 0.6882, \n",
      "Epoch [51/100], Train Loss: 0.6876, \n",
      "Epoch [52/100], Train Loss: 0.6880, \n",
      "Epoch [53/100], Train Loss: 0.6882, \n",
      "Epoch [54/100], Train Loss: 0.6878, \n",
      "Epoch [55/100], Train Loss: 0.6881, \n",
      "Epoch [56/100], Train Loss: 0.6889, \n",
      "Epoch [57/100], Train Loss: 0.6882, \n",
      "Epoch [58/100], Train Loss: 0.6881, \n",
      "Epoch [59/100], Train Loss: 0.6889, \n",
      "Epoch [60/100], Train Loss: 0.6881, \n",
      "Epoch [61/100], Train Loss: 0.6892, \n",
      "Epoch [62/100], Train Loss: 0.6893, \n",
      "Epoch [63/100], Train Loss: 0.6880, \n",
      "Epoch [64/100], Train Loss: 0.6877, \n",
      "Epoch [65/100], Train Loss: 0.6878, \n",
      "Epoch [66/100], Train Loss: 0.6881, \n",
      "Epoch [67/100], Train Loss: 0.6876, \n",
      "Epoch [68/100], Train Loss: 0.6877, \n",
      "Epoch [69/100], Train Loss: 0.6881, \n",
      "Epoch [70/100], Train Loss: 0.6883, \n",
      "Epoch [71/100], Train Loss: 0.6881, \n",
      "Epoch [72/100], Train Loss: 0.6881, \n",
      "Epoch [73/100], Train Loss: 0.6876, \n",
      "Epoch [74/100], Train Loss: 0.6875, \n",
      "Epoch [75/100], Train Loss: 0.6872, \n",
      "Epoch [76/100], Train Loss: 0.6872, \n",
      "Epoch [77/100], Train Loss: 0.6874, \n",
      "Epoch [78/100], Train Loss: 0.6863, \n",
      "Epoch [79/100], Train Loss: 0.6876, \n",
      "Epoch [80/100], Train Loss: 0.6871, \n",
      "Epoch [81/100], Train Loss: 0.6861, \n",
      "Epoch [82/100], Train Loss: 0.6881, \n",
      "Epoch [83/100], Train Loss: 0.6889, \n",
      "Epoch [84/100], Train Loss: 0.6890, \n",
      "Epoch [85/100], Train Loss: 0.6873, \n",
      "Epoch [86/100], Train Loss: 0.6874, \n",
      "Epoch [87/100], Train Loss: 0.6869, \n",
      "Epoch [88/100], Train Loss: 0.6872, \n",
      "Epoch [89/100], Train Loss: 0.6879, \n",
      "Epoch [90/100], Train Loss: 0.6875, \n",
      "Epoch [91/100], Train Loss: 0.6878, \n",
      "Epoch [92/100], Train Loss: 0.6885, \n",
      "Epoch [93/100], Train Loss: 0.6886, \n",
      "Epoch [94/100], Train Loss: 0.6873, \n",
      "Epoch [95/100], Train Loss: 0.6873, \n",
      "Epoch [96/100], Train Loss: 0.6879, \n",
      "Epoch [97/100], Train Loss: 0.6890, \n",
      "Epoch [98/100], Train Loss: 0.6882, \n",
      "Epoch [99/100], Train Loss: 0.6877, \n",
      "Epoch [100/100], Train Loss: 0.6870, \n",
      "training loss at last epoch: 0.687\n",
      "seed = 1\n",
      "8000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 13.5842, \n",
      "Epoch [2/100], Train Loss: 4.5506, \n",
      "Epoch [3/100], Train Loss: 2.7747, \n",
      "Epoch [4/100], Train Loss: 3.3533, \n",
      "Epoch [5/100], Train Loss: 16.5139, \n",
      "Epoch [6/100], Train Loss: 14.4306, \n",
      "Epoch [7/100], Train Loss: 12.4339, \n",
      "Epoch [8/100], Train Loss: 10.6764, \n",
      "Epoch [9/100], Train Loss: 9.1009, \n",
      "Epoch [10/100], Train Loss: 7.6013, \n",
      "Epoch [11/100], Train Loss: 6.1913, \n",
      "Epoch [12/100], Train Loss: 4.9784, \n",
      "Epoch [13/100], Train Loss: 3.9111, \n",
      "Epoch [14/100], Train Loss: 2.8454, \n",
      "Epoch [15/100], Train Loss: 2.4973, \n",
      "Epoch [16/100], Train Loss: 2.2795, \n",
      "Epoch [17/100], Train Loss: 1.9090, \n",
      "Epoch [18/100], Train Loss: 2.5600, \n",
      "Epoch [19/100], Train Loss: 1.8615, \n",
      "Epoch [20/100], Train Loss: 1.6804, \n",
      "Epoch [21/100], Train Loss: 2.2497, \n",
      "Epoch [22/100], Train Loss: 6.8934, \n",
      "Epoch [23/100], Train Loss: 5.6506, \n",
      "Epoch [24/100], Train Loss: 4.5498, \n",
      "Epoch [25/100], Train Loss: 3.5129, \n",
      "Epoch [26/100], Train Loss: 2.6778, \n",
      "Epoch [27/100], Train Loss: 1.9965, \n",
      "Epoch [28/100], Train Loss: 1.6868, \n",
      "Epoch [29/100], Train Loss: 1.2345, \n",
      "Epoch [30/100], Train Loss: 1.1038, \n",
      "Epoch [31/100], Train Loss: 1.6567, \n",
      "Epoch [32/100], Train Loss: 1.4332, \n",
      "Epoch [33/100], Train Loss: 1.7187, \n",
      "Epoch [34/100], Train Loss: 1.0260, \n",
      "Epoch [35/100], Train Loss: 7.6160, \n",
      "Epoch [36/100], Train Loss: 6.5029, \n",
      "Epoch [37/100], Train Loss: 5.4775, \n",
      "Epoch [38/100], Train Loss: 4.5994, \n",
      "Epoch [39/100], Train Loss: 3.7691, \n",
      "Epoch [40/100], Train Loss: 2.9740, \n",
      "Epoch [41/100], Train Loss: 2.3232, \n",
      "Epoch [42/100], Train Loss: 1.9345, \n",
      "Epoch [43/100], Train Loss: 1.5688, \n",
      "Epoch [44/100], Train Loss: 1.7949, \n",
      "Epoch [45/100], Train Loss: 1.4727, \n",
      "Epoch [46/100], Train Loss: 1.2149, \n",
      "Epoch [47/100], Train Loss: 1.2814, \n",
      "Epoch [48/100], Train Loss: 1.4731, \n",
      "Epoch [49/100], Train Loss: 1.1093, \n",
      "Epoch [50/100], Train Loss: 2.7935, \n",
      "Epoch [51/100], Train Loss: 2.0595, \n",
      "Epoch [52/100], Train Loss: 1.4323, \n",
      "Epoch [53/100], Train Loss: 1.2798, \n",
      "Epoch [54/100], Train Loss: 1.2570, \n",
      "Epoch [55/100], Train Loss: 1.4515, \n",
      "Epoch [56/100], Train Loss: 0.9816, \n",
      "Epoch [57/100], Train Loss: 1.5895, \n",
      "Epoch [58/100], Train Loss: 1.1717, \n",
      "Epoch [59/100], Train Loss: 1.6366, \n",
      "Epoch [60/100], Train Loss: 1.3072, \n",
      "Epoch [61/100], Train Loss: 1.2140, \n",
      "Epoch [62/100], Train Loss: 1.0275, \n",
      "Epoch [63/100], Train Loss: 5.4362, \n",
      "Epoch [64/100], Train Loss: 4.7017, \n",
      "Epoch [65/100], Train Loss: 4.0291, \n",
      "Epoch [66/100], Train Loss: 3.4600, \n",
      "Epoch [67/100], Train Loss: 2.9363, \n",
      "Epoch [68/100], Train Loss: 2.4288, \n",
      "Epoch [69/100], Train Loss: 1.9520, \n",
      "Epoch [70/100], Train Loss: 1.5385, \n",
      "Epoch [71/100], Train Loss: 1.1690, \n",
      "Epoch [72/100], Train Loss: 1.3595, \n",
      "Epoch [73/100], Train Loss: 1.2009, \n",
      "Epoch [74/100], Train Loss: 0.8787, \n",
      "Epoch [75/100], Train Loss: 0.9466, \n",
      "Epoch [76/100], Train Loss: 0.9845, \n",
      "Epoch [77/100], Train Loss: 1.1447, \n",
      "Epoch [78/100], Train Loss: 0.9498, \n",
      "Epoch [79/100], Train Loss: 1.0754, \n",
      "Epoch [80/100], Train Loss: 1.0249, \n",
      "Epoch [81/100], Train Loss: 1.2001, \n",
      "Epoch [82/100], Train Loss: 0.8674, \n",
      "Epoch [83/100], Train Loss: 1.0249, \n",
      "Epoch [84/100], Train Loss: 0.9979, \n",
      "Epoch [85/100], Train Loss: 0.9866, \n",
      "Epoch [86/100], Train Loss: 0.9529, \n",
      "Epoch [87/100], Train Loss: 1.7866, \n",
      "Epoch [88/100], Train Loss: 1.1670, \n",
      "Epoch [89/100], Train Loss: 0.8189, \n",
      "Epoch [90/100], Train Loss: 1.4318, \n",
      "Epoch [91/100], Train Loss: 1.0020, \n",
      "Epoch [92/100], Train Loss: 0.9547, \n",
      "Epoch [93/100], Train Loss: 1.0070, \n",
      "Epoch [94/100], Train Loss: 0.9739, \n",
      "Epoch [95/100], Train Loss: 0.8402, \n",
      "Epoch [96/100], Train Loss: 0.8387, \n",
      "Epoch [97/100], Train Loss: 1.0407, \n",
      "Epoch [98/100], Train Loss: 1.0214, \n",
      "Epoch [99/100], Train Loss: 0.8760, \n",
      "Epoch [100/100], Train Loss: 0.7293, \n",
      "training loss at last epoch: 0.729\n",
      "Epoch [1/100], Train Loss: 6.2698, \n",
      "Epoch [2/100], Train Loss: 0.6892, \n",
      "Epoch [3/100], Train Loss: 0.6889, \n",
      "Epoch [4/100], Train Loss: 0.6889, \n",
      "Epoch [5/100], Train Loss: 0.6886, \n",
      "Epoch [6/100], Train Loss: 0.6878, \n",
      "Epoch [7/100], Train Loss: 0.6873, \n",
      "Epoch [8/100], Train Loss: 0.6894, \n",
      "Epoch [9/100], Train Loss: 0.6884, \n",
      "Epoch [10/100], Train Loss: 0.6893, \n",
      "Epoch [11/100], Train Loss: 0.6882, \n",
      "Epoch [12/100], Train Loss: 0.6881, \n",
      "Epoch [13/100], Train Loss: 0.6877, \n",
      "Epoch [14/100], Train Loss: 0.6885, \n",
      "Epoch [15/100], Train Loss: 0.6876, \n",
      "Epoch [16/100], Train Loss: 0.6891, \n",
      "Epoch [17/100], Train Loss: 0.6891, \n",
      "Epoch [18/100], Train Loss: 0.6884, \n",
      "Epoch [19/100], Train Loss: 0.6885, \n",
      "Epoch [20/100], Train Loss: 0.6910, \n",
      "Epoch [21/100], Train Loss: 0.6901, \n",
      "Epoch [22/100], Train Loss: 0.6895, \n",
      "Epoch [23/100], Train Loss: 0.6883, \n",
      "Epoch [24/100], Train Loss: 0.6897, \n",
      "Epoch [25/100], Train Loss: 0.6876, \n",
      "Epoch [26/100], Train Loss: 0.6882, \n",
      "Epoch [27/100], Train Loss: 0.6898, \n",
      "Epoch [28/100], Train Loss: 0.6880, \n",
      "Epoch [29/100], Train Loss: 0.6887, \n",
      "Epoch [30/100], Train Loss: 0.6897, \n",
      "Epoch [31/100], Train Loss: 0.6886, \n",
      "Epoch [32/100], Train Loss: 0.6891, \n",
      "Epoch [33/100], Train Loss: 0.6890, \n",
      "Epoch [34/100], Train Loss: 0.6891, \n",
      "Epoch [35/100], Train Loss: 0.6902, \n",
      "Epoch [36/100], Train Loss: 0.6890, \n",
      "Epoch [37/100], Train Loss: 0.6901, \n",
      "Epoch [38/100], Train Loss: 0.6889, \n",
      "Epoch [39/100], Train Loss: 0.6878, \n",
      "Epoch [40/100], Train Loss: 0.6891, \n",
      "Epoch [41/100], Train Loss: 0.6879, \n",
      "Epoch [42/100], Train Loss: 0.6899, \n",
      "Epoch [43/100], Train Loss: 0.6903, \n",
      "Epoch [44/100], Train Loss: 0.6895, \n",
      "Epoch [45/100], Train Loss: 0.6889, \n",
      "Epoch [46/100], Train Loss: 0.6886, \n",
      "Epoch [47/100], Train Loss: 0.6886, \n",
      "Epoch [48/100], Train Loss: 0.6885, \n",
      "Epoch [49/100], Train Loss: 0.6878, \n",
      "Epoch [50/100], Train Loss: 0.6881, \n",
      "Epoch [51/100], Train Loss: 0.6883, \n",
      "Epoch [52/100], Train Loss: 0.6882, \n",
      "Epoch [53/100], Train Loss: 0.6886, \n",
      "Epoch [54/100], Train Loss: 0.6887, \n",
      "Epoch [55/100], Train Loss: 0.6885, \n",
      "Epoch [56/100], Train Loss: 0.6879, \n",
      "Epoch [57/100], Train Loss: 0.6891, \n",
      "Epoch [58/100], Train Loss: 0.6882, \n",
      "Epoch [59/100], Train Loss: 0.6909, \n",
      "Epoch [60/100], Train Loss: 0.6882, \n",
      "Epoch [61/100], Train Loss: 0.6904, \n",
      "Epoch [62/100], Train Loss: 0.6868, \n",
      "Epoch [63/100], Train Loss: 0.6874, \n",
      "Epoch [64/100], Train Loss: 0.6886, \n",
      "Epoch [65/100], Train Loss: 0.6882, \n",
      "Epoch [66/100], Train Loss: 0.6888, \n",
      "Epoch [67/100], Train Loss: 0.6912, \n",
      "Epoch [68/100], Train Loss: 0.6887, \n",
      "Epoch [69/100], Train Loss: 0.6887, \n",
      "Epoch [70/100], Train Loss: 0.6878, \n",
      "Epoch [71/100], Train Loss: 0.6895, \n",
      "Epoch [72/100], Train Loss: 0.6884, \n",
      "Epoch [73/100], Train Loss: 0.6890, \n",
      "Epoch [74/100], Train Loss: 0.6886, \n",
      "Epoch [75/100], Train Loss: 0.6887, \n",
      "Epoch [76/100], Train Loss: 0.6891, \n",
      "Epoch [77/100], Train Loss: 0.6892, \n",
      "Epoch [78/100], Train Loss: 0.6882, \n",
      "Epoch [79/100], Train Loss: 0.6896, \n",
      "Epoch [80/100], Train Loss: 0.6889, \n",
      "Epoch [81/100], Train Loss: 0.6879, \n",
      "Epoch [82/100], Train Loss: 0.6881, \n",
      "Epoch [83/100], Train Loss: 0.6889, \n",
      "Epoch [84/100], Train Loss: 0.6887, \n",
      "Epoch [85/100], Train Loss: 0.6884, \n",
      "Epoch [86/100], Train Loss: 0.6887, \n",
      "Epoch [87/100], Train Loss: 0.6876, \n",
      "Epoch [88/100], Train Loss: 0.6894, \n",
      "Epoch [89/100], Train Loss: 0.6888, \n",
      "Epoch [90/100], Train Loss: 0.6881, \n",
      "Epoch [91/100], Train Loss: 0.6893, \n",
      "Epoch [92/100], Train Loss: 0.6887, \n",
      "Epoch [93/100], Train Loss: 0.6897, \n",
      "Epoch [94/100], Train Loss: 0.6888, \n",
      "Epoch [95/100], Train Loss: 0.6889, \n",
      "Epoch [96/100], Train Loss: 0.6884, \n",
      "Epoch [97/100], Train Loss: 0.6879, \n",
      "Epoch [98/100], Train Loss: 0.6883, \n",
      "Epoch [99/100], Train Loss: 0.6875, \n",
      "Epoch [100/100], Train Loss: 0.6888, \n",
      "training loss at last epoch: 0.689\n",
      "seed = 2\n",
      "8000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 113.6604, \n",
      "Epoch [2/100], Train Loss: 49.6259, \n",
      "Epoch [3/100], Train Loss: 89.6881, \n",
      "Epoch [4/100], Train Loss: 70.1930, \n",
      "Epoch [5/100], Train Loss: 29.5885, \n",
      "Epoch [6/100], Train Loss: 18.0408, \n",
      "Epoch [7/100], Train Loss: 25.0029, \n",
      "Epoch [8/100], Train Loss: 129.9376, \n",
      "Epoch [9/100], Train Loss: 65.7266, \n",
      "Epoch [10/100], Train Loss: 22.0075, \n",
      "Epoch [11/100], Train Loss: 16.0483, \n",
      "Epoch [12/100], Train Loss: 15.1092, \n",
      "Epoch [13/100], Train Loss: 24.4429, \n",
      "Epoch [14/100], Train Loss: 51.4849, \n",
      "Epoch [15/100], Train Loss: 77.6982, \n",
      "Epoch [16/100], Train Loss: 29.8930, \n",
      "Epoch [17/100], Train Loss: 11.2357, \n",
      "Epoch [18/100], Train Loss: 12.7008, \n",
      "Epoch [19/100], Train Loss: 11.8573, \n",
      "Epoch [20/100], Train Loss: 5.6214, \n",
      "Epoch [21/100], Train Loss: 34.0612, \n",
      "Epoch [22/100], Train Loss: 13.4568, \n",
      "Epoch [23/100], Train Loss: 11.5739, \n",
      "Epoch [24/100], Train Loss: 9.3990, \n",
      "Epoch [25/100], Train Loss: 22.4193, \n",
      "Epoch [26/100], Train Loss: 11.9660, \n",
      "Epoch [27/100], Train Loss: 9.8074, \n",
      "Epoch [28/100], Train Loss: 10.1166, \n",
      "Epoch [29/100], Train Loss: 24.8499, \n",
      "Epoch [30/100], Train Loss: 10.5768, \n",
      "Epoch [31/100], Train Loss: 10.4895, \n",
      "Epoch [32/100], Train Loss: 8.4465, \n",
      "Epoch [33/100], Train Loss: 11.8601, \n",
      "Epoch [34/100], Train Loss: 11.1188, \n",
      "Epoch [35/100], Train Loss: 16.6547, \n",
      "Epoch [36/100], Train Loss: 14.1236, \n",
      "Epoch [37/100], Train Loss: 7.8872, \n",
      "Epoch [38/100], Train Loss: 8.8490, \n",
      "Epoch [39/100], Train Loss: 6.5321, \n",
      "Epoch [40/100], Train Loss: 6.9864, \n",
      "Epoch [41/100], Train Loss: 7.2079, \n",
      "Epoch [42/100], Train Loss: 15.4104, \n",
      "Epoch [43/100], Train Loss: 46.3124, \n",
      "Epoch [44/100], Train Loss: 24.2532, \n",
      "Epoch [45/100], Train Loss: 6.2919, \n",
      "Epoch [46/100], Train Loss: 6.3053, \n",
      "Epoch [47/100], Train Loss: 4.1460, \n",
      "Epoch [48/100], Train Loss: 3.5945, \n",
      "Epoch [49/100], Train Loss: 2.8742, \n",
      "Epoch [50/100], Train Loss: 4.4419, \n",
      "Epoch [51/100], Train Loss: 7.0772, \n",
      "Epoch [52/100], Train Loss: 5.4065, \n",
      "Epoch [53/100], Train Loss: 7.0925, \n",
      "Epoch [54/100], Train Loss: 5.7807, \n",
      "Epoch [55/100], Train Loss: 3.2293, \n",
      "Epoch [56/100], Train Loss: 2.3597, \n",
      "Epoch [57/100], Train Loss: 4.3371, \n",
      "Epoch [58/100], Train Loss: 4.5471, \n",
      "Epoch [59/100], Train Loss: 5.6454, \n",
      "Epoch [60/100], Train Loss: 4.1397, \n",
      "Epoch [61/100], Train Loss: 3.3572, \n",
      "Epoch [62/100], Train Loss: 2.7784, \n",
      "Epoch [63/100], Train Loss: 3.9170, \n",
      "Epoch [64/100], Train Loss: 3.0672, \n",
      "Epoch [65/100], Train Loss: 3.5790, \n",
      "Epoch [66/100], Train Loss: 3.5077, \n",
      "Epoch [67/100], Train Loss: 8.9788, \n",
      "Epoch [68/100], Train Loss: 2.9632, \n",
      "Epoch [69/100], Train Loss: 3.8556, \n",
      "Epoch [70/100], Train Loss: 2.2301, \n",
      "Epoch [71/100], Train Loss: 5.9847, \n",
      "Epoch [72/100], Train Loss: 3.3949, \n",
      "Epoch [73/100], Train Loss: 3.2528, \n",
      "Epoch [74/100], Train Loss: 2.2001, \n",
      "Epoch [75/100], Train Loss: 3.7068, \n",
      "Epoch [76/100], Train Loss: 2.5153, \n",
      "Epoch [77/100], Train Loss: 4.3823, \n",
      "Epoch [78/100], Train Loss: 2.2924, \n",
      "Epoch [79/100], Train Loss: 3.5329, \n",
      "Epoch [80/100], Train Loss: 2.7055, \n",
      "Epoch [81/100], Train Loss: 2.2829, \n",
      "Epoch [82/100], Train Loss: 3.7925, \n",
      "Epoch [83/100], Train Loss: 3.1059, \n",
      "Epoch [84/100], Train Loss: 2.3790, \n",
      "Epoch [85/100], Train Loss: 2.1420, \n",
      "Epoch [86/100], Train Loss: 2.7156, \n",
      "Epoch [87/100], Train Loss: 1.7861, \n",
      "Epoch [88/100], Train Loss: 2.2439, \n",
      "Epoch [89/100], Train Loss: 3.6141, \n",
      "Epoch [90/100], Train Loss: 2.0443, \n",
      "Epoch [91/100], Train Loss: 2.5811, \n",
      "Epoch [92/100], Train Loss: 2.5860, \n",
      "Epoch [93/100], Train Loss: 1.8432, \n",
      "Epoch [94/100], Train Loss: 3.4584, \n",
      "Epoch [95/100], Train Loss: 2.8468, \n",
      "Epoch [96/100], Train Loss: 2.6046, \n",
      "Epoch [97/100], Train Loss: 2.9203, \n",
      "Epoch [98/100], Train Loss: 1.8311, \n",
      "Epoch [99/100], Train Loss: 3.7204, \n",
      "Epoch [100/100], Train Loss: 3.1715, \n",
      "training loss at last epoch: 3.172\n",
      "Epoch [1/100], Train Loss: 6.6663, \n",
      "Epoch [2/100], Train Loss: 1.0477, \n",
      "Epoch [3/100], Train Loss: 0.7002, \n",
      "Epoch [4/100], Train Loss: 0.6890, \n",
      "Epoch [5/100], Train Loss: 0.6893, \n",
      "Epoch [6/100], Train Loss: 0.6893, \n",
      "Epoch [7/100], Train Loss: 0.6887, \n",
      "Epoch [8/100], Train Loss: 0.6874, \n",
      "Epoch [9/100], Train Loss: 0.6959, \n",
      "Epoch [10/100], Train Loss: 0.6927, \n",
      "Epoch [11/100], Train Loss: 0.6878, \n",
      "Epoch [12/100], Train Loss: 0.6887, \n",
      "Epoch [13/100], Train Loss: 0.6887, \n",
      "Epoch [14/100], Train Loss: 0.6888, \n",
      "Epoch [15/100], Train Loss: 0.6876, \n",
      "Epoch [16/100], Train Loss: 0.6888, \n",
      "Epoch [17/100], Train Loss: 0.6874, \n",
      "Epoch [18/100], Train Loss: 0.6882, \n",
      "Epoch [19/100], Train Loss: 0.6879, \n",
      "Epoch [20/100], Train Loss: 0.6890, \n",
      "Epoch [21/100], Train Loss: 0.6880, \n",
      "Epoch [22/100], Train Loss: 0.6895, \n",
      "Epoch [23/100], Train Loss: 0.6891, \n",
      "Epoch [24/100], Train Loss: 0.6895, \n",
      "Epoch [25/100], Train Loss: 0.6892, \n",
      "Epoch [26/100], Train Loss: 0.6884, \n",
      "Epoch [27/100], Train Loss: 0.6882, \n",
      "Epoch [28/100], Train Loss: 0.6894, \n",
      "Epoch [29/100], Train Loss: 0.6872, \n",
      "Epoch [30/100], Train Loss: 0.6885, \n",
      "Epoch [31/100], Train Loss: 0.6871, \n",
      "Epoch [32/100], Train Loss: 0.6888, \n",
      "Epoch [33/100], Train Loss: 0.6886, \n",
      "Epoch [34/100], Train Loss: 0.6891, \n",
      "Epoch [35/100], Train Loss: 0.6886, \n",
      "Epoch [36/100], Train Loss: 0.6878, \n",
      "Epoch [37/100], Train Loss: 0.6880, \n",
      "Epoch [38/100], Train Loss: 0.6886, \n",
      "Epoch [39/100], Train Loss: 0.6897, \n",
      "Epoch [40/100], Train Loss: 0.6884, \n",
      "Epoch [41/100], Train Loss: 0.6884, \n",
      "Epoch [42/100], Train Loss: 0.6887, \n",
      "Epoch [43/100], Train Loss: 0.6875, \n",
      "Epoch [44/100], Train Loss: 0.6880, \n",
      "Epoch [45/100], Train Loss: 0.6906, \n",
      "Epoch [46/100], Train Loss: 0.6884, \n",
      "Epoch [47/100], Train Loss: 0.6889, \n",
      "Epoch [48/100], Train Loss: 0.6902, \n",
      "Epoch [49/100], Train Loss: 0.6888, \n",
      "Epoch [50/100], Train Loss: 0.6878, \n",
      "Epoch [51/100], Train Loss: 0.6883, \n",
      "Epoch [52/100], Train Loss: 0.6888, \n",
      "Epoch [53/100], Train Loss: 0.6889, \n",
      "Epoch [54/100], Train Loss: 0.6882, \n",
      "Epoch [55/100], Train Loss: 0.6888, \n",
      "Epoch [56/100], Train Loss: 0.6886, \n",
      "Epoch [57/100], Train Loss: 0.6889, \n",
      "Epoch [58/100], Train Loss: 0.6883, \n",
      "Epoch [59/100], Train Loss: 0.6889, \n",
      "Epoch [60/100], Train Loss: 0.6889, \n",
      "Epoch [61/100], Train Loss: 0.6895, \n",
      "Epoch [62/100], Train Loss: 0.6899, \n",
      "Epoch [63/100], Train Loss: 0.6885, \n",
      "Epoch [64/100], Train Loss: 0.6880, \n",
      "Epoch [65/100], Train Loss: 0.6886, \n",
      "Epoch [66/100], Train Loss: 0.6884, \n",
      "Epoch [67/100], Train Loss: 0.6891, \n",
      "Epoch [68/100], Train Loss: 0.6890, \n",
      "Epoch [69/100], Train Loss: 0.6890, \n",
      "Epoch [70/100], Train Loss: 0.6885, \n",
      "Epoch [71/100], Train Loss: 0.6886, \n",
      "Epoch [72/100], Train Loss: 0.6880, \n",
      "Epoch [73/100], Train Loss: 0.6886, \n",
      "Epoch [74/100], Train Loss: 0.6879, \n",
      "Epoch [75/100], Train Loss: 0.6886, \n",
      "Epoch [76/100], Train Loss: 0.6884, \n",
      "Epoch [77/100], Train Loss: 0.6880, \n",
      "Epoch [78/100], Train Loss: 0.6883, \n",
      "Epoch [79/100], Train Loss: 0.6887, \n",
      "Epoch [80/100], Train Loss: 0.6879, \n",
      "Epoch [81/100], Train Loss: 0.6880, \n",
      "Epoch [82/100], Train Loss: 0.6880, \n",
      "Epoch [83/100], Train Loss: 0.6897, \n",
      "Epoch [84/100], Train Loss: 0.6896, \n",
      "Epoch [85/100], Train Loss: 0.6895, \n",
      "Epoch [86/100], Train Loss: 0.6896, \n",
      "Epoch [87/100], Train Loss: 0.6878, \n",
      "Epoch [88/100], Train Loss: 0.6880, \n",
      "Epoch [89/100], Train Loss: 0.6885, \n",
      "Epoch [90/100], Train Loss: 0.6898, \n",
      "Epoch [91/100], Train Loss: 0.6889, \n",
      "Epoch [92/100], Train Loss: 0.6874, \n",
      "Epoch [93/100], Train Loss: 0.6890, \n",
      "Epoch [94/100], Train Loss: 0.6879, \n",
      "Epoch [95/100], Train Loss: 0.6889, \n",
      "Epoch [96/100], Train Loss: 0.6882, \n",
      "Epoch [97/100], Train Loss: 0.6891, \n",
      "Epoch [98/100], Train Loss: 0.6894, \n",
      "Epoch [99/100], Train Loss: 0.6882, \n",
      "Epoch [100/100], Train Loss: 0.6895, \n",
      "training loss at last epoch: 0.689\n",
      "time t = 250\n",
      "seed = 0\n",
      "10000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 2149.3255, \n",
      "Epoch [2/100], Train Loss: 8020.5258, \n",
      "Epoch [3/100], Train Loss: 6648.1884, \n",
      "Epoch [4/100], Train Loss: 5376.1916, \n",
      "Epoch [5/100], Train Loss: 4147.4644, \n",
      "Epoch [6/100], Train Loss: 3011.3946, \n",
      "Epoch [7/100], Train Loss: 1922.6325, \n",
      "Epoch [8/100], Train Loss: 863.9446, \n",
      "Epoch [9/100], Train Loss: 4658.4189, \n",
      "Epoch [10/100], Train Loss: 3095.9341, \n",
      "Epoch [11/100], Train Loss: 2074.3657, \n",
      "Epoch [12/100], Train Loss: 1104.9416, \n",
      "Epoch [13/100], Train Loss: 1635.0444, \n",
      "Epoch [14/100], Train Loss: 2507.9990, \n",
      "Epoch [15/100], Train Loss: 1556.6131, \n",
      "Epoch [16/100], Train Loss: 811.8185, \n",
      "Epoch [17/100], Train Loss: 5395.2789, \n",
      "Epoch [18/100], Train Loss: 4402.3941, \n",
      "Epoch [19/100], Train Loss: 3474.4222, \n",
      "Epoch [20/100], Train Loss: 2629.2142, \n",
      "Epoch [21/100], Train Loss: 1786.4634, \n",
      "Epoch [22/100], Train Loss: 1002.2973, \n",
      "Epoch [23/100], Train Loss: 306.5326, \n",
      "Epoch [24/100], Train Loss: 715.6188, \n",
      "Epoch [25/100], Train Loss: 2012.0344, \n",
      "Epoch [26/100], Train Loss: 1254.0021, \n",
      "Epoch [27/100], Train Loss: 538.2101, \n",
      "Epoch [28/100], Train Loss: 3069.1870, \n",
      "Epoch [29/100], Train Loss: 2314.8970, \n",
      "Epoch [30/100], Train Loss: 1606.1320, \n",
      "Epoch [31/100], Train Loss: 919.9783, \n",
      "Epoch [32/100], Train Loss: 433.5895, \n",
      "Epoch [33/100], Train Loss: 1927.2752, \n",
      "Epoch [34/100], Train Loss: 1267.5319, \n",
      "Epoch [35/100], Train Loss: 633.4766, \n",
      "Epoch [36/100], Train Loss: 1169.1187, \n",
      "Epoch [37/100], Train Loss: 3231.0794, \n",
      "Epoch [38/100], Train Loss: 2550.0192, \n",
      "Epoch [39/100], Train Loss: 1942.3030, \n",
      "Epoch [40/100], Train Loss: 1368.0294, \n",
      "Epoch [41/100], Train Loss: 815.0960, \n",
      "Epoch [42/100], Train Loss: 455.6406, \n",
      "Epoch [43/100], Train Loss: 595.5296, \n",
      "Epoch [44/100], Train Loss: 1855.5891, \n",
      "Epoch [45/100], Train Loss: 1303.7945, \n",
      "Epoch [46/100], Train Loss: 781.0512, \n",
      "Epoch [47/100], Train Loss: 355.4788, \n",
      "Epoch [48/100], Train Loss: 292.8780, \n",
      "Epoch [49/100], Train Loss: 275.4191, \n",
      "Epoch [50/100], Train Loss: 1239.1540, \n",
      "Epoch [51/100], Train Loss: 608.8536, \n",
      "Epoch [52/100], Train Loss: 390.6740, \n",
      "Epoch [53/100], Train Loss: 210.6131, \n",
      "Epoch [54/100], Train Loss: 678.3058, \n",
      "Epoch [55/100], Train Loss: 320.0392, \n",
      "Epoch [56/100], Train Loss: 1232.9084, \n",
      "Epoch [57/100], Train Loss: 774.3673, \n",
      "Epoch [58/100], Train Loss: 354.3552, \n",
      "Epoch [59/100], Train Loss: 231.1742, \n",
      "Epoch [60/100], Train Loss: 362.4434, \n",
      "Epoch [61/100], Train Loss: 537.2422, \n",
      "Epoch [62/100], Train Loss: 177.0264, \n",
      "Epoch [63/100], Train Loss: 953.9108, \n",
      "Epoch [64/100], Train Loss: 539.6921, \n",
      "Epoch [65/100], Train Loss: 172.5181, \n",
      "Epoch [66/100], Train Loss: 329.0395, \n",
      "Epoch [67/100], Train Loss: 450.0580, \n",
      "Epoch [68/100], Train Loss: 132.6733, \n",
      "Epoch [69/100], Train Loss: 996.5692, \n",
      "Epoch [70/100], Train Loss: 607.3843, \n",
      "Epoch [71/100], Train Loss: 293.1295, \n",
      "Epoch [72/100], Train Loss: 323.4219, \n",
      "Epoch [73/100], Train Loss: 321.5410, \n",
      "Epoch [74/100], Train Loss: 450.0076, \n",
      "Epoch [75/100], Train Loss: 229.5215, \n",
      "Epoch [76/100], Train Loss: 503.3934, \n",
      "Epoch [77/100], Train Loss: 326.0132, \n",
      "Epoch [78/100], Train Loss: 427.8414, \n",
      "Epoch [79/100], Train Loss: 158.9253, \n",
      "Epoch [80/100], Train Loss: 431.2667, \n",
      "Epoch [81/100], Train Loss: 310.9485, \n",
      "Epoch [82/100], Train Loss: 377.5521, \n",
      "Epoch [83/100], Train Loss: 223.4755, \n",
      "Epoch [84/100], Train Loss: 87.3794, \n",
      "Epoch [85/100], Train Loss: 352.8132, \n",
      "Epoch [86/100], Train Loss: 131.1379, \n",
      "Epoch [87/100], Train Loss: 341.6119, \n",
      "Epoch [88/100], Train Loss: 157.7188, \n",
      "Epoch [89/100], Train Loss: 579.4575, \n",
      "Epoch [90/100], Train Loss: 272.4857, \n",
      "Epoch [91/100], Train Loss: 148.1575, \n",
      "Epoch [92/100], Train Loss: 13.9590, \n",
      "Epoch [93/100], Train Loss: 285.4553, \n",
      "Epoch [94/100], Train Loss: 86.2530, \n",
      "Epoch [95/100], Train Loss: 271.4183, \n",
      "Epoch [96/100], Train Loss: 155.5290, \n",
      "Epoch [97/100], Train Loss: 316.4651, \n",
      "Epoch [98/100], Train Loss: 8.1550, \n",
      "Epoch [99/100], Train Loss: 1140.9585, \n",
      "Epoch [100/100], Train Loss: 837.5525, \n",
      "training loss at last epoch: 837.553\n",
      "Epoch [1/100], Train Loss: 8.3582, \n",
      "Epoch [2/100], Train Loss: 0.9284, \n",
      "Epoch [3/100], Train Loss: 0.7010, \n",
      "Epoch [4/100], Train Loss: 0.6986, \n",
      "Epoch [5/100], Train Loss: 0.6977, \n",
      "Epoch [6/100], Train Loss: 0.6929, \n",
      "Epoch [7/100], Train Loss: 0.6917, \n",
      "Epoch [8/100], Train Loss: 0.6916, \n",
      "Epoch [9/100], Train Loss: 0.6919, \n",
      "Epoch [10/100], Train Loss: 0.6913, \n",
      "Epoch [11/100], Train Loss: 0.6908, \n",
      "Epoch [12/100], Train Loss: 0.6912, \n",
      "Epoch [13/100], Train Loss: 0.6906, \n",
      "Epoch [14/100], Train Loss: 0.6921, \n",
      "Epoch [15/100], Train Loss: 0.6897, \n",
      "Epoch [16/100], Train Loss: 0.6895, \n",
      "Epoch [17/100], Train Loss: 0.6897, \n",
      "Epoch [18/100], Train Loss: 0.6900, \n",
      "Epoch [19/100], Train Loss: 0.6895, \n",
      "Epoch [20/100], Train Loss: 0.6897, \n",
      "Epoch [21/100], Train Loss: 0.6898, \n",
      "Epoch [22/100], Train Loss: 0.6898, \n",
      "Epoch [23/100], Train Loss: 0.6906, \n",
      "Epoch [24/100], Train Loss: 0.6889, \n",
      "Epoch [25/100], Train Loss: 0.6894, \n",
      "Epoch [26/100], Train Loss: 0.6902, \n",
      "Epoch [27/100], Train Loss: 0.6904, \n",
      "Epoch [28/100], Train Loss: 0.6891, \n",
      "Epoch [29/100], Train Loss: 0.6903, \n",
      "Epoch [30/100], Train Loss: 0.6890, \n",
      "Epoch [31/100], Train Loss: 0.6897, \n",
      "Epoch [32/100], Train Loss: 0.6884, \n",
      "Epoch [33/100], Train Loss: 0.6893, \n",
      "Epoch [34/100], Train Loss: 0.6893, \n",
      "Epoch [35/100], Train Loss: 0.6884, \n",
      "Epoch [36/100], Train Loss: 0.6903, \n",
      "Epoch [37/100], Train Loss: 0.6895, \n",
      "Epoch [38/100], Train Loss: 0.6891, \n",
      "Epoch [39/100], Train Loss: 0.6893, \n",
      "Epoch [40/100], Train Loss: 0.6902, \n",
      "Epoch [41/100], Train Loss: 0.6892, \n",
      "Epoch [42/100], Train Loss: 0.6896, \n",
      "Epoch [43/100], Train Loss: 0.6896, \n",
      "Epoch [44/100], Train Loss: 0.6893, \n",
      "Epoch [45/100], Train Loss: 0.6902, \n",
      "Epoch [46/100], Train Loss: 0.6896, \n",
      "Epoch [47/100], Train Loss: 0.6887, \n",
      "Epoch [48/100], Train Loss: 0.6897, \n",
      "Epoch [49/100], Train Loss: 0.6894, \n",
      "Epoch [50/100], Train Loss: 0.6888, \n",
      "Epoch [51/100], Train Loss: 0.6894, \n",
      "Epoch [52/100], Train Loss: 0.6886, \n",
      "Epoch [53/100], Train Loss: 0.6890, \n",
      "Epoch [54/100], Train Loss: 0.6888, \n",
      "Epoch [55/100], Train Loss: 0.6878, \n",
      "Epoch [56/100], Train Loss: 0.6887, \n",
      "Epoch [57/100], Train Loss: 0.6887, \n",
      "Epoch [58/100], Train Loss: 0.6884, \n",
      "Epoch [59/100], Train Loss: 0.6899, \n",
      "Epoch [60/100], Train Loss: 0.6897, \n",
      "Epoch [61/100], Train Loss: 0.6899, \n",
      "Epoch [62/100], Train Loss: 0.6894, \n",
      "Epoch [63/100], Train Loss: 0.6890, \n",
      "Epoch [64/100], Train Loss: 0.6894, \n",
      "Epoch [65/100], Train Loss: 0.6884, \n",
      "Epoch [66/100], Train Loss: 0.6899, \n",
      "Epoch [67/100], Train Loss: 0.6899, \n",
      "Epoch [68/100], Train Loss: 0.6891, \n",
      "Epoch [69/100], Train Loss: 0.6893, \n",
      "Epoch [70/100], Train Loss: 0.6893, \n",
      "Epoch [71/100], Train Loss: 0.6901, \n",
      "Epoch [72/100], Train Loss: 0.6893, \n",
      "Epoch [73/100], Train Loss: 0.6893, \n",
      "Epoch [74/100], Train Loss: 0.6878, \n",
      "Epoch [75/100], Train Loss: 0.6904, \n",
      "Epoch [76/100], Train Loss: 0.6898, \n",
      "Epoch [77/100], Train Loss: 0.6885, \n",
      "Epoch [78/100], Train Loss: 0.6898, \n",
      "Epoch [79/100], Train Loss: 0.6894, \n",
      "Epoch [80/100], Train Loss: 0.6880, \n",
      "Epoch [81/100], Train Loss: 0.6890, \n",
      "Epoch [82/100], Train Loss: 0.6894, \n",
      "Epoch [83/100], Train Loss: 0.6891, \n",
      "Epoch [84/100], Train Loss: 0.6887, \n",
      "Epoch [85/100], Train Loss: 0.6886, \n",
      "Epoch [86/100], Train Loss: 0.6896, \n",
      "Epoch [87/100], Train Loss: 0.6893, \n",
      "Epoch [88/100], Train Loss: 0.6894, \n",
      "Epoch [89/100], Train Loss: 0.6892, \n",
      "Epoch [90/100], Train Loss: 0.6886, \n",
      "Epoch [91/100], Train Loss: 0.6890, \n",
      "Epoch [92/100], Train Loss: 0.6887, \n",
      "Epoch [93/100], Train Loss: 0.6893, \n",
      "Epoch [94/100], Train Loss: 0.6881, \n",
      "Epoch [95/100], Train Loss: 0.6898, \n",
      "Epoch [96/100], Train Loss: 0.6887, \n",
      "Epoch [97/100], Train Loss: 0.6894, \n",
      "Epoch [98/100], Train Loss: 0.6893, \n",
      "Epoch [99/100], Train Loss: 0.6888, \n",
      "Epoch [100/100], Train Loss: 0.6890, \n",
      "training loss at last epoch: 0.689\n",
      "seed = 1\n",
      "10000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 351.0744, \n",
      "Epoch [2/100], Train Loss: 55.2861, \n",
      "Epoch [3/100], Train Loss: 43.1792, \n",
      "Epoch [4/100], Train Loss: 31.9566, \n",
      "Epoch [5/100], Train Loss: 21.1215, \n",
      "Epoch [6/100], Train Loss: 11.9203, \n",
      "Epoch [7/100], Train Loss: 17.9172, \n",
      "Epoch [8/100], Train Loss: 49.3733, \n",
      "Epoch [9/100], Train Loss: 38.5968, \n",
      "Epoch [10/100], Train Loss: 28.5829, \n",
      "Epoch [11/100], Train Loss: 18.9554, \n",
      "Epoch [12/100], Train Loss: 11.1832, \n",
      "Epoch [13/100], Train Loss: 5.3315, \n",
      "Epoch [14/100], Train Loss: 14.3151, \n",
      "Epoch [15/100], Train Loss: 6.9538, \n",
      "Epoch [16/100], Train Loss: 11.5088, \n",
      "Epoch [17/100], Train Loss: 68.1591, \n",
      "Epoch [18/100], Train Loss: 57.9723, \n",
      "Epoch [19/100], Train Loss: 48.1781, \n",
      "Epoch [20/100], Train Loss: 39.5710, \n",
      "Epoch [21/100], Train Loss: 31.2979, \n",
      "Epoch [22/100], Train Loss: 23.8844, \n",
      "Epoch [23/100], Train Loss: 17.0208, \n",
      "Epoch [24/100], Train Loss: 11.7482, \n",
      "Epoch [25/100], Train Loss: 8.2527, \n",
      "Epoch [26/100], Train Loss: 8.5793, \n",
      "Epoch [27/100], Train Loss: 5.9998, \n",
      "Epoch [28/100], Train Loss: 14.1587, \n",
      "Epoch [29/100], Train Loss: 7.9256, \n",
      "Epoch [30/100], Train Loss: 6.4645, \n",
      "Epoch [31/100], Train Loss: 9.2252, \n",
      "Epoch [32/100], Train Loss: 7.0756, \n",
      "Epoch [33/100], Train Loss: 47.0045, \n",
      "Epoch [34/100], Train Loss: 39.5568, \n",
      "Epoch [35/100], Train Loss: 32.9182, \n",
      "Epoch [36/100], Train Loss: 26.5509, \n",
      "Epoch [37/100], Train Loss: 20.7479, \n",
      "Epoch [38/100], Train Loss: 15.0776, \n",
      "Epoch [39/100], Train Loss: 11.0031, \n",
      "Epoch [40/100], Train Loss: 7.6038, \n",
      "Epoch [41/100], Train Loss: 7.3367, \n",
      "Epoch [42/100], Train Loss: 6.2841, \n",
      "Epoch [43/100], Train Loss: 4.5314, \n",
      "Epoch [44/100], Train Loss: 53.7964, \n",
      "Epoch [45/100], Train Loss: 47.3725, \n",
      "Epoch [46/100], Train Loss: 41.0811, \n",
      "Epoch [47/100], Train Loss: 35.6253, \n",
      "Epoch [48/100], Train Loss: 30.6717, \n",
      "Epoch [49/100], Train Loss: 26.0889, \n",
      "Epoch [50/100], Train Loss: 21.8425, \n",
      "Epoch [51/100], Train Loss: 17.8105, \n",
      "Epoch [52/100], Train Loss: 14.0706, \n",
      "Epoch [53/100], Train Loss: 10.5548, \n",
      "Epoch [54/100], Train Loss: 7.5866, \n",
      "Epoch [55/100], Train Loss: 5.0124, \n",
      "Epoch [56/100], Train Loss: 6.4292, \n",
      "Epoch [57/100], Train Loss: 4.7428, \n",
      "Epoch [58/100], Train Loss: 5.6514, \n",
      "Epoch [59/100], Train Loss: 5.2408, \n",
      "Epoch [60/100], Train Loss: 4.8473, \n",
      "Epoch [61/100], Train Loss: 4.0129, \n",
      "Epoch [62/100], Train Loss: 3.4525, \n",
      "Epoch [63/100], Train Loss: 4.0056, \n",
      "Epoch [64/100], Train Loss: 2.5722, \n",
      "Epoch [65/100], Train Loss: 5.2432, \n",
      "Epoch [66/100], Train Loss: 2.3907, \n",
      "Epoch [67/100], Train Loss: 1.9208, \n",
      "Epoch [68/100], Train Loss: 2.8357, \n",
      "Epoch [69/100], Train Loss: 2.3685, \n",
      "Epoch [70/100], Train Loss: 5.7479, \n",
      "Epoch [71/100], Train Loss: 3.6214, \n",
      "Epoch [72/100], Train Loss: 3.1915, \n",
      "Epoch [73/100], Train Loss: 2.5116, \n",
      "Epoch [74/100], Train Loss: 2.3157, \n",
      "Epoch [75/100], Train Loss: 3.9613, \n",
      "Epoch [76/100], Train Loss: 2.5850, \n",
      "Epoch [77/100], Train Loss: 2.4463, \n",
      "Epoch [78/100], Train Loss: 6.5886, \n",
      "Epoch [79/100], Train Loss: 26.4662, \n",
      "Epoch [80/100], Train Loss: 23.1394, \n",
      "Epoch [81/100], Train Loss: 20.1532, \n",
      "Epoch [82/100], Train Loss: 17.5287, \n",
      "Epoch [83/100], Train Loss: 15.0430, \n",
      "Epoch [84/100], Train Loss: 12.8218, \n",
      "Epoch [85/100], Train Loss: 10.7046, \n",
      "Epoch [86/100], Train Loss: 8.7559, \n",
      "Epoch [87/100], Train Loss: 6.9112, \n",
      "Epoch [88/100], Train Loss: 5.1900, \n",
      "Epoch [89/100], Train Loss: 4.0323, \n",
      "Epoch [90/100], Train Loss: 4.4573, \n",
      "Epoch [91/100], Train Loss: 3.9167, \n",
      "Epoch [92/100], Train Loss: 4.0270, \n",
      "Epoch [93/100], Train Loss: 3.4909, \n",
      "Epoch [94/100], Train Loss: 3.0183, \n",
      "Epoch [95/100], Train Loss: 3.1806, \n",
      "Epoch [96/100], Train Loss: 2.7208, \n",
      "Epoch [97/100], Train Loss: 2.3657, \n",
      "Epoch [98/100], Train Loss: 1.9698, \n",
      "Epoch [99/100], Train Loss: 2.8243, \n",
      "Epoch [100/100], Train Loss: 2.4674, \n",
      "training loss at last epoch: 2.467\n",
      "Epoch [1/100], Train Loss: 37.4375, \n",
      "Epoch [2/100], Train Loss: 0.7274, \n",
      "Epoch [3/100], Train Loss: 0.6907, \n",
      "Epoch [4/100], Train Loss: 0.6904, \n",
      "Epoch [5/100], Train Loss: 0.6888, \n",
      "Epoch [6/100], Train Loss: 0.6894, \n",
      "Epoch [7/100], Train Loss: 0.6902, \n",
      "Epoch [8/100], Train Loss: 0.6902, \n",
      "Epoch [9/100], Train Loss: 0.7086, \n",
      "Epoch [10/100], Train Loss: 0.6902, \n",
      "Epoch [11/100], Train Loss: 0.6897, \n",
      "Epoch [12/100], Train Loss: 0.6898, \n",
      "Epoch [13/100], Train Loss: 0.6897, \n",
      "Epoch [14/100], Train Loss: 0.6885, \n",
      "Epoch [15/100], Train Loss: 0.6892, \n",
      "Epoch [16/100], Train Loss: 0.6879, \n",
      "Epoch [17/100], Train Loss: 0.6890, \n",
      "Epoch [18/100], Train Loss: 0.6896, \n",
      "Epoch [19/100], Train Loss: 0.6896, \n",
      "Epoch [20/100], Train Loss: 0.6905, \n",
      "Epoch [21/100], Train Loss: 0.6894, \n",
      "Epoch [22/100], Train Loss: 0.6895, \n",
      "Epoch [23/100], Train Loss: 0.6906, \n",
      "Epoch [24/100], Train Loss: 0.6900, \n",
      "Epoch [25/100], Train Loss: 0.6905, \n",
      "Epoch [26/100], Train Loss: 0.6907, \n",
      "Epoch [27/100], Train Loss: 0.6897, \n",
      "Epoch [28/100], Train Loss: 0.6890, \n",
      "Epoch [29/100], Train Loss: 0.6897, \n",
      "Epoch [30/100], Train Loss: 0.6899, \n",
      "Epoch [31/100], Train Loss: 0.6900, \n",
      "Epoch [32/100], Train Loss: 0.6908, \n",
      "Epoch [33/100], Train Loss: 0.6899, \n",
      "Epoch [34/100], Train Loss: 0.6900, \n",
      "Epoch [35/100], Train Loss: 0.6895, \n",
      "Epoch [36/100], Train Loss: 0.6893, \n",
      "Epoch [37/100], Train Loss: 0.6902, \n",
      "Epoch [38/100], Train Loss: 0.6897, \n",
      "Epoch [39/100], Train Loss: 0.6904, \n",
      "Epoch [40/100], Train Loss: 0.6905, \n",
      "Epoch [41/100], Train Loss: 0.6904, \n",
      "Epoch [42/100], Train Loss: 0.6911, \n",
      "Epoch [43/100], Train Loss: 0.6902, \n",
      "Epoch [44/100], Train Loss: 0.6891, \n",
      "Epoch [45/100], Train Loss: 0.6904, \n",
      "Epoch [46/100], Train Loss: 0.6902, \n",
      "Epoch [47/100], Train Loss: 0.6891, \n",
      "Epoch [48/100], Train Loss: 0.6895, \n",
      "Epoch [49/100], Train Loss: 0.6905, \n",
      "Epoch [50/100], Train Loss: 0.6889, \n",
      "Epoch [51/100], Train Loss: 0.6907, \n",
      "Epoch [52/100], Train Loss: 0.6898, \n",
      "Epoch [53/100], Train Loss: 0.6909, \n",
      "Epoch [54/100], Train Loss: 0.6895, \n",
      "Epoch [55/100], Train Loss: 0.6905, \n",
      "Epoch [56/100], Train Loss: 0.6911, \n",
      "Epoch [57/100], Train Loss: 0.6895, \n",
      "Epoch [58/100], Train Loss: 0.6895, \n",
      "Epoch [59/100], Train Loss: 0.6902, \n",
      "Epoch [60/100], Train Loss: 0.6894, \n",
      "Epoch [61/100], Train Loss: 0.6894, \n",
      "Epoch [62/100], Train Loss: 0.6890, \n",
      "Epoch [63/100], Train Loss: 0.6894, \n",
      "Epoch [64/100], Train Loss: 0.6902, \n",
      "Epoch [65/100], Train Loss: 0.6898, \n",
      "Epoch [66/100], Train Loss: 0.6903, \n",
      "Epoch [67/100], Train Loss: 0.6905, \n",
      "Epoch [68/100], Train Loss: 0.6900, \n",
      "Epoch [69/100], Train Loss: 0.6899, \n",
      "Epoch [70/100], Train Loss: 0.6905, \n",
      "Epoch [71/100], Train Loss: 0.6901, \n",
      "Epoch [72/100], Train Loss: 0.6901, \n",
      "Epoch [73/100], Train Loss: 0.6897, \n",
      "Epoch [74/100], Train Loss: 0.6901, \n",
      "Epoch [75/100], Train Loss: 0.6904, \n",
      "Epoch [76/100], Train Loss: 0.6900, \n",
      "Epoch [77/100], Train Loss: 0.6902, \n",
      "Epoch [78/100], Train Loss: 0.6908, \n",
      "Epoch [79/100], Train Loss: 0.6901, \n",
      "Epoch [80/100], Train Loss: 0.6897, \n",
      "Epoch [81/100], Train Loss: 0.6905, \n",
      "Epoch [82/100], Train Loss: 0.6903, \n",
      "Epoch [83/100], Train Loss: 0.6900, \n",
      "Epoch [84/100], Train Loss: 0.6899, \n",
      "Epoch [85/100], Train Loss: 0.6893, \n",
      "Epoch [86/100], Train Loss: 0.6894, \n",
      "Epoch [87/100], Train Loss: 0.6905, \n",
      "Epoch [88/100], Train Loss: 0.6904, \n",
      "Epoch [89/100], Train Loss: 0.6912, \n",
      "Epoch [90/100], Train Loss: 0.6900, \n",
      "Epoch [91/100], Train Loss: 0.6903, \n",
      "Epoch [92/100], Train Loss: 0.6897, \n",
      "Epoch [93/100], Train Loss: 0.6898, \n",
      "Epoch [94/100], Train Loss: 0.6901, \n",
      "Epoch [95/100], Train Loss: 0.6903, \n",
      "Epoch [96/100], Train Loss: 0.6899, \n",
      "Epoch [97/100], Train Loss: 0.6896, \n",
      "Epoch [98/100], Train Loss: 0.6898, \n",
      "Epoch [99/100], Train Loss: 0.6901, \n",
      "Epoch [100/100], Train Loss: 0.6902, \n",
      "training loss at last epoch: 0.690\n",
      "seed = 2\n",
      "10000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 109.9969, \n",
      "Epoch [2/100], Train Loss: 98.0861, \n",
      "Epoch [3/100], Train Loss: 68.6780, \n",
      "Epoch [4/100], Train Loss: 106.1749, \n",
      "Epoch [5/100], Train Loss: 35.7306, \n",
      "Epoch [6/100], Train Loss: 55.8009, \n",
      "Epoch [7/100], Train Loss: 8.4748, \n",
      "Epoch [8/100], Train Loss: 95.8717, \n",
      "Epoch [9/100], Train Loss: 32.5884, \n",
      "Epoch [10/100], Train Loss: 42.7459, \n",
      "Epoch [11/100], Train Loss: 45.3958, \n",
      "Epoch [12/100], Train Loss: 16.8736, \n",
      "Epoch [13/100], Train Loss: 14.9638, \n",
      "Epoch [14/100], Train Loss: 88.7019, \n",
      "Epoch [15/100], Train Loss: 81.6537, \n",
      "Epoch [16/100], Train Loss: 38.9296, \n",
      "Epoch [17/100], Train Loss: 19.2610, \n",
      "Epoch [18/100], Train Loss: 14.9378, \n",
      "Epoch [19/100], Train Loss: 23.9836, \n",
      "Epoch [20/100], Train Loss: 32.6144, \n",
      "Epoch [21/100], Train Loss: 7.6442, \n",
      "Epoch [22/100], Train Loss: 13.1471, \n",
      "Epoch [23/100], Train Loss: 14.2126, \n",
      "Epoch [24/100], Train Loss: 9.3336, \n",
      "Epoch [25/100], Train Loss: 14.1463, \n",
      "Epoch [26/100], Train Loss: 8.4539, \n",
      "Epoch [27/100], Train Loss: 34.4887, \n",
      "Epoch [28/100], Train Loss: 9.9087, \n",
      "Epoch [29/100], Train Loss: 113.4085, \n",
      "Epoch [30/100], Train Loss: 3099.4673, \n",
      "Epoch [31/100], Train Loss: 2054.2430, \n",
      "Epoch [32/100], Train Loss: 1383.9442, \n",
      "Epoch [33/100], Train Loss: 876.3858, \n",
      "Epoch [34/100], Train Loss: 472.8634, \n",
      "Epoch [35/100], Train Loss: 122.4485, \n",
      "Epoch [36/100], Train Loss: 71.6650, \n",
      "Epoch [37/100], Train Loss: 96.0177, \n",
      "Epoch [38/100], Train Loss: 40.6825, \n",
      "Epoch [39/100], Train Loss: 50.3900, \n",
      "Epoch [40/100], Train Loss: 63.2303, \n",
      "Epoch [41/100], Train Loss: 69.9637, \n",
      "Epoch [42/100], Train Loss: 107.9469, \n",
      "Epoch [43/100], Train Loss: 134.0811, \n",
      "Epoch [44/100], Train Loss: 178.7320, \n",
      "Epoch [45/100], Train Loss: 70.3923, \n",
      "Epoch [46/100], Train Loss: 38.3409, \n",
      "Epoch [47/100], Train Loss: 50.7867, \n",
      "Epoch [48/100], Train Loss: 101.2322, \n",
      "Epoch [49/100], Train Loss: 59.6134, \n",
      "Epoch [50/100], Train Loss: 77.7711, \n",
      "Epoch [51/100], Train Loss: 38.4276, \n",
      "Epoch [52/100], Train Loss: 94.7843, \n",
      "Epoch [53/100], Train Loss: 42.1582, \n",
      "Epoch [54/100], Train Loss: 44.8749, \n",
      "Epoch [55/100], Train Loss: 98.6131, \n",
      "Epoch [56/100], Train Loss: 54.6418, \n",
      "Epoch [57/100], Train Loss: 43.7827, \n",
      "Epoch [58/100], Train Loss: 41.4564, \n",
      "Epoch [59/100], Train Loss: 48.5092, \n",
      "Epoch [60/100], Train Loss: 57.3892, \n",
      "Epoch [61/100], Train Loss: 32.6339, \n",
      "Epoch [62/100], Train Loss: 48.6797, \n",
      "Epoch [63/100], Train Loss: 63.8832, \n",
      "Epoch [64/100], Train Loss: 36.8614, \n",
      "Epoch [65/100], Train Loss: 51.5460, \n",
      "Epoch [66/100], Train Loss: 27.3812, \n",
      "Epoch [67/100], Train Loss: 45.5619, \n",
      "Epoch [68/100], Train Loss: 48.1595, \n",
      "Epoch [69/100], Train Loss: 34.1419, \n",
      "Epoch [70/100], Train Loss: 14.2236, \n",
      "Epoch [71/100], Train Loss: 54.8974, \n",
      "Epoch [72/100], Train Loss: 84.7922, \n",
      "Epoch [73/100], Train Loss: 49.5009, \n",
      "Epoch [74/100], Train Loss: 12.5824, \n",
      "Epoch [75/100], Train Loss: 24.7798, \n",
      "Epoch [76/100], Train Loss: 35.7432, \n",
      "Epoch [77/100], Train Loss: 56.8563, \n",
      "Epoch [78/100], Train Loss: 15.9708, \n",
      "Epoch [79/100], Train Loss: 28.5357, \n",
      "Epoch [80/100], Train Loss: 23.7964, \n",
      "Epoch [81/100], Train Loss: 49.7676, \n",
      "Epoch [82/100], Train Loss: 39.1718, \n",
      "Epoch [83/100], Train Loss: 26.4799, \n",
      "Epoch [84/100], Train Loss: 12.7510, \n",
      "Epoch [85/100], Train Loss: 36.4096, \n",
      "Epoch [86/100], Train Loss: 13.5031, \n",
      "Epoch [87/100], Train Loss: 18.8059, \n",
      "Epoch [88/100], Train Loss: 39.5942, \n",
      "Epoch [89/100], Train Loss: 29.5655, \n",
      "Epoch [90/100], Train Loss: 38.1665, \n",
      "Epoch [91/100], Train Loss: 26.1439, \n",
      "Epoch [92/100], Train Loss: 28.5830, \n",
      "Epoch [93/100], Train Loss: 26.9261, \n",
      "Epoch [94/100], Train Loss: 22.7807, \n",
      "Epoch [95/100], Train Loss: 17.7617, \n",
      "Epoch [96/100], Train Loss: 27.6516, \n",
      "Epoch [97/100], Train Loss: 28.4812, \n",
      "Epoch [98/100], Train Loss: 24.0789, \n",
      "Epoch [99/100], Train Loss: 36.2555, \n",
      "Epoch [100/100], Train Loss: 27.1140, \n",
      "training loss at last epoch: 27.114\n",
      "Epoch [1/100], Train Loss: 11.3905, \n",
      "Epoch [2/100], Train Loss: 0.7306, \n",
      "Epoch [3/100], Train Loss: 0.7032, \n",
      "Epoch [4/100], Train Loss: 0.6956, \n",
      "Epoch [5/100], Train Loss: 0.6978, \n",
      "Epoch [6/100], Train Loss: 0.6956, \n",
      "Epoch [7/100], Train Loss: 0.6916, \n",
      "Epoch [8/100], Train Loss: 0.6934, \n",
      "Epoch [9/100], Train Loss: 0.6913, \n",
      "Epoch [10/100], Train Loss: 0.6913, \n",
      "Epoch [11/100], Train Loss: 0.6899, \n",
      "Epoch [12/100], Train Loss: 0.6906, \n",
      "Epoch [13/100], Train Loss: 0.6909, \n",
      "Epoch [14/100], Train Loss: 0.6911, \n",
      "Epoch [15/100], Train Loss: 0.6901, \n",
      "Epoch [16/100], Train Loss: 0.6909, \n",
      "Epoch [17/100], Train Loss: 0.6895, \n",
      "Epoch [18/100], Train Loss: 0.6901, \n",
      "Epoch [19/100], Train Loss: 0.6898, \n",
      "Epoch [20/100], Train Loss: 0.6900, \n",
      "Epoch [21/100], Train Loss: 0.6900, \n",
      "Epoch [22/100], Train Loss: 0.6893, \n",
      "Epoch [23/100], Train Loss: 0.6901, \n",
      "Epoch [24/100], Train Loss: 0.6903, \n",
      "Epoch [25/100], Train Loss: 0.6909, \n",
      "Epoch [26/100], Train Loss: 0.6894, \n",
      "Epoch [27/100], Train Loss: 0.6901, \n",
      "Epoch [28/100], Train Loss: 0.6879, \n",
      "Epoch [29/100], Train Loss: 0.6913, \n",
      "Epoch [30/100], Train Loss: 0.6896, \n",
      "Epoch [31/100], Train Loss: 0.6903, \n",
      "Epoch [32/100], Train Loss: 0.6901, \n",
      "Epoch [33/100], Train Loss: 0.6891, \n",
      "Epoch [34/100], Train Loss: 0.6902, \n",
      "Epoch [35/100], Train Loss: 0.6895, \n",
      "Epoch [36/100], Train Loss: 0.6900, \n",
      "Epoch [37/100], Train Loss: 0.6905, \n",
      "Epoch [38/100], Train Loss: 0.6896, \n",
      "Epoch [39/100], Train Loss: 0.6894, \n",
      "Epoch [40/100], Train Loss: 0.6913, \n",
      "Epoch [41/100], Train Loss: 0.6916, \n",
      "Epoch [42/100], Train Loss: 0.6907, \n",
      "Epoch [43/100], Train Loss: 0.6903, \n",
      "Epoch [44/100], Train Loss: 0.6902, \n",
      "Epoch [45/100], Train Loss: 0.6896, \n",
      "Epoch [46/100], Train Loss: 0.6904, \n",
      "Epoch [47/100], Train Loss: 0.6905, \n",
      "Epoch [48/100], Train Loss: 0.6900, \n",
      "Epoch [49/100], Train Loss: 0.6903, \n",
      "Epoch [50/100], Train Loss: 0.6900, \n",
      "Epoch [51/100], Train Loss: 0.6906, \n",
      "Epoch [52/100], Train Loss: 0.6894, \n",
      "Epoch [53/100], Train Loss: 0.6895, \n",
      "Epoch [54/100], Train Loss: 0.6894, \n",
      "Epoch [55/100], Train Loss: 0.6904, \n",
      "Epoch [56/100], Train Loss: 0.6913, \n",
      "Epoch [57/100], Train Loss: 0.6903, \n",
      "Epoch [58/100], Train Loss: 0.6898, \n",
      "Epoch [59/100], Train Loss: 0.6889, \n",
      "Epoch [60/100], Train Loss: 0.6905, \n",
      "Epoch [61/100], Train Loss: 0.6894, \n",
      "Epoch [62/100], Train Loss: 0.6897, \n",
      "Epoch [63/100], Train Loss: 0.6898, \n",
      "Epoch [64/100], Train Loss: 0.6906, \n",
      "Epoch [65/100], Train Loss: 0.6899, \n",
      "Epoch [66/100], Train Loss: 0.6897, \n",
      "Epoch [67/100], Train Loss: 0.6895, \n",
      "Epoch [68/100], Train Loss: 0.6903, \n",
      "Epoch [69/100], Train Loss: 0.6896, \n",
      "Epoch [70/100], Train Loss: 0.6898, \n",
      "Epoch [71/100], Train Loss: 0.6895, \n",
      "Epoch [72/100], Train Loss: 0.6907, \n",
      "Epoch [73/100], Train Loss: 0.6907, \n",
      "Epoch [74/100], Train Loss: 0.6900, \n",
      "Epoch [75/100], Train Loss: 0.6904, \n",
      "Epoch [76/100], Train Loss: 0.6899, \n",
      "Epoch [77/100], Train Loss: 0.6901, \n",
      "Epoch [78/100], Train Loss: 0.6894, \n",
      "Epoch [79/100], Train Loss: 0.6901, \n",
      "Epoch [80/100], Train Loss: 0.6905, \n",
      "Epoch [81/100], Train Loss: 0.6896, \n",
      "Epoch [82/100], Train Loss: 0.6894, \n",
      "Epoch [83/100], Train Loss: 0.6906, \n",
      "Epoch [84/100], Train Loss: 0.6906, \n",
      "Epoch [85/100], Train Loss: 0.6911, \n",
      "Epoch [86/100], Train Loss: 0.6898, \n",
      "Epoch [87/100], Train Loss: 0.6901, \n",
      "Epoch [88/100], Train Loss: 0.6913, \n",
      "Epoch [89/100], Train Loss: 0.6892, \n",
      "Epoch [90/100], Train Loss: 0.6916, \n",
      "Epoch [91/100], Train Loss: 0.6891, \n",
      "Epoch [92/100], Train Loss: 0.6894, \n",
      "Epoch [93/100], Train Loss: 0.6899, \n",
      "Epoch [94/100], Train Loss: 0.6901, \n",
      "Epoch [95/100], Train Loss: 0.6905, \n",
      "Epoch [96/100], Train Loss: 0.6905, \n",
      "Epoch [97/100], Train Loss: 0.6898, \n",
      "Epoch [98/100], Train Loss: 0.6913, \n",
      "Epoch [99/100], Train Loss: 0.6897, \n",
      "Epoch [100/100], Train Loss: 0.6896, \n",
      "training loss at last epoch: 0.690\n",
      "time t = 300\n",
      "seed = 0\n",
      "12000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 78.1662, \n",
      "Epoch [2/100], Train Loss: 8.7788, \n",
      "Epoch [3/100], Train Loss: 2.5871, \n",
      "Epoch [4/100], Train Loss: 310.8249, \n",
      "Epoch [5/100], Train Loss: 189.6826, \n",
      "Epoch [6/100], Train Loss: 968.5046, \n",
      "Epoch [7/100], Train Loss: 707.0849, \n",
      "Epoch [8/100], Train Loss: 460.7363, \n",
      "Epoch [9/100], Train Loss: 226.3601, \n",
      "Epoch [10/100], Train Loss: 197.6206, \n",
      "Epoch [11/100], Train Loss: 644.9408, \n",
      "Epoch [12/100], Train Loss: 410.4464, \n",
      "Epoch [13/100], Train Loss: 185.9069, \n",
      "Epoch [14/100], Train Loss: 3069.7688, \n",
      "Epoch [15/100], Train Loss: 2679.3453, \n",
      "Epoch [16/100], Train Loss: 2371.1917, \n",
      "Epoch [17/100], Train Loss: 2098.5863, \n",
      "Epoch [18/100], Train Loss: 1851.2018, \n",
      "Epoch [19/100], Train Loss: 1626.0371, \n",
      "Epoch [20/100], Train Loss: 1416.2995, \n",
      "Epoch [21/100], Train Loss: 1238.7766, \n",
      "Epoch [22/100], Train Loss: 1068.4784, \n",
      "Epoch [23/100], Train Loss: 916.2329, \n",
      "Epoch [24/100], Train Loss: 781.1314, \n",
      "Epoch [25/100], Train Loss: 653.7256, \n",
      "Epoch [26/100], Train Loss: 535.9247, \n",
      "Epoch [27/100], Train Loss: 423.0033, \n",
      "Epoch [28/100], Train Loss: 321.9678, \n",
      "Epoch [29/100], Train Loss: 227.9212, \n",
      "Epoch [30/100], Train Loss: 139.3502, \n",
      "Epoch [31/100], Train Loss: 67.4274, \n",
      "Epoch [32/100], Train Loss: 33.7474, \n",
      "Epoch [33/100], Train Loss: 68.9721, \n",
      "Epoch [34/100], Train Loss: 79.4990, \n",
      "Epoch [35/100], Train Loss: 65.3169, \n",
      "Epoch [36/100], Train Loss: 87.2048, \n",
      "Epoch [37/100], Train Loss: 27.4354, \n",
      "Epoch [38/100], Train Loss: 64.9599, \n",
      "Epoch [39/100], Train Loss: 74.6133, \n",
      "Epoch [40/100], Train Loss: 62.2427, \n",
      "Epoch [41/100], Train Loss: 58.1338, \n",
      "Epoch [42/100], Train Loss: 66.8003, \n",
      "Epoch [43/100], Train Loss: 67.7091, \n",
      "Epoch [44/100], Train Loss: 72.2136, \n",
      "Epoch [45/100], Train Loss: 65.6941, \n",
      "Epoch [46/100], Train Loss: 70.4122, \n",
      "Epoch [47/100], Train Loss: 143.2742, \n",
      "Epoch [48/100], Train Loss: 69.2737, \n",
      "Epoch [49/100], Train Loss: 58.9537, \n",
      "Epoch [50/100], Train Loss: 37.5873, \n",
      "Epoch [51/100], Train Loss: 58.4589, \n",
      "Epoch [52/100], Train Loss: 33.5941, \n",
      "Epoch [53/100], Train Loss: 91.2979, \n",
      "Epoch [54/100], Train Loss: 43.6615, \n",
      "Epoch [55/100], Train Loss: 60.9356, \n",
      "Epoch [56/100], Train Loss: 64.0040, \n",
      "Epoch [57/100], Train Loss: 19.4220, \n",
      "Epoch [58/100], Train Loss: 53.7849, \n",
      "Epoch [59/100], Train Loss: 69.9628, \n",
      "Epoch [60/100], Train Loss: 58.5846, \n",
      "Epoch [61/100], Train Loss: 18.5840, \n",
      "Epoch [62/100], Train Loss: 42.1021, \n",
      "Epoch [63/100], Train Loss: 10.2457, \n",
      "Epoch [64/100], Train Loss: 174.1066, \n",
      "Epoch [65/100], Train Loss: 113.5130, \n",
      "Epoch [66/100], Train Loss: 59.7765, \n",
      "Epoch [67/100], Train Loss: 36.0003, \n",
      "Epoch [68/100], Train Loss: 56.6973, \n",
      "Epoch [69/100], Train Loss: 46.4520, \n",
      "Epoch [70/100], Train Loss: 39.9580, \n",
      "Epoch [71/100], Train Loss: 42.0479, \n",
      "Epoch [72/100], Train Loss: 35.9267, \n",
      "Epoch [73/100], Train Loss: 49.0689, \n",
      "Epoch [74/100], Train Loss: 50.7229, \n",
      "Epoch [75/100], Train Loss: 37.7460, \n",
      "Epoch [76/100], Train Loss: 12.8517, \n",
      "Epoch [77/100], Train Loss: 51.4455, \n",
      "Epoch [78/100], Train Loss: 35.1574, \n",
      "Epoch [79/100], Train Loss: 17.3384, \n",
      "Epoch [80/100], Train Loss: 24.0117, \n",
      "Epoch [81/100], Train Loss: 42.3044, \n",
      "Epoch [82/100], Train Loss: 42.4056, \n",
      "Epoch [83/100], Train Loss: 33.8248, \n",
      "Epoch [84/100], Train Loss: 43.2330, \n",
      "Epoch [85/100], Train Loss: 43.4565, \n",
      "Epoch [86/100], Train Loss: 15.5369, \n",
      "Epoch [87/100], Train Loss: 57.4824, \n",
      "Epoch [88/100], Train Loss: 92.9726, \n",
      "Epoch [89/100], Train Loss: 49.9142, \n",
      "Epoch [90/100], Train Loss: 31.3636, \n",
      "Epoch [91/100], Train Loss: 45.2887, \n",
      "Epoch [92/100], Train Loss: 55.1942, \n",
      "Epoch [93/100], Train Loss: 15.9646, \n",
      "Epoch [94/100], Train Loss: 67.2702, \n",
      "Epoch [95/100], Train Loss: 39.5037, \n",
      "Epoch [96/100], Train Loss: 30.4804, \n",
      "Epoch [97/100], Train Loss: 31.8015, \n",
      "Epoch [98/100], Train Loss: 35.4906, \n",
      "Epoch [99/100], Train Loss: 36.0568, \n",
      "Epoch [100/100], Train Loss: 27.1684, \n",
      "training loss at last epoch: 27.168\n",
      "Epoch [1/100], Train Loss: 8.7822, \n",
      "Epoch [2/100], Train Loss: 1.0003, \n",
      "Epoch [3/100], Train Loss: 0.7189, \n",
      "Epoch [4/100], Train Loss: 0.7073, \n",
      "Epoch [5/100], Train Loss: 0.6997, \n",
      "Epoch [6/100], Train Loss: 0.6958, \n",
      "Epoch [7/100], Train Loss: 0.6913, \n",
      "Epoch [8/100], Train Loss: 0.6903, \n",
      "Epoch [9/100], Train Loss: 0.7309, \n",
      "Epoch [10/100], Train Loss: 0.6905, \n",
      "Epoch [11/100], Train Loss: 0.6912, \n",
      "Epoch [12/100], Train Loss: 0.6912, \n",
      "Epoch [13/100], Train Loss: 0.6910, \n",
      "Epoch [14/100], Train Loss: 0.6922, \n",
      "Epoch [15/100], Train Loss: 0.6907, \n",
      "Epoch [16/100], Train Loss: 0.6921, \n",
      "Epoch [17/100], Train Loss: 0.6909, \n",
      "Epoch [18/100], Train Loss: 0.6900, \n",
      "Epoch [19/100], Train Loss: 0.6915, \n",
      "Epoch [20/100], Train Loss: 0.6920, \n",
      "Epoch [21/100], Train Loss: 0.6911, \n",
      "Epoch [22/100], Train Loss: 0.6912, \n",
      "Epoch [23/100], Train Loss: 0.6910, \n",
      "Epoch [24/100], Train Loss: 0.6911, \n",
      "Epoch [25/100], Train Loss: 0.6905, \n",
      "Epoch [26/100], Train Loss: 0.6914, \n",
      "Epoch [27/100], Train Loss: 0.6906, \n",
      "Epoch [28/100], Train Loss: 0.6918, \n",
      "Epoch [29/100], Train Loss: 0.6908, \n",
      "Epoch [30/100], Train Loss: 0.6899, \n",
      "Epoch [31/100], Train Loss: 0.6915, \n",
      "Epoch [32/100], Train Loss: 0.6920, \n",
      "Epoch [33/100], Train Loss: 0.6906, \n",
      "Epoch [34/100], Train Loss: 0.6908, \n",
      "Epoch [35/100], Train Loss: 0.6912, \n",
      "Epoch [36/100], Train Loss: 0.6925, \n",
      "Epoch [37/100], Train Loss: 0.6912, \n",
      "Epoch [38/100], Train Loss: 0.6908, \n",
      "Epoch [39/100], Train Loss: 0.6906, \n",
      "Epoch [40/100], Train Loss: 0.6905, \n",
      "Epoch [41/100], Train Loss: 0.6914, \n",
      "Epoch [42/100], Train Loss: 0.6897, \n",
      "Epoch [43/100], Train Loss: 0.6908, \n",
      "Epoch [44/100], Train Loss: 0.6904, \n",
      "Epoch [45/100], Train Loss: 0.6918, \n",
      "Epoch [46/100], Train Loss: 0.6913, \n",
      "Epoch [47/100], Train Loss: 0.6915, \n",
      "Epoch [48/100], Train Loss: 0.6899, \n",
      "Epoch [49/100], Train Loss: 0.6907, \n",
      "Epoch [50/100], Train Loss: 0.6907, \n",
      "Epoch [51/100], Train Loss: 0.6905, \n",
      "Epoch [52/100], Train Loss: 0.6888, \n",
      "Epoch [53/100], Train Loss: 0.6906, \n",
      "Epoch [54/100], Train Loss: 0.6907, \n",
      "Epoch [55/100], Train Loss: 0.6908, \n",
      "Epoch [56/100], Train Loss: 0.6906, \n",
      "Epoch [57/100], Train Loss: 0.6908, \n",
      "Epoch [58/100], Train Loss: 0.6907, \n",
      "Epoch [59/100], Train Loss: 0.6912, \n",
      "Epoch [60/100], Train Loss: 0.6908, \n",
      "Epoch [61/100], Train Loss: 0.6914, \n",
      "Epoch [62/100], Train Loss: 0.6907, \n",
      "Epoch [63/100], Train Loss: 0.6912, \n",
      "Epoch [64/100], Train Loss: 0.6911, \n",
      "Epoch [65/100], Train Loss: 0.6909, \n",
      "Epoch [66/100], Train Loss: 0.6905, \n",
      "Epoch [67/100], Train Loss: 0.6916, \n",
      "Epoch [68/100], Train Loss: 0.6911, \n",
      "Epoch [69/100], Train Loss: 0.6902, \n",
      "Epoch [70/100], Train Loss: 0.6909, \n",
      "Epoch [71/100], Train Loss: 0.6901, \n",
      "Epoch [72/100], Train Loss: 0.6911, \n",
      "Epoch [73/100], Train Loss: 0.6906, \n",
      "Epoch [74/100], Train Loss: 0.6905, \n",
      "Epoch [75/100], Train Loss: 0.6914, \n",
      "Epoch [76/100], Train Loss: 0.6917, \n",
      "Epoch [77/100], Train Loss: 0.6907, \n",
      "Epoch [78/100], Train Loss: 0.6906, \n",
      "Epoch [79/100], Train Loss: 0.6916, \n",
      "Epoch [80/100], Train Loss: 0.6907, \n",
      "Epoch [81/100], Train Loss: 0.6907, \n",
      "Epoch [82/100], Train Loss: 0.6905, \n",
      "Epoch [83/100], Train Loss: 0.6904, \n",
      "Epoch [84/100], Train Loss: 0.6907, \n",
      "Epoch [85/100], Train Loss: 0.6910, \n",
      "Epoch [86/100], Train Loss: 0.6906, \n",
      "Epoch [87/100], Train Loss: 0.6909, \n",
      "Epoch [88/100], Train Loss: 0.6905, \n",
      "Epoch [89/100], Train Loss: 0.6917, \n",
      "Epoch [90/100], Train Loss: 0.6901, \n",
      "Epoch [91/100], Train Loss: 0.6909, \n",
      "Epoch [92/100], Train Loss: 0.6912, \n",
      "Epoch [93/100], Train Loss: 0.6910, \n",
      "Epoch [94/100], Train Loss: 0.6914, \n",
      "Epoch [95/100], Train Loss: 0.6917, \n",
      "Epoch [96/100], Train Loss: 0.6907, \n",
      "Epoch [97/100], Train Loss: 0.6903, \n",
      "Epoch [98/100], Train Loss: 0.6908, \n",
      "Epoch [99/100], Train Loss: 0.6899, \n",
      "Epoch [100/100], Train Loss: 0.6910, \n",
      "training loss at last epoch: 0.691\n",
      "seed = 1\n",
      "12000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 240.8923, \n",
      "Epoch [2/100], Train Loss: 54.2373, \n",
      "Epoch [3/100], Train Loss: 31.4771, \n",
      "Epoch [4/100], Train Loss: 60.2183, \n",
      "Epoch [5/100], Train Loss: 218.6122, \n",
      "Epoch [6/100], Train Loss: 189.7366, \n",
      "Epoch [7/100], Train Loss: 165.3969, \n",
      "Epoch [8/100], Train Loss: 141.8193, \n",
      "Epoch [9/100], Train Loss: 120.2259, \n",
      "Epoch [10/100], Train Loss: 100.3154, \n",
      "Epoch [11/100], Train Loss: 81.5864, \n",
      "Epoch [12/100], Train Loss: 64.4707, \n",
      "Epoch [13/100], Train Loss: 49.6195, \n",
      "Epoch [14/100], Train Loss: 37.5203, \n",
      "Epoch [15/100], Train Loss: 28.6269, \n",
      "Epoch [16/100], Train Loss: 22.6684, \n",
      "Epoch [17/100], Train Loss: 15.6406, \n",
      "Epoch [18/100], Train Loss: 19.8078, \n",
      "Epoch [19/100], Train Loss: 9.9368, \n",
      "Epoch [20/100], Train Loss: 12.6219, \n",
      "Epoch [21/100], Train Loss: 15.2346, \n",
      "Epoch [22/100], Train Loss: 9.3773, \n",
      "Epoch [23/100], Train Loss: 50.1895, \n",
      "Epoch [24/100], Train Loss: 36.5612, \n",
      "Epoch [25/100], Train Loss: 24.0725, \n",
      "Epoch [26/100], Train Loss: 16.1050, \n",
      "Epoch [27/100], Train Loss: 11.3858, \n",
      "Epoch [28/100], Train Loss: 25.1682, \n",
      "Epoch [29/100], Train Loss: 13.8423, \n",
      "Epoch [30/100], Train Loss: 10.6478, \n",
      "Epoch [31/100], Train Loss: 21.0858, \n",
      "Epoch [32/100], Train Loss: 13.2066, \n",
      "Epoch [33/100], Train Loss: 17.1067, \n",
      "Epoch [34/100], Train Loss: 76.3531, \n",
      "Epoch [35/100], Train Loss: 63.8403, \n",
      "Epoch [36/100], Train Loss: 52.0093, \n",
      "Epoch [37/100], Train Loss: 41.2415, \n",
      "Epoch [38/100], Train Loss: 31.1254, \n",
      "Epoch [39/100], Train Loss: 22.1988, \n",
      "Epoch [40/100], Train Loss: 16.1636, \n",
      "Epoch [41/100], Train Loss: 8.8852, \n",
      "Epoch [42/100], Train Loss: 17.4734, \n",
      "Epoch [43/100], Train Loss: 11.8676, \n",
      "Epoch [44/100], Train Loss: 9.0630, \n",
      "Epoch [45/100], Train Loss: 6.4689, \n",
      "Epoch [46/100], Train Loss: 53.2083, \n",
      "Epoch [47/100], Train Loss: 43.4710, \n",
      "Epoch [48/100], Train Loss: 34.4693, \n",
      "Epoch [49/100], Train Loss: 26.2613, \n",
      "Epoch [50/100], Train Loss: 18.7286, \n",
      "Epoch [51/100], Train Loss: 13.2727, \n",
      "Epoch [52/100], Train Loss: 7.9216, \n",
      "Epoch [53/100], Train Loss: 11.5781, \n",
      "Epoch [54/100], Train Loss: 6.8089, \n",
      "Epoch [55/100], Train Loss: 10.3478, \n",
      "Epoch [56/100], Train Loss: 8.2370, \n",
      "Epoch [57/100], Train Loss: 6.6924, \n",
      "Epoch [58/100], Train Loss: 7.7366, \n",
      "Epoch [59/100], Train Loss: 31.9067, \n",
      "Epoch [60/100], Train Loss: 24.8140, \n",
      "Epoch [61/100], Train Loss: 18.3125, \n",
      "Epoch [62/100], Train Loss: 12.1698, \n",
      "Epoch [63/100], Train Loss: 7.2325, \n",
      "Epoch [64/100], Train Loss: 6.7507, \n",
      "Epoch [65/100], Train Loss: 6.2304, \n",
      "Epoch [66/100], Train Loss: 2.5961, \n",
      "Epoch [67/100], Train Loss: 4.7101, \n",
      "Epoch [68/100], Train Loss: 12.4877, \n",
      "Epoch [69/100], Train Loss: 7.7311, \n",
      "Epoch [70/100], Train Loss: 6.1052, \n",
      "Epoch [71/100], Train Loss: 4.9833, \n",
      "Epoch [72/100], Train Loss: 4.4369, \n",
      "Epoch [73/100], Train Loss: 8.6369, \n",
      "Epoch [74/100], Train Loss: 4.7494, \n",
      "Epoch [75/100], Train Loss: 5.8179, \n",
      "Epoch [76/100], Train Loss: 4.4639, \n",
      "Epoch [77/100], Train Loss: 14.6166, \n",
      "Epoch [78/100], Train Loss: 9.5463, \n",
      "Epoch [79/100], Train Loss: 7.2225, \n",
      "Epoch [80/100], Train Loss: 4.7373, \n",
      "Epoch [81/100], Train Loss: 5.4169, \n",
      "Epoch [82/100], Train Loss: 5.3063, \n",
      "Epoch [83/100], Train Loss: 3.6983, \n",
      "Epoch [84/100], Train Loss: 6.8028, \n",
      "Epoch [85/100], Train Loss: 4.7604, \n",
      "Epoch [86/100], Train Loss: 3.9739, \n",
      "Epoch [87/100], Train Loss: 4.2636, \n",
      "Epoch [88/100], Train Loss: 5.0438, \n",
      "Epoch [89/100], Train Loss: 3.6733, \n",
      "Epoch [90/100], Train Loss: 9.2383, \n",
      "Epoch [91/100], Train Loss: 5.6418, \n",
      "Epoch [92/100], Train Loss: 4.5859, \n",
      "Epoch [93/100], Train Loss: 4.2285, \n",
      "Epoch [94/100], Train Loss: 4.3110, \n",
      "Epoch [95/100], Train Loss: 5.4341, \n",
      "Epoch [96/100], Train Loss: 16.9892, \n",
      "Epoch [97/100], Train Loss: 12.8578, \n",
      "Epoch [98/100], Train Loss: 9.0476, \n",
      "Epoch [99/100], Train Loss: 5.5540, \n",
      "Epoch [100/100], Train Loss: 2.9186, \n",
      "training loss at last epoch: 2.919\n",
      "Epoch [1/100], Train Loss: 38.6515, \n",
      "Epoch [2/100], Train Loss: 0.7066, \n",
      "Epoch [3/100], Train Loss: 0.6919, \n",
      "Epoch [4/100], Train Loss: 0.6911, \n",
      "Epoch [5/100], Train Loss: 0.6908, \n",
      "Epoch [6/100], Train Loss: 0.6914, \n",
      "Epoch [7/100], Train Loss: 0.6905, \n",
      "Epoch [8/100], Train Loss: 0.6909, \n",
      "Epoch [9/100], Train Loss: 0.6904, \n",
      "Epoch [10/100], Train Loss: 0.6910, \n",
      "Epoch [11/100], Train Loss: 0.6903, \n",
      "Epoch [12/100], Train Loss: 0.6914, \n",
      "Epoch [13/100], Train Loss: 0.6902, \n",
      "Epoch [14/100], Train Loss: 0.6899, \n",
      "Epoch [15/100], Train Loss: 0.6898, \n",
      "Epoch [16/100], Train Loss: 0.6920, \n",
      "Epoch [17/100], Train Loss: 0.6909, \n",
      "Epoch [18/100], Train Loss: 0.6908, \n",
      "Epoch [19/100], Train Loss: 0.6905, \n",
      "Epoch [20/100], Train Loss: 0.6907, \n",
      "Epoch [21/100], Train Loss: 0.6910, \n",
      "Epoch [22/100], Train Loss: 0.6907, \n",
      "Epoch [23/100], Train Loss: 0.6919, \n",
      "Epoch [24/100], Train Loss: 0.6910, \n",
      "Epoch [25/100], Train Loss: 0.6905, \n",
      "Epoch [26/100], Train Loss: 0.6900, \n",
      "Epoch [27/100], Train Loss: 0.6914, \n",
      "Epoch [28/100], Train Loss: 0.6902, \n",
      "Epoch [29/100], Train Loss: 0.7142, \n",
      "Epoch [30/100], Train Loss: 0.6927, \n",
      "Epoch [31/100], Train Loss: 0.6915, \n",
      "Epoch [32/100], Train Loss: 0.6915, \n",
      "Epoch [33/100], Train Loss: 0.6916, \n",
      "Epoch [34/100], Train Loss: 0.6912, \n",
      "Epoch [35/100], Train Loss: 0.6913, \n",
      "Epoch [36/100], Train Loss: 0.6922, \n",
      "Epoch [37/100], Train Loss: 0.6909, \n",
      "Epoch [38/100], Train Loss: 0.6912, \n",
      "Epoch [39/100], Train Loss: 0.6911, \n",
      "Epoch [40/100], Train Loss: 0.6910, \n",
      "Epoch [41/100], Train Loss: 0.6912, \n",
      "Epoch [42/100], Train Loss: 0.6923, \n",
      "Epoch [43/100], Train Loss: 0.6915, \n",
      "Epoch [44/100], Train Loss: 0.6912, \n",
      "Epoch [45/100], Train Loss: 0.6910, \n",
      "Epoch [46/100], Train Loss: 0.6912, \n",
      "Epoch [47/100], Train Loss: 0.6912, \n",
      "Epoch [48/100], Train Loss: 0.6924, \n",
      "Epoch [49/100], Train Loss: 0.6913, \n",
      "Epoch [50/100], Train Loss: 0.6910, \n",
      "Epoch [51/100], Train Loss: 0.6912, \n",
      "Epoch [52/100], Train Loss: 0.6919, \n",
      "Epoch [53/100], Train Loss: 0.6910, \n",
      "Epoch [54/100], Train Loss: 0.6910, \n",
      "Epoch [55/100], Train Loss: 0.6911, \n",
      "Epoch [56/100], Train Loss: 0.6907, \n",
      "Epoch [57/100], Train Loss: 0.6904, \n",
      "Epoch [58/100], Train Loss: 0.6907, \n",
      "Epoch [59/100], Train Loss: 0.6910, \n",
      "Epoch [60/100], Train Loss: 0.6911, \n",
      "Epoch [61/100], Train Loss: 0.6907, \n",
      "Epoch [62/100], Train Loss: 0.6912, \n",
      "Epoch [63/100], Train Loss: 0.6911, \n",
      "Epoch [64/100], Train Loss: 0.6904, \n",
      "Epoch [65/100], Train Loss: 0.6909, \n",
      "Epoch [66/100], Train Loss: 0.6904, \n",
      "Epoch [67/100], Train Loss: 0.6908, \n",
      "Epoch [68/100], Train Loss: 0.6905, \n",
      "Epoch [69/100], Train Loss: 0.6915, \n",
      "Epoch [70/100], Train Loss: 0.6913, \n",
      "Epoch [71/100], Train Loss: 0.6924, \n",
      "Epoch [72/100], Train Loss: 0.6917, \n",
      "Epoch [73/100], Train Loss: 0.6901, \n",
      "Epoch [74/100], Train Loss: 0.6920, \n",
      "Epoch [75/100], Train Loss: 0.6904, \n",
      "Epoch [76/100], Train Loss: 0.6910, \n",
      "Epoch [77/100], Train Loss: 0.6914, \n",
      "Epoch [78/100], Train Loss: 0.6922, \n",
      "Epoch [79/100], Train Loss: 0.6909, \n",
      "Epoch [80/100], Train Loss: 0.6916, \n",
      "Epoch [81/100], Train Loss: 0.6907, \n",
      "Epoch [82/100], Train Loss: 0.6913, \n",
      "Epoch [83/100], Train Loss: 0.6922, \n",
      "Epoch [84/100], Train Loss: 0.6924, \n",
      "Epoch [85/100], Train Loss: 0.6903, \n",
      "Epoch [86/100], Train Loss: 0.6905, \n",
      "Epoch [87/100], Train Loss: 0.6910, \n",
      "Epoch [88/100], Train Loss: 0.6906, \n",
      "Epoch [89/100], Train Loss: 0.6905, \n",
      "Epoch [90/100], Train Loss: 0.6904, \n",
      "Epoch [91/100], Train Loss: 0.6905, \n",
      "Epoch [92/100], Train Loss: 0.6920, \n",
      "Epoch [93/100], Train Loss: 0.6898, \n",
      "Epoch [94/100], Train Loss: 0.6915, \n",
      "Epoch [95/100], Train Loss: 0.6907, \n",
      "Epoch [96/100], Train Loss: 0.6908, \n",
      "Epoch [97/100], Train Loss: 0.6908, \n",
      "Epoch [98/100], Train Loss: 0.6920, \n",
      "Epoch [99/100], Train Loss: 0.6905, \n",
      "Epoch [100/100], Train Loss: 0.6906, \n",
      "training loss at last epoch: 0.691\n",
      "seed = 2\n",
      "12000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 404.4047, \n",
      "Epoch [2/100], Train Loss: 117.8540, \n",
      "Epoch [3/100], Train Loss: 49.5186, \n",
      "Epoch [4/100], Train Loss: 168.0278, \n",
      "Epoch [5/100], Train Loss: 66.3455, \n",
      "Epoch [6/100], Train Loss: 47.7851, \n",
      "Epoch [7/100], Train Loss: 131.2279, \n",
      "Epoch [8/100], Train Loss: 45.5280, \n",
      "Epoch [9/100], Train Loss: 59.6529, \n",
      "Epoch [10/100], Train Loss: 84.9974, \n",
      "Epoch [11/100], Train Loss: 43.5353, \n",
      "Epoch [12/100], Train Loss: 80.9171, \n",
      "Epoch [13/100], Train Loss: 26.0998, \n",
      "Epoch [14/100], Train Loss: 21.4704, \n",
      "Epoch [15/100], Train Loss: 15.5497, \n",
      "Epoch [16/100], Train Loss: 105.1806, \n",
      "Epoch [17/100], Train Loss: 48.9771, \n",
      "Epoch [18/100], Train Loss: 18.6898, \n",
      "Epoch [19/100], Train Loss: 18.4746, \n",
      "Epoch [20/100], Train Loss: 14.6399, \n",
      "Epoch [21/100], Train Loss: 27.3654, \n",
      "Epoch [22/100], Train Loss: 11.2088, \n",
      "Epoch [23/100], Train Loss: 15.9995, \n",
      "Epoch [24/100], Train Loss: 13.1182, \n",
      "Epoch [25/100], Train Loss: 14.9724, \n",
      "Epoch [26/100], Train Loss: 10.0896, \n",
      "Epoch [27/100], Train Loss: 10.8664, \n",
      "Epoch [28/100], Train Loss: 19.4213, \n",
      "Epoch [29/100], Train Loss: 15.8652, \n",
      "Epoch [30/100], Train Loss: 10.5272, \n",
      "Epoch [31/100], Train Loss: 10.9752, \n",
      "Epoch [32/100], Train Loss: 10.3608, \n",
      "Epoch [33/100], Train Loss: 11.2437, \n",
      "Epoch [34/100], Train Loss: 9.8225, \n",
      "Epoch [35/100], Train Loss: 12.2253, \n",
      "Epoch [36/100], Train Loss: 11.0539, \n",
      "Epoch [37/100], Train Loss: 13.6247, \n",
      "Epoch [38/100], Train Loss: 5.7476, \n",
      "Epoch [39/100], Train Loss: 7.6191, \n",
      "Epoch [40/100], Train Loss: 5.8957, \n",
      "Epoch [41/100], Train Loss: 8.4274, \n",
      "Epoch [42/100], Train Loss: 8.1107, \n",
      "Epoch [43/100], Train Loss: 7.7577, \n",
      "Epoch [44/100], Train Loss: 5.8401, \n",
      "Epoch [45/100], Train Loss: 6.5135, \n",
      "Epoch [46/100], Train Loss: 11.7719, \n",
      "Epoch [47/100], Train Loss: 3.8674, \n",
      "Epoch [48/100], Train Loss: 8.4725, \n",
      "Epoch [49/100], Train Loss: 7.0340, \n",
      "Epoch [50/100], Train Loss: 5.9315, \n",
      "Epoch [51/100], Train Loss: 7.9991, \n",
      "Epoch [52/100], Train Loss: 3.8896, \n",
      "Epoch [53/100], Train Loss: 4.0023, \n",
      "Epoch [54/100], Train Loss: 9.9510, \n",
      "Epoch [55/100], Train Loss: 7.0846, \n",
      "Epoch [56/100], Train Loss: 6.5159, \n",
      "Epoch [57/100], Train Loss: 6.5494, \n",
      "Epoch [58/100], Train Loss: 5.1243, \n",
      "Epoch [59/100], Train Loss: 8.5879, \n",
      "Epoch [60/100], Train Loss: 4.5193, \n",
      "Epoch [61/100], Train Loss: 6.3698, \n",
      "Epoch [62/100], Train Loss: 5.9517, \n",
      "Epoch [63/100], Train Loss: 10.7874, \n",
      "Epoch [64/100], Train Loss: 6.3856, \n",
      "Epoch [65/100], Train Loss: 5.1133, \n",
      "Epoch [66/100], Train Loss: 6.1193, \n",
      "Epoch [67/100], Train Loss: 2.1715, \n",
      "Epoch [68/100], Train Loss: 5.1736, \n",
      "Epoch [69/100], Train Loss: 2.6288, \n",
      "Epoch [70/100], Train Loss: 5.6026, \n",
      "Epoch [71/100], Train Loss: 5.9021, \n",
      "Epoch [72/100], Train Loss: 4.2161, \n",
      "Epoch [73/100], Train Loss: 6.0667, \n",
      "Epoch [74/100], Train Loss: 5.1767, \n",
      "Epoch [75/100], Train Loss: 3.8921, \n",
      "Epoch [76/100], Train Loss: 5.0803, \n",
      "Epoch [77/100], Train Loss: 3.7426, \n",
      "Epoch [78/100], Train Loss: 2.5121, \n",
      "Epoch [79/100], Train Loss: 3.6844, \n",
      "Epoch [80/100], Train Loss: 3.0923, \n",
      "Epoch [81/100], Train Loss: 5.2864, \n",
      "Epoch [82/100], Train Loss: 3.6424, \n",
      "Epoch [83/100], Train Loss: 4.7674, \n",
      "Epoch [84/100], Train Loss: 2.6047, \n",
      "Epoch [85/100], Train Loss: 4.6152, \n",
      "Epoch [86/100], Train Loss: 2.8705, \n",
      "Epoch [87/100], Train Loss: 6.7136, \n",
      "Epoch [88/100], Train Loss: 3.5170, \n",
      "Epoch [89/100], Train Loss: 3.3903, \n",
      "Epoch [90/100], Train Loss: 4.9116, \n",
      "Epoch [91/100], Train Loss: 1.8616, \n",
      "Epoch [92/100], Train Loss: 3.1008, \n",
      "Epoch [93/100], Train Loss: 2.9752, \n",
      "Epoch [94/100], Train Loss: 4.3562, \n",
      "Epoch [95/100], Train Loss: 4.1904, \n",
      "Epoch [96/100], Train Loss: 2.3265, \n",
      "Epoch [97/100], Train Loss: 2.4617, \n",
      "Epoch [98/100], Train Loss: 3.2697, \n",
      "Epoch [99/100], Train Loss: 3.0234, \n",
      "Epoch [100/100], Train Loss: 2.9061, \n",
      "training loss at last epoch: 2.906\n",
      "Epoch [1/100], Train Loss: 23.8458, \n",
      "Epoch [2/100], Train Loss: 0.7642, \n",
      "Epoch [3/100], Train Loss: 0.7031, \n",
      "Epoch [4/100], Train Loss: 0.7024, \n",
      "Epoch [5/100], Train Loss: 0.6991, \n",
      "Epoch [6/100], Train Loss: 0.6982, \n",
      "Epoch [7/100], Train Loss: 0.7066, \n",
      "Epoch [8/100], Train Loss: 0.6949, \n",
      "Epoch [9/100], Train Loss: 0.6949, \n",
      "Epoch [10/100], Train Loss: 0.7278, \n",
      "Epoch [11/100], Train Loss: 0.6969, \n",
      "Epoch [12/100], Train Loss: 0.6929, \n",
      "Epoch [13/100], Train Loss: 0.6919, \n",
      "Epoch [14/100], Train Loss: 0.6916, \n",
      "Epoch [15/100], Train Loss: 0.6921, \n",
      "Epoch [16/100], Train Loss: 0.6912, \n",
      "Epoch [17/100], Train Loss: 0.6912, \n",
      "Epoch [18/100], Train Loss: 0.6917, \n",
      "Epoch [19/100], Train Loss: 0.6910, \n",
      "Epoch [20/100], Train Loss: 0.6912, \n",
      "Epoch [21/100], Train Loss: 0.6910, \n",
      "Epoch [22/100], Train Loss: 0.6907, \n",
      "Epoch [23/100], Train Loss: 0.6907, \n",
      "Epoch [24/100], Train Loss: 0.6906, \n",
      "Epoch [25/100], Train Loss: 0.6911, \n",
      "Epoch [26/100], Train Loss: 0.6911, \n",
      "Epoch [27/100], Train Loss: 0.6905, \n",
      "Epoch [28/100], Train Loss: 0.6908, \n",
      "Epoch [29/100], Train Loss: 0.6917, \n",
      "Epoch [30/100], Train Loss: 0.6906, \n",
      "Epoch [31/100], Train Loss: 0.6914, \n",
      "Epoch [32/100], Train Loss: 0.6920, \n",
      "Epoch [33/100], Train Loss: 0.6914, \n",
      "Epoch [34/100], Train Loss: 0.6901, \n",
      "Epoch [35/100], Train Loss: 0.6915, \n",
      "Epoch [36/100], Train Loss: 0.6905, \n",
      "Epoch [37/100], Train Loss: 0.6905, \n",
      "Epoch [38/100], Train Loss: 0.6907, \n",
      "Epoch [39/100], Train Loss: 0.6909, \n",
      "Epoch [40/100], Train Loss: 0.6917, \n",
      "Epoch [41/100], Train Loss: 0.6905, \n",
      "Epoch [42/100], Train Loss: 0.6894, \n",
      "Epoch [43/100], Train Loss: 0.6905, \n",
      "Epoch [44/100], Train Loss: 0.6906, \n",
      "Epoch [45/100], Train Loss: 0.6902, \n",
      "Epoch [46/100], Train Loss: 0.6893, \n",
      "Epoch [47/100], Train Loss: 0.6925, \n",
      "Epoch [48/100], Train Loss: 0.6900, \n",
      "Epoch [49/100], Train Loss: 0.6906, \n",
      "Epoch [50/100], Train Loss: 0.6909, \n",
      "Epoch [51/100], Train Loss: 0.6908, \n",
      "Epoch [52/100], Train Loss: 0.6906, \n",
      "Epoch [53/100], Train Loss: 0.6907, \n",
      "Epoch [54/100], Train Loss: 0.6909, \n",
      "Epoch [55/100], Train Loss: 0.6905, \n",
      "Epoch [56/100], Train Loss: 0.6908, \n",
      "Epoch [57/100], Train Loss: 0.6899, \n",
      "Epoch [58/100], Train Loss: 0.6901, \n",
      "Epoch [59/100], Train Loss: 0.6897, \n",
      "Epoch [60/100], Train Loss: 0.6895, \n",
      "Epoch [61/100], Train Loss: 0.6895, \n",
      "Epoch [62/100], Train Loss: 0.6899, \n",
      "Epoch [63/100], Train Loss: 0.6899, \n",
      "Epoch [64/100], Train Loss: 0.6909, \n",
      "Epoch [65/100], Train Loss: 0.6904, \n",
      "Epoch [66/100], Train Loss: 0.6910, \n",
      "Epoch [67/100], Train Loss: 0.6909, \n",
      "Epoch [68/100], Train Loss: 0.6927, \n",
      "Epoch [69/100], Train Loss: 0.6912, \n",
      "Epoch [70/100], Train Loss: 0.6903, \n",
      "Epoch [71/100], Train Loss: 0.6920, \n",
      "Epoch [72/100], Train Loss: 0.6902, \n",
      "Epoch [73/100], Train Loss: 0.6899, \n",
      "Epoch [74/100], Train Loss: 0.6904, \n",
      "Epoch [75/100], Train Loss: 0.6899, \n",
      "Epoch [76/100], Train Loss: 0.6905, \n",
      "Epoch [77/100], Train Loss: 0.6921, \n",
      "Epoch [78/100], Train Loss: 0.6899, \n",
      "Epoch [79/100], Train Loss: 0.6909, \n",
      "Epoch [80/100], Train Loss: 0.6903, \n",
      "Epoch [81/100], Train Loss: 0.6895, \n",
      "Epoch [82/100], Train Loss: 0.6897, \n",
      "Epoch [83/100], Train Loss: 0.6888, \n",
      "Epoch [84/100], Train Loss: 0.6924, \n",
      "Epoch [85/100], Train Loss: 0.6907, \n",
      "Epoch [86/100], Train Loss: 0.6909, \n",
      "Epoch [87/100], Train Loss: 0.6909, \n",
      "Epoch [88/100], Train Loss: 0.6913, \n",
      "Epoch [89/100], Train Loss: 0.6913, \n",
      "Epoch [90/100], Train Loss: 0.6902, \n",
      "Epoch [91/100], Train Loss: 0.6905, \n",
      "Epoch [92/100], Train Loss: 0.6911, \n",
      "Epoch [93/100], Train Loss: 0.6900, \n",
      "Epoch [94/100], Train Loss: 0.6916, \n",
      "Epoch [95/100], Train Loss: 0.6915, \n",
      "Epoch [96/100], Train Loss: 0.6911, \n",
      "Epoch [97/100], Train Loss: 0.6902, \n",
      "Epoch [98/100], Train Loss: 0.6903, \n",
      "Epoch [99/100], Train Loss: 0.6905, \n",
      "Epoch [100/100], Train Loss: 0.6898, \n",
      "training loss at last epoch: 0.690\n",
      "time t = 350\n",
      "seed = 0\n",
      "14000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 698.7429, \n",
      "Epoch [2/100], Train Loss: 7863.8306, \n",
      "Epoch [3/100], Train Loss: 4548.0089, \n",
      "Epoch [4/100], Train Loss: 2335.7484, \n",
      "Epoch [5/100], Train Loss: 3457.4497, \n",
      "Epoch [6/100], Train Loss: 8479.1435, \n",
      "Epoch [7/100], Train Loss: 15074.1479, \n",
      "Epoch [8/100], Train Loss: 11804.0041, \n",
      "Epoch [9/100], Train Loss: 8818.7601, \n",
      "Epoch [10/100], Train Loss: 5839.6490, \n",
      "Epoch [11/100], Train Loss: 3073.1687, \n",
      "Epoch [12/100], Train Loss: 3387.1300, \n",
      "Epoch [13/100], Train Loss: 5734.5393, \n",
      "Epoch [14/100], Train Loss: 3075.8917, \n",
      "Epoch [15/100], Train Loss: 3739.8899, \n",
      "Epoch [16/100], Train Loss: 10384.2329, \n",
      "Epoch [17/100], Train Loss: 7792.6026, \n",
      "Epoch [18/100], Train Loss: 5287.4111, \n",
      "Epoch [19/100], Train Loss: 2864.8405, \n",
      "Epoch [20/100], Train Loss: 4103.2379, \n",
      "Epoch [21/100], Train Loss: 10967.0945, \n",
      "Epoch [22/100], Train Loss: 8565.0704, \n",
      "Epoch [23/100], Train Loss: 6240.1452, \n",
      "Epoch [24/100], Train Loss: 4110.3543, \n",
      "Epoch [25/100], Train Loss: 2040.4551, \n",
      "Epoch [26/100], Train Loss: 781.6626, \n",
      "Epoch [27/100], Train Loss: 6837.6991, \n",
      "Epoch [28/100], Train Loss: 4794.0823, \n",
      "Epoch [29/100], Train Loss: 2845.9352, \n",
      "Epoch [30/100], Train Loss: 1338.9949, \n",
      "Epoch [31/100], Train Loss: 2481.8695, \n",
      "Epoch [32/100], Train Loss: 6618.0210, \n",
      "Epoch [33/100], Train Loss: 11370.2718, \n",
      "Epoch [34/100], Train Loss: 9324.1408, \n",
      "Epoch [35/100], Train Loss: 7469.8973, \n",
      "Epoch [36/100], Train Loss: 5786.3767, \n",
      "Epoch [37/100], Train Loss: 4122.3788, \n",
      "Epoch [38/100], Train Loss: 2753.9854, \n",
      "Epoch [39/100], Train Loss: 1503.1398, \n",
      "Epoch [40/100], Train Loss: 8640.6184, \n",
      "Epoch [41/100], Train Loss: 7073.9801, \n",
      "Epoch [42/100], Train Loss: 5568.4438, \n",
      "Epoch [43/100], Train Loss: 4138.5707, \n",
      "Epoch [44/100], Train Loss: 2824.0202, \n",
      "Epoch [45/100], Train Loss: 1568.3571, \n",
      "Epoch [46/100], Train Loss: 784.1966, \n",
      "Epoch [47/100], Train Loss: 7305.7324, \n",
      "Epoch [48/100], Train Loss: 5995.9530, \n",
      "Epoch [49/100], Train Loss: 4735.8569, \n",
      "Epoch [50/100], Train Loss: 3585.1130, \n",
      "Epoch [51/100], Train Loss: 2486.1522, \n",
      "Epoch [52/100], Train Loss: 1442.6235, \n",
      "Epoch [53/100], Train Loss: 1289.7164, \n",
      "Epoch [54/100], Train Loss: 1318.0834, \n",
      "Epoch [55/100], Train Loss: 458.7333, \n",
      "Epoch [56/100], Train Loss: 1532.4814, \n",
      "Epoch [57/100], Train Loss: 755.1974, \n",
      "Epoch [58/100], Train Loss: 3459.3788, \n",
      "Epoch [59/100], Train Loss: 2497.0491, \n",
      "Epoch [60/100], Train Loss: 1573.1625, \n",
      "Epoch [61/100], Train Loss: 1328.7507, \n",
      "Epoch [62/100], Train Loss: 12593.0208, \n",
      "Epoch [63/100], Train Loss: 11179.0098, \n",
      "Epoch [64/100], Train Loss: 9894.1150, \n",
      "Epoch [65/100], Train Loss: 8771.3097, \n",
      "Epoch [66/100], Train Loss: 7772.1173, \n",
      "Epoch [67/100], Train Loss: 6860.5919, \n",
      "Epoch [68/100], Train Loss: 6077.7214, \n",
      "Epoch [69/100], Train Loss: 5341.8579, \n",
      "Epoch [70/100], Train Loss: 4669.5039, \n",
      "Epoch [71/100], Train Loss: 4093.9236, \n",
      "Epoch [72/100], Train Loss: 3545.1162, \n",
      "Epoch [73/100], Train Loss: 3043.8613, \n",
      "Epoch [74/100], Train Loss: 2615.4645, \n",
      "Epoch [75/100], Train Loss: 2204.2087, \n",
      "Epoch [76/100], Train Loss: 1839.7028, \n",
      "Epoch [77/100], Train Loss: 1485.5630, \n",
      "Epoch [78/100], Train Loss: 1163.1856, \n",
      "Epoch [79/100], Train Loss: 862.4422, \n",
      "Epoch [80/100], Train Loss: 581.9520, \n",
      "Epoch [81/100], Train Loss: 306.7032, \n",
      "Epoch [82/100], Train Loss: 385.0152, \n",
      "Epoch [83/100], Train Loss: 1930.1972, \n",
      "Epoch [84/100], Train Loss: 1598.8624, \n",
      "Epoch [85/100], Train Loss: 1311.5868, \n",
      "Epoch [86/100], Train Loss: 1050.7939, \n",
      "Epoch [87/100], Train Loss: 809.1596, \n",
      "Epoch [88/100], Train Loss: 587.5547, \n",
      "Epoch [89/100], Train Loss: 369.4640, \n",
      "Epoch [90/100], Train Loss: 172.3497, \n",
      "Epoch [91/100], Train Loss: 1086.6353, \n",
      "Epoch [92/100], Train Loss: 3355.6999, \n",
      "Epoch [93/100], Train Loss: 2978.3848, \n",
      "Epoch [94/100], Train Loss: 2613.3771, \n",
      "Epoch [95/100], Train Loss: 2325.6282, \n",
      "Epoch [96/100], Train Loss: 2081.7077, \n",
      "Epoch [97/100], Train Loss: 1846.9780, \n",
      "Epoch [98/100], Train Loss: 1644.4989, \n",
      "Epoch [99/100], Train Loss: 1453.1338, \n",
      "Epoch [100/100], Train Loss: 1287.2877, \n",
      "training loss at last epoch: 1287.288\n",
      "Epoch [1/100], Train Loss: 59.1766, \n",
      "Epoch [2/100], Train Loss: 3.7587, \n",
      "Epoch [3/100], Train Loss: 0.8605, \n",
      "Epoch [4/100], Train Loss: 0.7993, \n",
      "Epoch [5/100], Train Loss: 0.7588, \n",
      "Epoch [6/100], Train Loss: 0.7276, \n",
      "Epoch [7/100], Train Loss: 0.7376, \n",
      "Epoch [8/100], Train Loss: 0.7110, \n",
      "Epoch [9/100], Train Loss: 0.7102, \n",
      "Epoch [10/100], Train Loss: 0.7069, \n",
      "Epoch [11/100], Train Loss: 0.7062, \n",
      "Epoch [12/100], Train Loss: 0.7008, \n",
      "Epoch [13/100], Train Loss: 0.7065, \n",
      "Epoch [14/100], Train Loss: 0.6995, \n",
      "Epoch [15/100], Train Loss: 0.6914, \n",
      "Epoch [16/100], Train Loss: 0.7061, \n",
      "Epoch [17/100], Train Loss: 0.6970, \n",
      "Epoch [18/100], Train Loss: 0.6981, \n",
      "Epoch [19/100], Train Loss: 0.6962, \n",
      "Epoch [20/100], Train Loss: 0.6943, \n",
      "Epoch [21/100], Train Loss: 0.6960, \n",
      "Epoch [22/100], Train Loss: 0.6929, \n",
      "Epoch [23/100], Train Loss: 0.6967, \n",
      "Epoch [24/100], Train Loss: 0.6943, \n",
      "Epoch [25/100], Train Loss: 0.6917, \n",
      "Epoch [26/100], Train Loss: 0.6937, \n",
      "Epoch [27/100], Train Loss: 0.6932, \n",
      "Epoch [28/100], Train Loss: 0.6925, \n",
      "Epoch [29/100], Train Loss: 0.6928, \n",
      "Epoch [30/100], Train Loss: 0.6921, \n",
      "Epoch [31/100], Train Loss: 0.6966, \n",
      "Epoch [32/100], Train Loss: 0.6925, \n",
      "Epoch [33/100], Train Loss: 0.6924, \n",
      "Epoch [34/100], Train Loss: 0.6918, \n",
      "Epoch [35/100], Train Loss: 0.6934, \n",
      "Epoch [36/100], Train Loss: 0.6924, \n",
      "Epoch [37/100], Train Loss: 0.6931, \n",
      "Epoch [38/100], Train Loss: 0.6915, \n",
      "Epoch [39/100], Train Loss: 0.6943, \n",
      "Epoch [40/100], Train Loss: 0.6925, \n",
      "Epoch [41/100], Train Loss: 0.6926, \n",
      "Epoch [42/100], Train Loss: 0.6927, \n",
      "Epoch [43/100], Train Loss: 0.6925, \n",
      "Epoch [44/100], Train Loss: 0.6925, \n",
      "Epoch [45/100], Train Loss: 0.6919, \n",
      "Epoch [46/100], Train Loss: 0.6930, \n",
      "Epoch [47/100], Train Loss: 0.6923, \n",
      "Epoch [48/100], Train Loss: 0.6917, \n",
      "Epoch [49/100], Train Loss: 0.6912, \n",
      "Epoch [50/100], Train Loss: 0.6923, \n",
      "Epoch [51/100], Train Loss: 0.6917, \n",
      "Epoch [52/100], Train Loss: 0.6927, \n",
      "Epoch [53/100], Train Loss: 0.6921, \n",
      "Epoch [54/100], Train Loss: 0.6922, \n",
      "Epoch [55/100], Train Loss: 0.6924, \n",
      "Epoch [56/100], Train Loss: 0.6913, \n",
      "Epoch [57/100], Train Loss: 0.6919, \n",
      "Epoch [58/100], Train Loss: 0.6912, \n",
      "Epoch [59/100], Train Loss: 0.6925, \n",
      "Epoch [60/100], Train Loss: 0.6921, \n",
      "Epoch [61/100], Train Loss: 0.6916, \n",
      "Epoch [62/100], Train Loss: 0.6925, \n",
      "Epoch [63/100], Train Loss: 0.6923, \n",
      "Epoch [64/100], Train Loss: 0.6921, \n",
      "Epoch [65/100], Train Loss: 0.6919, \n",
      "Epoch [66/100], Train Loss: 0.6914, \n",
      "Epoch [67/100], Train Loss: 0.6917, \n",
      "Epoch [68/100], Train Loss: 0.6918, \n",
      "Epoch [69/100], Train Loss: 0.6919, \n",
      "Epoch [70/100], Train Loss: 0.6916, \n",
      "Epoch [71/100], Train Loss: 0.6919, \n",
      "Epoch [72/100], Train Loss: 0.6924, \n",
      "Epoch [73/100], Train Loss: 0.6922, \n",
      "Epoch [74/100], Train Loss: 0.6920, \n",
      "Epoch [75/100], Train Loss: 0.6913, \n",
      "Epoch [76/100], Train Loss: 0.6915, \n",
      "Epoch [77/100], Train Loss: 0.6916, \n",
      "Epoch [78/100], Train Loss: 0.6920, \n",
      "Epoch [79/100], Train Loss: 0.6910, \n",
      "Epoch [80/100], Train Loss: 0.6921, \n",
      "Epoch [81/100], Train Loss: 0.6918, \n",
      "Epoch [82/100], Train Loss: 0.6924, \n",
      "Epoch [83/100], Train Loss: 0.6922, \n",
      "Epoch [84/100], Train Loss: 0.6926, \n",
      "Epoch [85/100], Train Loss: 0.6907, \n",
      "Epoch [86/100], Train Loss: 0.6918, \n",
      "Epoch [87/100], Train Loss: 0.6914, \n",
      "Epoch [88/100], Train Loss: 0.6920, \n",
      "Epoch [89/100], Train Loss: 0.6918, \n",
      "Epoch [90/100], Train Loss: 0.6920, \n",
      "Epoch [91/100], Train Loss: 0.6919, \n",
      "Epoch [92/100], Train Loss: 0.6919, \n",
      "Epoch [93/100], Train Loss: 0.6927, \n",
      "Epoch [94/100], Train Loss: 0.6914, \n",
      "Epoch [95/100], Train Loss: 0.6923, \n",
      "Epoch [96/100], Train Loss: 0.6919, \n",
      "Epoch [97/100], Train Loss: 0.6921, \n",
      "Epoch [98/100], Train Loss: 0.6922, \n",
      "Epoch [99/100], Train Loss: 0.6908, \n",
      "Epoch [100/100], Train Loss: 0.6915, \n",
      "training loss at last epoch: 0.691\n",
      "seed = 1\n",
      "14000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 306.6401, \n",
      "Epoch [2/100], Train Loss: 20.6754, \n",
      "Epoch [3/100], Train Loss: 8.3194, \n",
      "Epoch [4/100], Train Loss: 23.0165, \n",
      "Epoch [5/100], Train Loss: 30.7072, \n",
      "Epoch [6/100], Train Loss: 151.4679, \n",
      "Epoch [7/100], Train Loss: 128.5958, \n",
      "Epoch [8/100], Train Loss: 106.3084, \n",
      "Epoch [9/100], Train Loss: 86.8485, \n",
      "Epoch [10/100], Train Loss: 68.2927, \n",
      "Epoch [11/100], Train Loss: 50.6622, \n",
      "Epoch [12/100], Train Loss: 33.8262, \n",
      "Epoch [13/100], Train Loss: 21.3575, \n",
      "Epoch [14/100], Train Loss: 15.5067, \n",
      "Epoch [15/100], Train Loss: 28.2455, \n",
      "Epoch [16/100], Train Loss: 109.8858, \n",
      "Epoch [17/100], Train Loss: 92.8936, \n",
      "Epoch [18/100], Train Loss: 76.2704, \n",
      "Epoch [19/100], Train Loss: 61.0859, \n",
      "Epoch [20/100], Train Loss: 46.7478, \n",
      "Epoch [21/100], Train Loss: 34.8166, \n",
      "Epoch [22/100], Train Loss: 25.6197, \n",
      "Epoch [23/100], Train Loss: 18.3476, \n",
      "Epoch [24/100], Train Loss: 15.4429, \n",
      "Epoch [25/100], Train Loss: 11.2308, \n",
      "Epoch [26/100], Train Loss: 11.6697, \n",
      "Epoch [27/100], Train Loss: 10.2189, \n",
      "Epoch [28/100], Train Loss: 18.1464, \n",
      "Epoch [29/100], Train Loss: 15.2781, \n",
      "Epoch [30/100], Train Loss: 41.4576, \n",
      "Epoch [31/100], Train Loss: 30.0218, \n",
      "Epoch [32/100], Train Loss: 19.5733, \n",
      "Epoch [33/100], Train Loss: 11.7186, \n",
      "Epoch [34/100], Train Loss: 10.0474, \n",
      "Epoch [35/100], Train Loss: 13.9594, \n",
      "Epoch [36/100], Train Loss: 9.7964, \n",
      "Epoch [37/100], Train Loss: 21.2758, \n",
      "Epoch [38/100], Train Loss: 12.2348, \n",
      "Epoch [39/100], Train Loss: 6.3474, \n",
      "Epoch [40/100], Train Loss: 74.8455, \n",
      "Epoch [41/100], Train Loss: 63.7556, \n",
      "Epoch [42/100], Train Loss: 53.5769, \n",
      "Epoch [43/100], Train Loss: 44.1803, \n",
      "Epoch [44/100], Train Loss: 35.5548, \n",
      "Epoch [45/100], Train Loss: 27.5007, \n",
      "Epoch [46/100], Train Loss: 21.0031, \n",
      "Epoch [47/100], Train Loss: 15.4767, \n",
      "Epoch [48/100], Train Loss: 11.6933, \n",
      "Epoch [49/100], Train Loss: 10.5114, \n",
      "Epoch [50/100], Train Loss: 7.6641, \n",
      "Epoch [51/100], Train Loss: 12.7917, \n",
      "Epoch [52/100], Train Loss: 7.8005, \n",
      "Epoch [53/100], Train Loss: 7.9847, \n",
      "Epoch [54/100], Train Loss: 3.4380, \n",
      "Epoch [55/100], Train Loss: 4.8630, \n",
      "Epoch [56/100], Train Loss: 8.4194, \n",
      "Epoch [57/100], Train Loss: 8.2414, \n",
      "Epoch [58/100], Train Loss: 30.8072, \n",
      "Epoch [59/100], Train Loss: 24.1801, \n",
      "Epoch [60/100], Train Loss: 18.0889, \n",
      "Epoch [61/100], Train Loss: 12.3586, \n",
      "Epoch [62/100], Train Loss: 7.9307, \n",
      "Epoch [63/100], Train Loss: 4.8296, \n",
      "Epoch [64/100], Train Loss: 81.9913, \n",
      "Epoch [65/100], Train Loss: 73.0109, \n",
      "Epoch [66/100], Train Loss: 64.5849, \n",
      "Epoch [67/100], Train Loss: 57.3573, \n",
      "Epoch [68/100], Train Loss: 50.8290, \n",
      "Epoch [69/100], Train Loss: 45.1216, \n",
      "Epoch [70/100], Train Loss: 39.5985, \n",
      "Epoch [71/100], Train Loss: 34.8555, \n",
      "Epoch [72/100], Train Loss: 30.3950, \n",
      "Epoch [73/100], Train Loss: 26.3421, \n",
      "Epoch [74/100], Train Loss: 22.6902, \n",
      "Epoch [75/100], Train Loss: 19.2482, \n",
      "Epoch [76/100], Train Loss: 16.1732, \n",
      "Epoch [77/100], Train Loss: 13.1943, \n",
      "Epoch [78/100], Train Loss: 10.4502, \n",
      "Epoch [79/100], Train Loss: 8.0552, \n",
      "Epoch [80/100], Train Loss: 6.5880, \n",
      "Epoch [81/100], Train Loss: 6.2340, \n",
      "Epoch [82/100], Train Loss: 5.1661, \n",
      "Epoch [83/100], Train Loss: 4.8816, \n",
      "Epoch [84/100], Train Loss: 3.5545, \n",
      "Epoch [85/100], Train Loss: 2.4852, \n",
      "Epoch [86/100], Train Loss: 1.4449, \n",
      "Epoch [87/100], Train Loss: 2.3084, \n",
      "Epoch [88/100], Train Loss: 2.7657, \n",
      "Epoch [89/100], Train Loss: 3.0322, \n",
      "Epoch [90/100], Train Loss: 2.1458, \n",
      "Epoch [91/100], Train Loss: 2.8624, \n",
      "Epoch [92/100], Train Loss: 2.2049, \n",
      "Epoch [93/100], Train Loss: 2.1349, \n",
      "Epoch [94/100], Train Loss: 1.4039, \n",
      "Epoch [95/100], Train Loss: 2.2498, \n",
      "Epoch [96/100], Train Loss: 1.3945, \n",
      "Epoch [97/100], Train Loss: 1.9768, \n",
      "Epoch [98/100], Train Loss: 1.3312, \n",
      "Epoch [99/100], Train Loss: 2.0249, \n",
      "Epoch [100/100], Train Loss: 1.7537, \n",
      "training loss at last epoch: 1.754\n",
      "Epoch [1/100], Train Loss: 107.0253, \n",
      "Epoch [2/100], Train Loss: 1.0468, \n",
      "Epoch [3/100], Train Loss: 0.6916, \n",
      "Epoch [4/100], Train Loss: 0.6916, \n",
      "Epoch [5/100], Train Loss: 0.6907, \n",
      "Epoch [6/100], Train Loss: 0.6923, \n",
      "Epoch [7/100], Train Loss: 0.6917, \n",
      "Epoch [8/100], Train Loss: 0.6919, \n",
      "Epoch [9/100], Train Loss: 0.6926, \n",
      "Epoch [10/100], Train Loss: 0.6919, \n",
      "Epoch [11/100], Train Loss: 0.6918, \n",
      "Epoch [12/100], Train Loss: 0.6911, \n",
      "Epoch [13/100], Train Loss: 0.6925, \n",
      "Epoch [14/100], Train Loss: 0.6914, \n",
      "Epoch [15/100], Train Loss: 0.6913, \n",
      "Epoch [16/100], Train Loss: 0.6908, \n",
      "Epoch [17/100], Train Loss: 0.6911, \n",
      "Epoch [18/100], Train Loss: 0.6913, \n",
      "Epoch [19/100], Train Loss: 0.6923, \n",
      "Epoch [20/100], Train Loss: 0.6924, \n",
      "Epoch [21/100], Train Loss: 0.6919, \n",
      "Epoch [22/100], Train Loss: 0.6913, \n",
      "Epoch [23/100], Train Loss: 0.6934, \n",
      "Epoch [24/100], Train Loss: 0.6918, \n",
      "Epoch [25/100], Train Loss: 0.6922, \n",
      "Epoch [26/100], Train Loss: 0.6922, \n",
      "Epoch [27/100], Train Loss: 0.6926, \n",
      "Epoch [28/100], Train Loss: 0.6916, \n",
      "Epoch [29/100], Train Loss: 0.6914, \n",
      "Epoch [30/100], Train Loss: 0.6919, \n",
      "Epoch [31/100], Train Loss: 0.6911, \n",
      "Epoch [32/100], Train Loss: 0.6914, \n",
      "Epoch [33/100], Train Loss: 0.6912, \n",
      "Epoch [34/100], Train Loss: 0.6909, \n",
      "Epoch [35/100], Train Loss: 0.6916, \n",
      "Epoch [36/100], Train Loss: 0.6907, \n",
      "Epoch [37/100], Train Loss: 0.6915, \n",
      "Epoch [38/100], Train Loss: 0.6898, \n",
      "Epoch [39/100], Train Loss: 0.6935, \n",
      "Epoch [40/100], Train Loss: 0.6921, \n",
      "Epoch [41/100], Train Loss: 0.6913, \n",
      "Epoch [42/100], Train Loss: 0.6914, \n",
      "Epoch [43/100], Train Loss: 0.6910, \n",
      "Epoch [44/100], Train Loss: 0.6912, \n",
      "Epoch [45/100], Train Loss: 0.6920, \n",
      "Epoch [46/100], Train Loss: 0.6914, \n",
      "Epoch [47/100], Train Loss: 0.6917, \n",
      "Epoch [48/100], Train Loss: 0.6913, \n",
      "Epoch [49/100], Train Loss: 0.6914, \n",
      "Epoch [50/100], Train Loss: 0.6910, \n",
      "Epoch [51/100], Train Loss: 0.6918, \n",
      "Epoch [52/100], Train Loss: 0.6915, \n",
      "Epoch [53/100], Train Loss: 0.6920, \n",
      "Epoch [54/100], Train Loss: 0.6926, \n",
      "Epoch [55/100], Train Loss: 0.6915, \n",
      "Epoch [56/100], Train Loss: 0.6916, \n",
      "Epoch [57/100], Train Loss: 0.6908, \n",
      "Epoch [58/100], Train Loss: 0.6919, \n",
      "Epoch [59/100], Train Loss: 0.7136, \n",
      "Epoch [60/100], Train Loss: 0.6928, \n",
      "Epoch [61/100], Train Loss: 0.6922, \n",
      "Epoch [62/100], Train Loss: 0.6917, \n",
      "Epoch [63/100], Train Loss: 0.6926, \n",
      "Epoch [64/100], Train Loss: 0.6919, \n",
      "Epoch [65/100], Train Loss: 0.6908, \n",
      "Epoch [66/100], Train Loss: 0.6918, \n",
      "Epoch [67/100], Train Loss: 0.6917, \n",
      "Epoch [68/100], Train Loss: 0.6927, \n",
      "Epoch [69/100], Train Loss: 0.6922, \n",
      "Epoch [70/100], Train Loss: 0.6917, \n",
      "Epoch [71/100], Train Loss: 0.6922, \n",
      "Epoch [72/100], Train Loss: 0.6914, \n",
      "Epoch [73/100], Train Loss: 0.6927, \n",
      "Epoch [74/100], Train Loss: 0.6919, \n",
      "Epoch [75/100], Train Loss: 0.6917, \n",
      "Epoch [76/100], Train Loss: 0.6909, \n",
      "Epoch [77/100], Train Loss: 0.6922, \n",
      "Epoch [78/100], Train Loss: 0.6921, \n",
      "Epoch [79/100], Train Loss: 0.6920, \n",
      "Epoch [80/100], Train Loss: 0.6912, \n",
      "Epoch [81/100], Train Loss: 0.6910, \n",
      "Epoch [82/100], Train Loss: 0.6918, \n",
      "Epoch [83/100], Train Loss: 0.6930, \n",
      "Epoch [84/100], Train Loss: 0.6921, \n",
      "Epoch [85/100], Train Loss: 0.6918, \n",
      "Epoch [86/100], Train Loss: 0.6931, \n",
      "Epoch [87/100], Train Loss: 0.6914, \n",
      "Epoch [88/100], Train Loss: 0.6917, \n",
      "Epoch [89/100], Train Loss: 0.6914, \n",
      "Epoch [90/100], Train Loss: 0.6915, \n",
      "Epoch [91/100], Train Loss: 0.6921, \n",
      "Epoch [92/100], Train Loss: 0.6914, \n",
      "Epoch [93/100], Train Loss: 0.6916, \n",
      "Epoch [94/100], Train Loss: 0.6922, \n",
      "Epoch [95/100], Train Loss: 0.6918, \n",
      "Epoch [96/100], Train Loss: 0.6910, \n",
      "Epoch [97/100], Train Loss: 0.6920, \n",
      "Epoch [98/100], Train Loss: 0.6919, \n",
      "Epoch [99/100], Train Loss: 0.6921, \n",
      "Epoch [100/100], Train Loss: 0.6914, \n",
      "training loss at last epoch: 0.691\n",
      "seed = 2\n",
      "14000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 724.1243, \n",
      "Epoch [2/100], Train Loss: 627.7441, \n",
      "Epoch [3/100], Train Loss: 744.1039, \n",
      "Epoch [4/100], Train Loss: 272.6035, \n",
      "Epoch [5/100], Train Loss: 301.6266, \n",
      "Epoch [6/100], Train Loss: 449.5225, \n",
      "Epoch [7/100], Train Loss: 137.2189, \n",
      "Epoch [8/100], Train Loss: 913.8316, \n",
      "Epoch [9/100], Train Loss: 552.5666, \n",
      "Epoch [10/100], Train Loss: 260.8303, \n",
      "Epoch [11/100], Train Loss: 77.5066, \n",
      "Epoch [12/100], Train Loss: 124.5514, \n",
      "Epoch [13/100], Train Loss: 109.9118, \n",
      "Epoch [14/100], Train Loss: 107.5246, \n",
      "Epoch [15/100], Train Loss: 185.2445, \n",
      "Epoch [16/100], Train Loss: 123.2788, \n",
      "Epoch [17/100], Train Loss: 141.5672, \n",
      "Epoch [18/100], Train Loss: 63.6509, \n",
      "Epoch [19/100], Train Loss: 109.3792, \n",
      "Epoch [20/100], Train Loss: 375.4000, \n",
      "Epoch [21/100], Train Loss: 491.4866, \n",
      "Epoch [22/100], Train Loss: 303.0922, \n",
      "Epoch [23/100], Train Loss: 158.7445, \n",
      "Epoch [24/100], Train Loss: 68.5395, \n",
      "Epoch [25/100], Train Loss: 54.7516, \n",
      "Epoch [26/100], Train Loss: 21.2618, \n",
      "Epoch [27/100], Train Loss: 68.6851, \n",
      "Epoch [28/100], Train Loss: 32.9243, \n",
      "Epoch [29/100], Train Loss: 57.1675, \n",
      "Epoch [30/100], Train Loss: 21.9911, \n",
      "Epoch [31/100], Train Loss: 31.4075, \n",
      "Epoch [32/100], Train Loss: 29.9769, \n",
      "Epoch [33/100], Train Loss: 32.3115, \n",
      "Epoch [34/100], Train Loss: 43.1955, \n",
      "Epoch [35/100], Train Loss: 33.8276, \n",
      "Epoch [36/100], Train Loss: 19.4410, \n",
      "Epoch [37/100], Train Loss: 93.9882, \n",
      "Epoch [38/100], Train Loss: 193.2129, \n",
      "Epoch [39/100], Train Loss: 107.9885, \n",
      "Epoch [40/100], Train Loss: 52.6580, \n",
      "Epoch [41/100], Train Loss: 24.2402, \n",
      "Epoch [42/100], Train Loss: 38.0846, \n",
      "Epoch [43/100], Train Loss: 14.1259, \n",
      "Epoch [44/100], Train Loss: 25.7664, \n",
      "Epoch [45/100], Train Loss: 20.3347, \n",
      "Epoch [46/100], Train Loss: 21.8352, \n",
      "Epoch [47/100], Train Loss: 23.8668, \n",
      "Epoch [48/100], Train Loss: 12.5027, \n",
      "Epoch [49/100], Train Loss: 17.3053, \n",
      "Epoch [50/100], Train Loss: 20.6827, \n",
      "Epoch [51/100], Train Loss: 17.1700, \n",
      "Epoch [52/100], Train Loss: 13.3402, \n",
      "Epoch [53/100], Train Loss: 13.1110, \n",
      "Epoch [54/100], Train Loss: 15.6116, \n",
      "Epoch [55/100], Train Loss: 108.7112, \n",
      "Epoch [56/100], Train Loss: 59.2727, \n",
      "Epoch [57/100], Train Loss: 30.5021, \n",
      "Epoch [58/100], Train Loss: 18.6122, \n",
      "Epoch [59/100], Train Loss: 16.6609, \n",
      "Epoch [60/100], Train Loss: 15.2171, \n",
      "Epoch [61/100], Train Loss: 12.9123, \n",
      "Epoch [62/100], Train Loss: 9.2831, \n",
      "Epoch [63/100], Train Loss: 7.9732, \n",
      "Epoch [64/100], Train Loss: 5.4320, \n",
      "Epoch [65/100], Train Loss: 5.0852, \n",
      "Epoch [66/100], Train Loss: 6.7733, \n",
      "Epoch [67/100], Train Loss: 4.5597, \n",
      "Epoch [68/100], Train Loss: 7.9062, \n",
      "Epoch [69/100], Train Loss: 4.2853, \n",
      "Epoch [70/100], Train Loss: 7.9517, \n",
      "Epoch [71/100], Train Loss: 6.5313, \n",
      "Epoch [72/100], Train Loss: 7.5746, \n",
      "Epoch [73/100], Train Loss: 4.8248, \n",
      "Epoch [74/100], Train Loss: 1.8816, \n",
      "Epoch [75/100], Train Loss: 3.8377, \n",
      "Epoch [76/100], Train Loss: 4.5254, \n",
      "Epoch [77/100], Train Loss: 3.5610, \n",
      "Epoch [78/100], Train Loss: 6.5285, \n",
      "Epoch [79/100], Train Loss: 4.6042, \n",
      "Epoch [80/100], Train Loss: 3.3169, \n",
      "Epoch [81/100], Train Loss: 5.6777, \n",
      "Epoch [82/100], Train Loss: 2.8969, \n",
      "Epoch [83/100], Train Loss: 5.3968, \n",
      "Epoch [84/100], Train Loss: 5.0231, \n",
      "Epoch [85/100], Train Loss: 4.0106, \n",
      "Epoch [86/100], Train Loss: 3.4551, \n",
      "Epoch [87/100], Train Loss: 4.4693, \n",
      "Epoch [88/100], Train Loss: 3.5998, \n",
      "Epoch [89/100], Train Loss: 4.7615, \n",
      "Epoch [90/100], Train Loss: 6.6396, \n",
      "Epoch [91/100], Train Loss: 1.7595, \n",
      "Epoch [92/100], Train Loss: 3.7432, \n",
      "Epoch [93/100], Train Loss: 3.2752, \n",
      "Epoch [94/100], Train Loss: 1.7678, \n",
      "Epoch [95/100], Train Loss: 2.6187, \n",
      "Epoch [96/100], Train Loss: 7.0672, \n",
      "Epoch [97/100], Train Loss: 4.3005, \n",
      "Epoch [98/100], Train Loss: 3.1705, \n",
      "Epoch [99/100], Train Loss: 2.9408, \n",
      "Epoch [100/100], Train Loss: 3.7990, \n",
      "training loss at last epoch: 3.799\n",
      "Epoch [1/100], Train Loss: 18.9428, \n",
      "Epoch [2/100], Train Loss: 0.7540, \n",
      "Epoch [3/100], Train Loss: 0.7509, \n",
      "Epoch [4/100], Train Loss: 0.7387, \n",
      "Epoch [5/100], Train Loss: 0.7363, \n",
      "Epoch [6/100], Train Loss: 0.7231, \n",
      "Epoch [7/100], Train Loss: 0.7084, \n",
      "Epoch [8/100], Train Loss: 0.7122, \n",
      "Epoch [9/100], Train Loss: 0.7042, \n",
      "Epoch [10/100], Train Loss: 0.6971, \n",
      "Epoch [11/100], Train Loss: 0.6952, \n",
      "Epoch [12/100], Train Loss: 0.6973, \n",
      "Epoch [13/100], Train Loss: 0.6951, \n",
      "Epoch [14/100], Train Loss: 0.6956, \n",
      "Epoch [15/100], Train Loss: 0.6943, \n",
      "Epoch [16/100], Train Loss: 0.6928, \n",
      "Epoch [17/100], Train Loss: 0.6945, \n",
      "Epoch [18/100], Train Loss: 0.6925, \n",
      "Epoch [19/100], Train Loss: 0.6928, \n",
      "Epoch [20/100], Train Loss: 0.6928, \n",
      "Epoch [21/100], Train Loss: 0.6957, \n",
      "Epoch [22/100], Train Loss: 0.7103, \n",
      "Epoch [23/100], Train Loss: 0.6968, \n",
      "Epoch [24/100], Train Loss: 0.6942, \n",
      "Epoch [25/100], Train Loss: 0.6944, \n",
      "Epoch [26/100], Train Loss: 0.7062, \n",
      "Epoch [27/100], Train Loss: 0.6927, \n",
      "Epoch [28/100], Train Loss: 0.6927, \n",
      "Epoch [29/100], Train Loss: 0.6932, \n",
      "Epoch [30/100], Train Loss: 0.6931, \n",
      "Epoch [31/100], Train Loss: 0.6921, \n",
      "Epoch [32/100], Train Loss: 0.6921, \n",
      "Epoch [33/100], Train Loss: 0.6926, \n",
      "Epoch [34/100], Train Loss: 0.6924, \n",
      "Epoch [35/100], Train Loss: 0.6923, \n",
      "Epoch [36/100], Train Loss: 0.6926, \n",
      "Epoch [37/100], Train Loss: 0.6927, \n",
      "Epoch [38/100], Train Loss: 0.6928, \n",
      "Epoch [39/100], Train Loss: 0.6923, \n",
      "Epoch [40/100], Train Loss: 0.6914, \n",
      "Epoch [41/100], Train Loss: 0.6918, \n",
      "Epoch [42/100], Train Loss: 0.6928, \n",
      "Epoch [43/100], Train Loss: 0.6926, \n",
      "Epoch [44/100], Train Loss: 0.6916, \n",
      "Epoch [45/100], Train Loss: 0.6919, \n",
      "Epoch [46/100], Train Loss: 0.6919, \n",
      "Epoch [47/100], Train Loss: 0.6923, \n",
      "Epoch [48/100], Train Loss: 0.6921, \n",
      "Epoch [49/100], Train Loss: 0.6915, \n",
      "Epoch [50/100], Train Loss: 0.6914, \n",
      "Epoch [51/100], Train Loss: 0.6921, \n",
      "Epoch [52/100], Train Loss: 0.6923, \n",
      "Epoch [53/100], Train Loss: 0.6908, \n",
      "Epoch [54/100], Train Loss: 0.6918, \n",
      "Epoch [55/100], Train Loss: 0.6921, \n",
      "Epoch [56/100], Train Loss: 0.6929, \n",
      "Epoch [57/100], Train Loss: 0.6925, \n",
      "Epoch [58/100], Train Loss: 0.6919, \n",
      "Epoch [59/100], Train Loss: 0.6930, \n",
      "Epoch [60/100], Train Loss: 0.6931, \n",
      "Epoch [61/100], Train Loss: 0.6924, \n",
      "Epoch [62/100], Train Loss: 0.6924, \n",
      "Epoch [63/100], Train Loss: 0.6924, \n",
      "Epoch [64/100], Train Loss: 0.6927, \n",
      "Epoch [65/100], Train Loss: 0.6912, \n",
      "Epoch [66/100], Train Loss: 0.6917, \n",
      "Epoch [67/100], Train Loss: 0.6912, \n",
      "Epoch [68/100], Train Loss: 0.6912, \n",
      "Epoch [69/100], Train Loss: 0.6929, \n",
      "Epoch [70/100], Train Loss: 0.6916, \n",
      "Epoch [71/100], Train Loss: 0.6911, \n",
      "Epoch [72/100], Train Loss: 0.6938, \n",
      "Epoch [73/100], Train Loss: 0.6924, \n",
      "Epoch [74/100], Train Loss: 0.6919, \n",
      "Epoch [75/100], Train Loss: 0.6927, \n",
      "Epoch [76/100], Train Loss: 0.6924, \n",
      "Epoch [77/100], Train Loss: 0.6917, \n",
      "Epoch [78/100], Train Loss: 0.6920, \n",
      "Epoch [79/100], Train Loss: 0.6917, \n",
      "Epoch [80/100], Train Loss: 0.6920, \n",
      "Epoch [81/100], Train Loss: 0.6925, \n",
      "Epoch [82/100], Train Loss: 0.6916, \n",
      "Epoch [83/100], Train Loss: 0.6927, \n",
      "Epoch [84/100], Train Loss: 0.6911, \n",
      "Epoch [85/100], Train Loss: 0.6913, \n",
      "Epoch [86/100], Train Loss: 0.6918, \n",
      "Epoch [87/100], Train Loss: 0.6921, \n",
      "Epoch [88/100], Train Loss: 0.6927, \n",
      "Epoch [89/100], Train Loss: 0.6914, \n",
      "Epoch [90/100], Train Loss: 0.6916, \n",
      "Epoch [91/100], Train Loss: 0.6916, \n",
      "Epoch [92/100], Train Loss: 0.6911, \n",
      "Epoch [93/100], Train Loss: 0.6928, \n",
      "Epoch [94/100], Train Loss: 0.6926, \n",
      "Epoch [95/100], Train Loss: 0.6916, \n",
      "Epoch [96/100], Train Loss: 0.6919, \n",
      "Epoch [97/100], Train Loss: 0.6930, \n",
      "Epoch [98/100], Train Loss: 0.6919, \n",
      "Epoch [99/100], Train Loss: 0.6920, \n",
      "Epoch [100/100], Train Loss: 0.6920, \n",
      "training loss at last epoch: 0.692\n",
      "time t = 400\n",
      "seed = 0\n",
      "16000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 42206.6106, \n",
      "Epoch [2/100], Train Loss: 22112.3742, \n",
      "Epoch [3/100], Train Loss: 21212.6636, \n",
      "Epoch [4/100], Train Loss: 71665.8509, \n",
      "Epoch [5/100], Train Loss: 57311.1626, \n",
      "Epoch [6/100], Train Loss: 44507.1708, \n",
      "Epoch [7/100], Train Loss: 32376.9354, \n",
      "Epoch [8/100], Train Loss: 20732.3795, \n",
      "Epoch [9/100], Train Loss: 10294.5957, \n",
      "Epoch [10/100], Train Loss: 24813.4305, \n",
      "Epoch [11/100], Train Loss: 14159.7063, \n",
      "Epoch [12/100], Train Loss: 23741.4265, \n",
      "Epoch [13/100], Train Loss: 82961.2490, \n",
      "Epoch [14/100], Train Loss: 70550.2953, \n",
      "Epoch [15/100], Train Loss: 59065.1654, \n",
      "Epoch [16/100], Train Loss: 48746.5807, \n",
      "Epoch [17/100], Train Loss: 39337.5364, \n",
      "Epoch [18/100], Train Loss: 30500.5081, \n",
      "Epoch [19/100], Train Loss: 22221.9010, \n",
      "Epoch [20/100], Train Loss: 14245.3420, \n",
      "Epoch [21/100], Train Loss: 7150.4167, \n",
      "Epoch [22/100], Train Loss: 14410.6708, \n",
      "Epoch [23/100], Train Loss: 7160.1220, \n",
      "Epoch [24/100], Train Loss: 4716.3975, \n",
      "Epoch [25/100], Train Loss: 58959.9431, \n",
      "Epoch [26/100], Train Loss: 110056.8825, \n",
      "Epoch [27/100], Train Loss: 97615.7788, \n",
      "Epoch [28/100], Train Loss: 86852.1781, \n",
      "Epoch [29/100], Train Loss: 77007.9238, \n",
      "Epoch [30/100], Train Loss: 68192.2021, \n",
      "Epoch [31/100], Train Loss: 60285.9058, \n",
      "Epoch [32/100], Train Loss: 53527.8031, \n",
      "Epoch [33/100], Train Loss: 47404.6371, \n",
      "Epoch [34/100], Train Loss: 42070.0630, \n",
      "Epoch [35/100], Train Loss: 36803.0646, \n",
      "Epoch [36/100], Train Loss: 32449.8275, \n",
      "Epoch [37/100], Train Loss: 28479.6903, \n",
      "Epoch [38/100], Train Loss: 25091.2672, \n",
      "Epoch [39/100], Train Loss: 22001.8384, \n",
      "Epoch [40/100], Train Loss: 19061.4075, \n",
      "Epoch [41/100], Train Loss: 16409.6542, \n",
      "Epoch [42/100], Train Loss: 14187.0199, \n",
      "Epoch [43/100], Train Loss: 11927.7796, \n",
      "Epoch [44/100], Train Loss: 10062.2919, \n",
      "Epoch [45/100], Train Loss: 8255.9786, \n",
      "Epoch [46/100], Train Loss: 6562.9035, \n",
      "Epoch [47/100], Train Loss: 4978.9116, \n",
      "Epoch [48/100], Train Loss: 3524.2216, \n",
      "Epoch [49/100], Train Loss: 2143.1048, \n",
      "Epoch [50/100], Train Loss: 1089.7311, \n",
      "Epoch [51/100], Train Loss: 2788.7199, \n",
      "Epoch [52/100], Train Loss: 1487.6754, \n",
      "Epoch [53/100], Train Loss: 7876.7664, \n",
      "Epoch [54/100], Train Loss: 19267.1581, \n",
      "Epoch [55/100], Train Loss: 17168.6000, \n",
      "Epoch [56/100], Train Loss: 15158.6206, \n",
      "Epoch [57/100], Train Loss: 13456.5022, \n",
      "Epoch [58/100], Train Loss: 11859.2703, \n",
      "Epoch [59/100], Train Loss: 10513.8999, \n",
      "Epoch [60/100], Train Loss: 9372.1016, \n",
      "Epoch [61/100], Train Loss: 8235.1718, \n",
      "Epoch [62/100], Train Loss: 7297.5552, \n",
      "Epoch [63/100], Train Loss: 6360.7183, \n",
      "Epoch [64/100], Train Loss: 5597.8825, \n",
      "Epoch [65/100], Train Loss: 4880.9550, \n",
      "Epoch [66/100], Train Loss: 4277.8723, \n",
      "Epoch [67/100], Train Loss: 3693.1352, \n",
      "Epoch [68/100], Train Loss: 3175.9035, \n",
      "Epoch [69/100], Train Loss: 2698.7714, \n",
      "Epoch [70/100], Train Loss: 2262.2875, \n",
      "Epoch [71/100], Train Loss: 1860.2669, \n",
      "Epoch [72/100], Train Loss: 1478.1640, \n",
      "Epoch [73/100], Train Loss: 1137.8760, \n",
      "Epoch [74/100], Train Loss: 809.7775, \n",
      "Epoch [75/100], Train Loss: 502.2166, \n",
      "Epoch [76/100], Train Loss: 244.9786, \n",
      "Epoch [77/100], Train Loss: 364.1620, \n",
      "Epoch [78/100], Train Loss: 459.5101, \n",
      "Epoch [79/100], Train Loss: 171.9949, \n",
      "Epoch [80/100], Train Loss: 861.1515, \n",
      "Epoch [81/100], Train Loss: 560.9179, \n",
      "Epoch [82/100], Train Loss: 290.4327, \n",
      "Epoch [83/100], Train Loss: 131.0582, \n",
      "Epoch [84/100], Train Loss: 443.9659, \n",
      "Epoch [85/100], Train Loss: 171.7873, \n",
      "Epoch [86/100], Train Loss: 302.0598, \n",
      "Epoch [87/100], Train Loss: 243.8990, \n",
      "Epoch [88/100], Train Loss: 189.9998, \n",
      "Epoch [89/100], Train Loss: 417.3916, \n",
      "Epoch [90/100], Train Loss: 231.2105, \n",
      "Epoch [91/100], Train Loss: 233.0622, \n",
      "Epoch [92/100], Train Loss: 264.0533, \n",
      "Epoch [93/100], Train Loss: 59.5367, \n",
      "Epoch [94/100], Train Loss: 404.8406, \n",
      "Epoch [95/100], Train Loss: 191.0460, \n",
      "Epoch [96/100], Train Loss: 93.8164, \n",
      "Epoch [97/100], Train Loss: 2584.2638, \n",
      "Epoch [98/100], Train Loss: 2227.9982, \n",
      "Epoch [99/100], Train Loss: 1942.8845, \n",
      "Epoch [100/100], Train Loss: 1710.7259, \n",
      "training loss at last epoch: 1710.726\n",
      "Epoch [1/100], Train Loss: 44.7346, \n",
      "Epoch [2/100], Train Loss: 2.9445, \n",
      "Epoch [3/100], Train Loss: 0.8259, \n",
      "Epoch [4/100], Train Loss: 0.7540, \n",
      "Epoch [5/100], Train Loss: 0.7269, \n",
      "Epoch [6/100], Train Loss: 0.7083, \n",
      "Epoch [7/100], Train Loss: 0.7099, \n",
      "Epoch [8/100], Train Loss: 0.7042, \n",
      "Epoch [9/100], Train Loss: 0.6998, \n",
      "Epoch [10/100], Train Loss: 0.6984, \n",
      "Epoch [11/100], Train Loss: 0.6978, \n",
      "Epoch [12/100], Train Loss: 0.6981, \n",
      "Epoch [13/100], Train Loss: 0.6974, \n",
      "Epoch [14/100], Train Loss: 0.6951, \n",
      "Epoch [15/100], Train Loss: 0.6954, \n",
      "Epoch [16/100], Train Loss: 0.6951, \n",
      "Epoch [17/100], Train Loss: 0.6946, \n",
      "Epoch [18/100], Train Loss: 0.6949, \n",
      "Epoch [19/100], Train Loss: 0.6945, \n",
      "Epoch [20/100], Train Loss: 0.6951, \n",
      "Epoch [21/100], Train Loss: 0.6938, \n",
      "Epoch [22/100], Train Loss: 0.6947, \n",
      "Epoch [23/100], Train Loss: 0.6933, \n",
      "Epoch [24/100], Train Loss: 0.6926, \n",
      "Epoch [25/100], Train Loss: 0.6920, \n",
      "Epoch [26/100], Train Loss: 0.6927, \n",
      "Epoch [27/100], Train Loss: 0.6934, \n",
      "Epoch [28/100], Train Loss: 0.6928, \n",
      "Epoch [29/100], Train Loss: 0.6930, \n",
      "Epoch [30/100], Train Loss: 0.6926, \n",
      "Epoch [31/100], Train Loss: 0.6931, \n",
      "Epoch [32/100], Train Loss: 0.6926, \n",
      "Epoch [33/100], Train Loss: 0.6927, \n",
      "Epoch [34/100], Train Loss: 0.6921, \n",
      "Epoch [35/100], Train Loss: 0.6933, \n",
      "Epoch [36/100], Train Loss: 0.6931, \n",
      "Epoch [37/100], Train Loss: 0.6919, \n",
      "Epoch [38/100], Train Loss: 0.6927, \n",
      "Epoch [39/100], Train Loss: 0.6931, \n",
      "Epoch [40/100], Train Loss: 0.6919, \n",
      "Epoch [41/100], Train Loss: 0.6931, \n",
      "Epoch [42/100], Train Loss: 0.6936, \n",
      "Epoch [43/100], Train Loss: 0.6921, \n",
      "Epoch [44/100], Train Loss: 0.6917, \n",
      "Epoch [45/100], Train Loss: 0.6917, \n",
      "Epoch [46/100], Train Loss: 0.6931, \n",
      "Epoch [47/100], Train Loss: 0.6928, \n",
      "Epoch [48/100], Train Loss: 0.6926, \n",
      "Epoch [49/100], Train Loss: 0.6936, \n",
      "Epoch [50/100], Train Loss: 0.6926, \n",
      "Epoch [51/100], Train Loss: 0.6921, \n",
      "Epoch [52/100], Train Loss: 0.6913, \n",
      "Epoch [53/100], Train Loss: 0.6919, \n",
      "Epoch [54/100], Train Loss: 0.6921, \n",
      "Epoch [55/100], Train Loss: 0.6919, \n",
      "Epoch [56/100], Train Loss: 0.6924, \n",
      "Epoch [57/100], Train Loss: 0.6924, \n",
      "Epoch [58/100], Train Loss: 0.6921, \n",
      "Epoch [59/100], Train Loss: 0.6921, \n",
      "Epoch [60/100], Train Loss: 0.6927, \n",
      "Epoch [61/100], Train Loss: 0.6929, \n",
      "Epoch [62/100], Train Loss: 0.6921, \n",
      "Epoch [63/100], Train Loss: 0.6921, \n",
      "Epoch [64/100], Train Loss: 0.6918, \n",
      "Epoch [65/100], Train Loss: 0.6913, \n",
      "Epoch [66/100], Train Loss: 0.6920, \n",
      "Epoch [67/100], Train Loss: 0.6917, \n",
      "Epoch [68/100], Train Loss: 0.6915, \n",
      "Epoch [69/100], Train Loss: 0.6929, \n",
      "Epoch [70/100], Train Loss: 0.6920, \n",
      "Epoch [71/100], Train Loss: 0.6919, \n",
      "Epoch [72/100], Train Loss: 0.6927, \n",
      "Epoch [73/100], Train Loss: 0.6928, \n",
      "Epoch [74/100], Train Loss: 0.6929, \n",
      "Epoch [75/100], Train Loss: 0.6924, \n",
      "Epoch [76/100], Train Loss: 0.6921, \n",
      "Epoch [77/100], Train Loss: 0.6924, \n",
      "Epoch [78/100], Train Loss: 0.6924, \n",
      "Epoch [79/100], Train Loss: 0.6923, \n",
      "Epoch [80/100], Train Loss: 0.6933, \n",
      "Epoch [81/100], Train Loss: 0.6928, \n",
      "Epoch [82/100], Train Loss: 0.6935, \n",
      "Epoch [83/100], Train Loss: 0.6927, \n",
      "Epoch [84/100], Train Loss: 0.6925, \n",
      "Epoch [85/100], Train Loss: 0.6924, \n",
      "Epoch [86/100], Train Loss: 0.6926, \n",
      "Epoch [87/100], Train Loss: 0.6929, \n",
      "Epoch [88/100], Train Loss: 0.6925, \n",
      "Epoch [89/100], Train Loss: 0.6931, \n",
      "Epoch [90/100], Train Loss: 0.6929, \n",
      "Epoch [91/100], Train Loss: 0.6936, \n",
      "Epoch [92/100], Train Loss: 0.6922, \n",
      "Epoch [93/100], Train Loss: 0.6922, \n",
      "Epoch [94/100], Train Loss: 0.6923, \n",
      "Epoch [95/100], Train Loss: 0.6924, \n",
      "Epoch [96/100], Train Loss: 0.6918, \n",
      "Epoch [97/100], Train Loss: 0.6931, \n",
      "Epoch [98/100], Train Loss: 0.6926, \n",
      "Epoch [99/100], Train Loss: 0.6919, \n",
      "Epoch [100/100], Train Loss: 0.6923, \n",
      "training loss at last epoch: 0.692\n",
      "seed = 1\n",
      "16000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 1106.0758, \n",
      "Epoch [2/100], Train Loss: 95.5812, \n",
      "Epoch [3/100], Train Loss: 218.1047, \n",
      "Epoch [4/100], Train Loss: 788.6446, \n",
      "Epoch [5/100], Train Loss: 686.4011, \n",
      "Epoch [6/100], Train Loss: 592.0160, \n",
      "Epoch [7/100], Train Loss: 504.8072, \n",
      "Epoch [8/100], Train Loss: 422.9667, \n",
      "Epoch [9/100], Train Loss: 352.4419, \n",
      "Epoch [10/100], Train Loss: 284.7291, \n",
      "Epoch [11/100], Train Loss: 220.8009, \n",
      "Epoch [12/100], Train Loss: 161.6226, \n",
      "Epoch [13/100], Train Loss: 107.0571, \n",
      "Epoch [14/100], Train Loss: 61.2188, \n",
      "Epoch [15/100], Train Loss: 61.3776, \n",
      "Epoch [16/100], Train Loss: 45.6074, \n",
      "Epoch [17/100], Train Loss: 138.6603, \n",
      "Epoch [18/100], Train Loss: 91.7229, \n",
      "Epoch [19/100], Train Loss: 48.0962, \n",
      "Epoch [20/100], Train Loss: 42.8186, \n",
      "Epoch [21/100], Train Loss: 464.3327, \n",
      "Epoch [22/100], Train Loss: 401.7478, \n",
      "Epoch [23/100], Train Loss: 344.3768, \n",
      "Epoch [24/100], Train Loss: 291.6005, \n",
      "Epoch [25/100], Train Loss: 245.4112, \n",
      "Epoch [26/100], Train Loss: 201.4576, \n",
      "Epoch [27/100], Train Loss: 161.7276, \n",
      "Epoch [28/100], Train Loss: 123.7893, \n",
      "Epoch [29/100], Train Loss: 90.2927, \n",
      "Epoch [30/100], Train Loss: 67.4515, \n",
      "Epoch [31/100], Train Loss: 48.1850, \n",
      "Epoch [32/100], Train Loss: 49.0294, \n",
      "Epoch [33/100], Train Loss: 44.6890, \n",
      "Epoch [34/100], Train Loss: 36.6286, \n",
      "Epoch [35/100], Train Loss: 42.1374, \n",
      "Epoch [36/100], Train Loss: 31.1816, \n",
      "Epoch [37/100], Train Loss: 10.1620, \n",
      "Epoch [38/100], Train Loss: 26.4891, \n",
      "Epoch [39/100], Train Loss: 33.0216, \n",
      "Epoch [40/100], Train Loss: 26.4151, \n",
      "Epoch [41/100], Train Loss: 34.3772, \n",
      "Epoch [42/100], Train Loss: 23.7263, \n",
      "Epoch [43/100], Train Loss: 29.3422, \n",
      "Epoch [44/100], Train Loss: 24.5125, \n",
      "Epoch [45/100], Train Loss: 34.9354, \n",
      "Epoch [46/100], Train Loss: 272.3674, \n",
      "Epoch [47/100], Train Loss: 236.5972, \n",
      "Epoch [48/100], Train Loss: 204.8793, \n",
      "Epoch [49/100], Train Loss: 178.1914, \n",
      "Epoch [50/100], Train Loss: 152.7332, \n",
      "Epoch [51/100], Train Loss: 128.8224, \n",
      "Epoch [52/100], Train Loss: 107.8252, \n",
      "Epoch [53/100], Train Loss: 87.6212, \n",
      "Epoch [54/100], Train Loss: 68.8568, \n",
      "Epoch [55/100], Train Loss: 50.9437, \n",
      "Epoch [56/100], Train Loss: 34.1310, \n",
      "Epoch [57/100], Train Loss: 24.6645, \n",
      "Epoch [58/100], Train Loss: 21.2860, \n",
      "Epoch [59/100], Train Loss: 13.2669, \n",
      "Epoch [60/100], Train Loss: 22.3570, \n",
      "Epoch [61/100], Train Loss: 21.7859, \n",
      "Epoch [62/100], Train Loss: 19.2984, \n",
      "Epoch [63/100], Train Loss: 14.6164, \n",
      "Epoch [64/100], Train Loss: 16.4590, \n",
      "Epoch [65/100], Train Loss: 11.7665, \n",
      "Epoch [66/100], Train Loss: 14.9475, \n",
      "Epoch [67/100], Train Loss: 18.5016, \n",
      "Epoch [68/100], Train Loss: 8.1723, \n",
      "Epoch [69/100], Train Loss: 15.1596, \n",
      "Epoch [70/100], Train Loss: 10.8236, \n",
      "Epoch [71/100], Train Loss: 14.9106, \n",
      "Epoch [72/100], Train Loss: 13.8223, \n",
      "Epoch [73/100], Train Loss: 14.7515, \n",
      "Epoch [74/100], Train Loss: 9.8993, \n",
      "Epoch [75/100], Train Loss: 11.4490, \n",
      "Epoch [76/100], Train Loss: 9.3319, \n",
      "Epoch [77/100], Train Loss: 12.3829, \n",
      "Epoch [78/100], Train Loss: 4.5383, \n",
      "Epoch [79/100], Train Loss: 18.0636, \n",
      "Epoch [80/100], Train Loss: 5.9940, \n",
      "Epoch [81/100], Train Loss: 15.3120, \n",
      "Epoch [82/100], Train Loss: 6.2009, \n",
      "Epoch [83/100], Train Loss: 10.4086, \n",
      "Epoch [84/100], Train Loss: 7.9342, \n",
      "Epoch [85/100], Train Loss: 7.4050, \n",
      "Epoch [86/100], Train Loss: 10.3395, \n",
      "Epoch [87/100], Train Loss: 9.8838, \n",
      "Epoch [88/100], Train Loss: 7.6384, \n",
      "Epoch [89/100], Train Loss: 8.1691, \n",
      "Epoch [90/100], Train Loss: 7.5912, \n",
      "Epoch [91/100], Train Loss: 6.4422, \n",
      "Epoch [92/100], Train Loss: 12.5975, \n",
      "Epoch [93/100], Train Loss: 5.9359, \n",
      "Epoch [94/100], Train Loss: 5.1651, \n",
      "Epoch [95/100], Train Loss: 0.6919, \n",
      "Epoch [96/100], Train Loss: 0.6925, \n",
      "Epoch [97/100], Train Loss: 0.6919, \n",
      "Epoch [98/100], Train Loss: 0.6916, \n",
      "Epoch [99/100], Train Loss: 0.6920, \n",
      "Epoch [100/100], Train Loss: 0.6916, \n",
      "training loss at last epoch: 0.692\n",
      "Epoch [1/100], Train Loss: 164.6403, \n",
      "Epoch [2/100], Train Loss: 1.1877, \n",
      "Epoch [3/100], Train Loss: 0.6928, \n",
      "Epoch [4/100], Train Loss: 0.6918, \n",
      "Epoch [5/100], Train Loss: 0.6931, \n",
      "Epoch [6/100], Train Loss: 0.6937, \n",
      "Epoch [7/100], Train Loss: 0.6922, \n",
      "Epoch [8/100], Train Loss: 0.6924, \n",
      "Epoch [9/100], Train Loss: 0.6928, \n",
      "Epoch [10/100], Train Loss: 0.6922, \n",
      "Epoch [11/100], Train Loss: 0.6925, \n",
      "Epoch [12/100], Train Loss: 0.6920, \n",
      "Epoch [13/100], Train Loss: 0.6923, \n",
      "Epoch [14/100], Train Loss: 0.6928, \n",
      "Epoch [15/100], Train Loss: 0.6926, \n",
      "Epoch [16/100], Train Loss: 0.6927, \n",
      "Epoch [17/100], Train Loss: 0.6928, \n",
      "Epoch [18/100], Train Loss: 0.6919, \n",
      "Epoch [19/100], Train Loss: 0.6923, \n",
      "Epoch [20/100], Train Loss: 0.6920, \n",
      "Epoch [21/100], Train Loss: 0.6929, \n",
      "Epoch [22/100], Train Loss: 0.6921, \n",
      "Epoch [23/100], Train Loss: 0.6922, \n",
      "Epoch [24/100], Train Loss: 0.6927, \n",
      "Epoch [25/100], Train Loss: 0.6921, \n",
      "Epoch [26/100], Train Loss: 0.6927, \n",
      "Epoch [27/100], Train Loss: 0.6923, \n",
      "Epoch [28/100], Train Loss: 0.6920, \n",
      "Epoch [29/100], Train Loss: 0.6936, \n",
      "Epoch [30/100], Train Loss: 0.6929, \n",
      "Epoch [31/100], Train Loss: 0.6924, \n",
      "Epoch [32/100], Train Loss: 0.6931, \n",
      "Epoch [33/100], Train Loss: 0.6929, \n",
      "Epoch [34/100], Train Loss: 0.6925, \n",
      "Epoch [35/100], Train Loss: 0.6918, \n",
      "Epoch [36/100], Train Loss: 0.6925, \n",
      "Epoch [37/100], Train Loss: 0.6920, \n",
      "Epoch [38/100], Train Loss: 0.6914, \n",
      "Epoch [39/100], Train Loss: 0.6927, \n",
      "Epoch [40/100], Train Loss: 0.6923, \n",
      "Epoch [41/100], Train Loss: 0.6930, \n",
      "Epoch [42/100], Train Loss: 0.6923, \n",
      "Epoch [43/100], Train Loss: 0.6919, \n",
      "Epoch [44/100], Train Loss: 0.6926, \n",
      "Epoch [45/100], Train Loss: 0.6931, \n",
      "Epoch [46/100], Train Loss: 0.6930, \n",
      "Epoch [47/100], Train Loss: 0.6930, \n",
      "Epoch [48/100], Train Loss: 0.6924, \n",
      "Epoch [49/100], Train Loss: 0.6923, \n",
      "Epoch [50/100], Train Loss: 0.6933, \n",
      "Epoch [51/100], Train Loss: 0.6921, \n",
      "Epoch [52/100], Train Loss: 0.6922, \n",
      "Epoch [53/100], Train Loss: 0.6926, \n",
      "Epoch [54/100], Train Loss: 0.6918, \n",
      "Epoch [55/100], Train Loss: 0.6921, \n",
      "Epoch [56/100], Train Loss: 0.6930, \n",
      "Epoch [57/100], Train Loss: 0.6929, \n",
      "Epoch [58/100], Train Loss: 0.6926, \n",
      "Epoch [59/100], Train Loss: 0.6927, \n",
      "Epoch [60/100], Train Loss: 0.6926, \n",
      "Epoch [61/100], Train Loss: 0.6927, \n",
      "Epoch [62/100], Train Loss: 0.6925, \n",
      "Epoch [63/100], Train Loss: 0.6921, \n",
      "Epoch [64/100], Train Loss: 0.6919, \n",
      "Epoch [65/100], Train Loss: 0.6918, \n",
      "Epoch [66/100], Train Loss: 0.6923, \n",
      "Epoch [67/100], Train Loss: 0.6924, \n",
      "Epoch [68/100], Train Loss: 0.6924, \n",
      "Epoch [69/100], Train Loss: 0.6930, \n",
      "Epoch [70/100], Train Loss: 0.6929, \n",
      "Epoch [71/100], Train Loss: 0.6930, \n",
      "Epoch [72/100], Train Loss: 0.6921, \n",
      "Epoch [73/100], Train Loss: 0.6925, \n",
      "Epoch [74/100], Train Loss: 0.6933, \n",
      "Epoch [75/100], Train Loss: 0.6926, \n",
      "Epoch [76/100], Train Loss: 0.6916, \n",
      "Epoch [77/100], Train Loss: 0.6924, \n",
      "Epoch [78/100], Train Loss: 0.6915, \n",
      "Epoch [79/100], Train Loss: 0.6920, \n",
      "Epoch [80/100], Train Loss: 0.6922, \n",
      "Epoch [81/100], Train Loss: 0.6927, \n",
      "Epoch [82/100], Train Loss: 0.6925, \n",
      "Epoch [83/100], Train Loss: 0.6924, \n",
      "Epoch [84/100], Train Loss: 0.6918, \n",
      "Epoch [85/100], Train Loss: 0.6917, \n",
      "Epoch [86/100], Train Loss: 0.6926, \n",
      "Epoch [87/100], Train Loss: 0.6934, \n",
      "Epoch [88/100], Train Loss: 0.6927, \n",
      "Epoch [89/100], Train Loss: 0.6928, \n",
      "Epoch [90/100], Train Loss: 0.6921, \n",
      "Epoch [91/100], Train Loss: 0.6919, \n",
      "Epoch [92/100], Train Loss: 0.6927, \n",
      "Epoch [93/100], Train Loss: 0.6918, \n",
      "Epoch [94/100], Train Loss: 0.6931, \n",
      "Epoch [95/100], Train Loss: 0.6927, \n",
      "Epoch [96/100], Train Loss: 0.6926, \n",
      "Epoch [97/100], Train Loss: 0.6926, \n",
      "Epoch [98/100], Train Loss: 0.6924, \n",
      "Epoch [99/100], Train Loss: 0.6930, \n",
      "Epoch [100/100], Train Loss: 0.6927, \n",
      "training loss at last epoch: 0.693\n",
      "seed = 2\n",
      "16000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 1421.2283, \n",
      "Epoch [2/100], Train Loss: 1121.2293, \n",
      "Epoch [3/100], Train Loss: 405.0079, \n",
      "Epoch [4/100], Train Loss: 428.3786, \n",
      "Epoch [5/100], Train Loss: 588.4883, \n",
      "Epoch [6/100], Train Loss: 700.4896, \n",
      "Epoch [7/100], Train Loss: 298.9476, \n",
      "Epoch [8/100], Train Loss: 570.1125, \n",
      "Epoch [9/100], Train Loss: 848.0643, \n",
      "Epoch [10/100], Train Loss: 365.5304, \n",
      "Epoch [11/100], Train Loss: 625.9350, \n",
      "Epoch [12/100], Train Loss: 502.0656, \n",
      "Epoch [13/100], Train Loss: 149.5617, \n",
      "Epoch [14/100], Train Loss: 228.5989, \n",
      "Epoch [15/100], Train Loss: 104.8117, \n",
      "Epoch [16/100], Train Loss: 334.4823, \n",
      "Epoch [17/100], Train Loss: 232.4455, \n",
      "Epoch [18/100], Train Loss: 325.9847, \n",
      "Epoch [19/100], Train Loss: 128.6551, \n",
      "Epoch [20/100], Train Loss: 230.9847, \n",
      "Epoch [21/100], Train Loss: 430.9569, \n",
      "Epoch [22/100], Train Loss: 180.6658, \n",
      "Epoch [23/100], Train Loss: 117.5656, \n",
      "Epoch [24/100], Train Loss: 77.7300, \n",
      "Epoch [25/100], Train Loss: 87.7702, \n",
      "Epoch [26/100], Train Loss: 74.3519, \n",
      "Epoch [27/100], Train Loss: 78.8339, \n",
      "Epoch [28/100], Train Loss: 52.4494, \n",
      "Epoch [29/100], Train Loss: 87.3479, \n",
      "Epoch [30/100], Train Loss: 167.7614, \n",
      "Epoch [31/100], Train Loss: 71.7673, \n",
      "Epoch [32/100], Train Loss: 60.0567, \n",
      "Epoch [33/100], Train Loss: 27.5648, \n",
      "Epoch [34/100], Train Loss: 61.6031, \n",
      "Epoch [35/100], Train Loss: 47.0908, \n",
      "Epoch [36/100], Train Loss: 45.3955, \n",
      "Epoch [37/100], Train Loss: 48.6519, \n",
      "Epoch [38/100], Train Loss: 57.0947, \n",
      "Epoch [39/100], Train Loss: 50.9837, \n",
      "Epoch [40/100], Train Loss: 309.2677, \n",
      "Epoch [41/100], Train Loss: 157.4725, \n",
      "Epoch [42/100], Train Loss: 57.3595, \n",
      "Epoch [43/100], Train Loss: 43.4222, \n",
      "Epoch [44/100], Train Loss: 37.0637, \n",
      "Epoch [45/100], Train Loss: 47.2873, \n",
      "Epoch [46/100], Train Loss: 59.5336, \n",
      "Epoch [47/100], Train Loss: 33.1369, \n",
      "Epoch [48/100], Train Loss: 42.9319, \n",
      "Epoch [49/100], Train Loss: 34.9840, \n",
      "Epoch [50/100], Train Loss: 43.8681, \n",
      "Epoch [51/100], Train Loss: 18.9360, \n",
      "Epoch [52/100], Train Loss: 37.0894, \n",
      "Epoch [53/100], Train Loss: 34.8452, \n",
      "Epoch [54/100], Train Loss: 106.2635, \n",
      "Epoch [55/100], Train Loss: 277.8155, \n",
      "Epoch [56/100], Train Loss: 180.8439, \n",
      "Epoch [57/100], Train Loss: 109.1614, \n",
      "Epoch [58/100], Train Loss: 48.9360, \n",
      "Epoch [59/100], Train Loss: 24.3080, \n",
      "Epoch [60/100], Train Loss: 19.1380, \n",
      "Epoch [61/100], Train Loss: 11.8578, \n",
      "Epoch [62/100], Train Loss: 18.2480, \n",
      "Epoch [63/100], Train Loss: 18.1687, \n",
      "Epoch [64/100], Train Loss: 9.1009, \n",
      "Epoch [65/100], Train Loss: 9.2648, \n",
      "Epoch [66/100], Train Loss: 10.7252, \n",
      "Epoch [67/100], Train Loss: 12.4301, \n",
      "Epoch [68/100], Train Loss: 11.6416, \n",
      "Epoch [69/100], Train Loss: 8.2248, \n",
      "Epoch [70/100], Train Loss: 6.1302, \n",
      "Epoch [71/100], Train Loss: 6.2455, \n",
      "Epoch [72/100], Train Loss: 13.3988, \n",
      "Epoch [73/100], Train Loss: 11.9619, \n",
      "Epoch [74/100], Train Loss: 6.1847, \n",
      "Epoch [75/100], Train Loss: 7.7501, \n",
      "Epoch [76/100], Train Loss: 6.3288, \n",
      "Epoch [77/100], Train Loss: 5.0447, \n",
      "Epoch [78/100], Train Loss: 2.7120, \n",
      "Epoch [79/100], Train Loss: 6.8752, \n",
      "Epoch [80/100], Train Loss: 3.4899, \n",
      "Epoch [81/100], Train Loss: 6.6731, \n",
      "Epoch [82/100], Train Loss: 6.6884, \n",
      "Epoch [83/100], Train Loss: 9.7812, \n",
      "Epoch [84/100], Train Loss: 3.8582, \n",
      "Epoch [85/100], Train Loss: 3.4649, \n",
      "Epoch [86/100], Train Loss: 9.1711, \n",
      "Epoch [87/100], Train Loss: 5.4051, \n",
      "Epoch [88/100], Train Loss: 4.7622, \n",
      "Epoch [89/100], Train Loss: 5.5369, \n",
      "Epoch [90/100], Train Loss: 1.9703, \n",
      "Epoch [91/100], Train Loss: 8.4941, \n",
      "Epoch [92/100], Train Loss: 5.5556, \n",
      "Epoch [93/100], Train Loss: 3.2694, \n",
      "Epoch [94/100], Train Loss: 3.5546, \n",
      "Epoch [95/100], Train Loss: 4.2245, \n",
      "Epoch [96/100], Train Loss: 3.3771, \n",
      "Epoch [97/100], Train Loss: 5.6643, \n",
      "Epoch [98/100], Train Loss: 4.1365, \n",
      "Epoch [99/100], Train Loss: 3.7808, \n",
      "Epoch [100/100], Train Loss: 2.3201, \n",
      "training loss at last epoch: 2.320\n",
      "Epoch [1/100], Train Loss: 51.0589, \n",
      "Epoch [2/100], Train Loss: 0.9865, \n",
      "Epoch [3/100], Train Loss: 0.7212, \n",
      "Epoch [4/100], Train Loss: 0.7254, \n",
      "Epoch [5/100], Train Loss: 0.7093, \n",
      "Epoch [6/100], Train Loss: 0.6997, \n",
      "Epoch [7/100], Train Loss: 0.6937, \n",
      "Epoch [8/100], Train Loss: 0.7082, \n",
      "Epoch [9/100], Train Loss: 0.6987, \n",
      "Epoch [10/100], Train Loss: 0.6968, \n",
      "Epoch [11/100], Train Loss: 0.6970, \n",
      "Epoch [12/100], Train Loss: 0.6962, \n",
      "Epoch [13/100], Train Loss: 0.6934, \n",
      "Epoch [14/100], Train Loss: 0.6955, \n",
      "Epoch [15/100], Train Loss: 0.6941, \n",
      "Epoch [16/100], Train Loss: 0.6946, \n",
      "Epoch [17/100], Train Loss: 0.6932, \n",
      "Epoch [18/100], Train Loss: 0.6935, \n",
      "Epoch [19/100], Train Loss: 0.6937, \n",
      "Epoch [20/100], Train Loss: 0.6938, \n",
      "Epoch [21/100], Train Loss: 0.6937, \n",
      "Epoch [22/100], Train Loss: 0.6936, \n",
      "Epoch [23/100], Train Loss: 0.6933, \n",
      "Epoch [24/100], Train Loss: 0.6929, \n",
      "Epoch [25/100], Train Loss: 0.6926, \n",
      "Epoch [26/100], Train Loss: 0.6923, \n",
      "Epoch [27/100], Train Loss: 0.6940, \n",
      "Epoch [28/100], Train Loss: 0.6929, \n",
      "Epoch [29/100], Train Loss: 0.6922, \n",
      "Epoch [30/100], Train Loss: 0.6928, \n",
      "Epoch [31/100], Train Loss: 0.6924, \n",
      "Epoch [32/100], Train Loss: 0.6929, \n",
      "Epoch [33/100], Train Loss: 0.6921, \n",
      "Epoch [34/100], Train Loss: 0.6930, \n",
      "Epoch [35/100], Train Loss: 0.6918, \n",
      "Epoch [36/100], Train Loss: 0.6922, \n",
      "Epoch [37/100], Train Loss: 0.6916, \n",
      "Epoch [38/100], Train Loss: 0.6922, \n",
      "Epoch [39/100], Train Loss: 0.6928, \n",
      "Epoch [40/100], Train Loss: 0.6922, \n",
      "Epoch [41/100], Train Loss: 0.6934, \n",
      "Epoch [42/100], Train Loss: 0.6922, \n",
      "Epoch [43/100], Train Loss: 0.6934, \n",
      "Epoch [44/100], Train Loss: 0.6922, \n",
      "Epoch [45/100], Train Loss: 0.6931, \n",
      "Epoch [46/100], Train Loss: 0.6922, \n",
      "Epoch [47/100], Train Loss: 0.6928, \n",
      "Epoch [48/100], Train Loss: 0.6933, \n",
      "Epoch [49/100], Train Loss: 0.6923, \n",
      "Epoch [50/100], Train Loss: 0.6922, \n",
      "Epoch [51/100], Train Loss: 0.6935, \n",
      "Epoch [52/100], Train Loss: 0.6921, \n",
      "Epoch [53/100], Train Loss: 0.6920, \n",
      "Epoch [54/100], Train Loss: 0.6916, \n",
      "Epoch [55/100], Train Loss: 0.6923, \n",
      "Epoch [56/100], Train Loss: 0.6916, \n",
      "Epoch [57/100], Train Loss: 0.6912, \n",
      "Epoch [58/100], Train Loss: 0.6944, \n",
      "Epoch [59/100], Train Loss: 0.6933, \n",
      "Epoch [60/100], Train Loss: 0.6934, \n",
      "Epoch [61/100], Train Loss: 0.6944, \n",
      "Epoch [62/100], Train Loss: 0.6933, \n",
      "Epoch [63/100], Train Loss: 0.6937, \n",
      "Epoch [64/100], Train Loss: 0.6930, \n",
      "Epoch [65/100], Train Loss: 0.6922, \n",
      "Epoch [66/100], Train Loss: 0.6933, \n",
      "Epoch [67/100], Train Loss: 0.6934, \n",
      "Epoch [68/100], Train Loss: 0.6928, \n",
      "Epoch [69/100], Train Loss: 0.6923, \n",
      "Epoch [70/100], Train Loss: 0.6930, \n",
      "Epoch [71/100], Train Loss: 0.6925, \n",
      "Epoch [72/100], Train Loss: 0.6923, \n",
      "Epoch [73/100], Train Loss: 0.6935, \n",
      "Epoch [74/100], Train Loss: 0.6928, \n",
      "Epoch [75/100], Train Loss: 0.6919, \n",
      "Epoch [76/100], Train Loss: 0.6926, \n",
      "Epoch [77/100], Train Loss: 0.6922, \n",
      "Epoch [78/100], Train Loss: 0.6921, \n",
      "Epoch [79/100], Train Loss: 0.6925, \n",
      "Epoch [80/100], Train Loss: 0.6920, \n",
      "Epoch [81/100], Train Loss: 0.6920, \n",
      "Epoch [82/100], Train Loss: 0.6925, \n",
      "Epoch [83/100], Train Loss: 0.6928, \n",
      "Epoch [84/100], Train Loss: 0.6929, \n",
      "Epoch [85/100], Train Loss: 0.6926, \n",
      "Epoch [86/100], Train Loss: 0.6921, \n",
      "Epoch [87/100], Train Loss: 0.6924, \n",
      "Epoch [88/100], Train Loss: 0.6927, \n",
      "Epoch [89/100], Train Loss: 0.6929, \n",
      "Epoch [90/100], Train Loss: 0.6927, \n",
      "Epoch [91/100], Train Loss: 0.6926, \n",
      "Epoch [92/100], Train Loss: 0.6926, \n",
      "Epoch [93/100], Train Loss: 0.6936, \n",
      "Epoch [94/100], Train Loss: 0.6918, \n",
      "Epoch [95/100], Train Loss: 0.6928, \n",
      "Epoch [96/100], Train Loss: 0.6927, \n",
      "Epoch [97/100], Train Loss: 0.6922, \n",
      "Epoch [98/100], Train Loss: 0.6923, \n",
      "Epoch [99/100], Train Loss: 0.6929, \n",
      "Epoch [100/100], Train Loss: 0.6928, \n",
      "training loss at last epoch: 0.693\n",
      "time t = 450\n",
      "seed = 0\n",
      "18000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 297127.9334, \n",
      "Epoch [2/100], Train Loss: 198093.6880, \n",
      "Epoch [3/100], Train Loss: 150139.3670, \n",
      "Epoch [4/100], Train Loss: 104711.5591, \n",
      "Epoch [5/100], Train Loss: 62431.0045, \n",
      "Epoch [6/100], Train Loss: 36023.2985, \n",
      "Epoch [7/100], Train Loss: 72740.7195, \n",
      "Epoch [8/100], Train Loss: 32457.4245, \n",
      "Epoch [9/100], Train Loss: 250717.2891, \n",
      "Epoch [10/100], Train Loss: 175002.3189, \n",
      "Epoch [11/100], Train Loss: 135948.6074, \n",
      "Epoch [12/100], Train Loss: 98768.5530, \n",
      "Epoch [13/100], Train Loss: 62912.8598, \n",
      "Epoch [14/100], Train Loss: 32355.2737, \n",
      "Epoch [15/100], Train Loss: 188948.4464, \n",
      "Epoch [16/100], Train Loss: 152518.4324, \n",
      "Epoch [17/100], Train Loss: 119329.6682, \n",
      "Epoch [18/100], Train Loss: 87027.5102, \n",
      "Epoch [19/100], Train Loss: 58250.9165, \n",
      "Epoch [20/100], Train Loss: 29864.7848, \n",
      "Epoch [21/100], Train Loss: 24242.3358, \n",
      "Epoch [22/100], Train Loss: 116272.1573, \n",
      "Epoch [23/100], Train Loss: 87311.3914, \n",
      "Epoch [24/100], Train Loss: 61015.0113, \n",
      "Epoch [25/100], Train Loss: 36055.3863, \n",
      "Epoch [26/100], Train Loss: 53179.9660, \n",
      "Epoch [27/100], Train Loss: 155683.0248, \n",
      "Epoch [28/100], Train Loss: 129053.1618, \n",
      "Epoch [29/100], Train Loss: 103603.1156, \n",
      "Epoch [30/100], Train Loss: 81145.1726, \n",
      "Epoch [31/100], Train Loss: 59117.3460, \n",
      "Epoch [32/100], Train Loss: 39213.5345, \n",
      "Epoch [33/100], Train Loss: 19651.9548, \n",
      "Epoch [34/100], Train Loss: 57787.2802, \n",
      "Epoch [35/100], Train Loss: 82382.4479, \n",
      "Epoch [36/100], Train Loss: 62968.0552, \n",
      "Epoch [37/100], Train Loss: 44704.5028, \n",
      "Epoch [38/100], Train Loss: 27536.8398, \n",
      "Epoch [39/100], Train Loss: 12297.1121, \n",
      "Epoch [40/100], Train Loss: 84043.1465, \n",
      "Epoch [41/100], Train Loss: 66560.8640, \n",
      "Epoch [42/100], Train Loss: 50199.2458, \n",
      "Epoch [43/100], Train Loss: 34438.3360, \n",
      "Epoch [44/100], Train Loss: 19977.4346, \n",
      "Epoch [45/100], Train Loss: 11878.9777, \n",
      "Epoch [46/100], Train Loss: 78201.6873, \n",
      "Epoch [47/100], Train Loss: 63159.3537, \n",
      "Epoch [48/100], Train Loss: 48473.1754, \n",
      "Epoch [49/100], Train Loss: 35613.5816, \n",
      "Epoch [50/100], Train Loss: 23134.0752, \n",
      "Epoch [51/100], Train Loss: 11343.5825, \n",
      "Epoch [52/100], Train Loss: 12071.3810, \n",
      "Epoch [53/100], Train Loss: 2209.1812, \n",
      "Epoch [54/100], Train Loss: 14955.4948, \n",
      "Epoch [55/100], Train Loss: 6540.4686, \n",
      "Epoch [56/100], Train Loss: 32734.3135, \n",
      "Epoch [57/100], Train Loss: 21669.6598, \n",
      "Epoch [58/100], Train Loss: 11188.9031, \n",
      "Epoch [59/100], Train Loss: 11490.7647, \n",
      "Epoch [60/100], Train Loss: 10678.7630, \n",
      "Epoch [61/100], Train Loss: 3766.6096, \n",
      "Epoch [62/100], Train Loss: 32510.7581, \n",
      "Epoch [63/100], Train Loss: 22614.1840, \n",
      "Epoch [64/100], Train Loss: 13245.0185, \n",
      "Epoch [65/100], Train Loss: 11711.4994, \n",
      "Epoch [66/100], Train Loss: 33570.8519, \n",
      "Epoch [67/100], Train Loss: 24327.4183, \n",
      "Epoch [68/100], Train Loss: 15670.8271, \n",
      "Epoch [69/100], Train Loss: 7815.5426, \n",
      "Epoch [70/100], Train Loss: 5769.9897, \n",
      "Epoch [71/100], Train Loss: 42653.7600, \n",
      "Epoch [72/100], Train Loss: 32336.7713, \n",
      "Epoch [73/100], Train Loss: 24412.9870, \n",
      "Epoch [74/100], Train Loss: 17034.6226, \n",
      "Epoch [75/100], Train Loss: 10059.7858, \n",
      "Epoch [76/100], Train Loss: 3615.2021, \n",
      "Epoch [77/100], Train Loss: 75604.5993, \n",
      "Epoch [78/100], Train Loss: 65777.2681, \n",
      "Epoch [79/100], Train Loss: 57530.6972, \n",
      "Epoch [80/100], Train Loss: 49652.1352, \n",
      "Epoch [81/100], Train Loss: 43042.6810, \n",
      "Epoch [82/100], Train Loss: 36682.2378, \n",
      "Epoch [83/100], Train Loss: 31142.9109, \n",
      "Epoch [84/100], Train Loss: 25991.7223, \n",
      "Epoch [85/100], Train Loss: 21138.2258, \n",
      "Epoch [86/100], Train Loss: 16859.2815, \n",
      "Epoch [87/100], Train Loss: 12727.9737, \n",
      "Epoch [88/100], Train Loss: 8928.7894, \n",
      "Epoch [89/100], Train Loss: 5235.4563, \n",
      "Epoch [90/100], Train Loss: 3017.7881, \n",
      "Epoch [91/100], Train Loss: 4277.3945, \n",
      "Epoch [92/100], Train Loss: 7349.2763, \n",
      "Epoch [93/100], Train Loss: 38344.6776, \n",
      "Epoch [94/100], Train Loss: 33135.2927, \n",
      "Epoch [95/100], Train Loss: 28841.9364, \n",
      "Epoch [96/100], Train Loss: 24971.3825, \n",
      "Epoch [97/100], Train Loss: 21516.9121, \n",
      "Epoch [98/100], Train Loss: 18589.8333, \n",
      "Epoch [99/100], Train Loss: 15683.8048, \n",
      "Epoch [100/100], Train Loss: 13208.2195, \n",
      "training loss at last epoch: 13208.220\n",
      "Epoch [1/100], Train Loss: 120.6198, \n",
      "Epoch [2/100], Train Loss: 7.0965, \n",
      "Epoch [3/100], Train Loss: 1.1468, \n",
      "Epoch [4/100], Train Loss: 0.8337, \n",
      "Epoch [5/100], Train Loss: 0.7603, \n",
      "Epoch [6/100], Train Loss: 0.7128, \n",
      "Epoch [7/100], Train Loss: 0.7644, \n",
      "Epoch [8/100], Train Loss: 0.7233, \n",
      "Epoch [9/100], Train Loss: 0.6970, \n",
      "Epoch [10/100], Train Loss: 0.7890, \n",
      "Epoch [11/100], Train Loss: 0.7108, \n",
      "Epoch [12/100], Train Loss: 0.6945, \n",
      "Epoch [13/100], Train Loss: 0.7258, \n",
      "Epoch [14/100], Train Loss: 0.7124, \n",
      "Epoch [15/100], Train Loss: 0.6952, \n",
      "Epoch [16/100], Train Loss: 0.6954, \n",
      "Epoch [17/100], Train Loss: 0.7131, \n",
      "Epoch [18/100], Train Loss: 0.6920, \n",
      "Epoch [19/100], Train Loss: 0.7018, \n",
      "Epoch [20/100], Train Loss: 0.7022, \n",
      "Epoch [21/100], Train Loss: 0.6993, \n",
      "Epoch [22/100], Train Loss: 0.7008, \n",
      "Epoch [23/100], Train Loss: 0.6985, \n",
      "Epoch [24/100], Train Loss: 0.6975, \n",
      "Epoch [25/100], Train Loss: 0.6957, \n",
      "Epoch [26/100], Train Loss: 0.6971, \n",
      "Epoch [27/100], Train Loss: 0.6954, \n",
      "Epoch [28/100], Train Loss: 0.6956, \n",
      "Epoch [29/100], Train Loss: 0.6954, \n",
      "Epoch [30/100], Train Loss: 0.6931, \n",
      "Epoch [31/100], Train Loss: 0.6964, \n",
      "Epoch [32/100], Train Loss: 0.6952, \n",
      "Epoch [33/100], Train Loss: 0.6940, \n",
      "Epoch [34/100], Train Loss: 0.6931, \n",
      "Epoch [35/100], Train Loss: 0.6942, \n",
      "Epoch [36/100], Train Loss: 0.6928, \n",
      "Epoch [37/100], Train Loss: 0.6939, \n",
      "Epoch [38/100], Train Loss: 0.6936, \n",
      "Epoch [39/100], Train Loss: 0.6937, \n",
      "Epoch [40/100], Train Loss: 0.6932, \n",
      "Epoch [41/100], Train Loss: 0.6931, \n",
      "Epoch [42/100], Train Loss: 0.6932, \n",
      "Epoch [43/100], Train Loss: 0.6933, \n",
      "Epoch [44/100], Train Loss: 0.6934, \n",
      "Epoch [45/100], Train Loss: 0.6929, \n",
      "Epoch [46/100], Train Loss: 0.6923, \n",
      "Epoch [47/100], Train Loss: 0.6934, \n",
      "Epoch [48/100], Train Loss: 0.6926, \n",
      "Epoch [49/100], Train Loss: 0.6929, \n",
      "Epoch [50/100], Train Loss: 0.6933, \n",
      "Epoch [51/100], Train Loss: 0.6929, \n",
      "Epoch [52/100], Train Loss: 0.6929, \n",
      "Epoch [53/100], Train Loss: 0.6927, \n",
      "Epoch [54/100], Train Loss: 0.6926, \n",
      "Epoch [55/100], Train Loss: 0.6922, \n",
      "Epoch [56/100], Train Loss: 0.6922, \n",
      "Epoch [57/100], Train Loss: 0.6931, \n",
      "Epoch [58/100], Train Loss: 0.6927, \n",
      "Epoch [59/100], Train Loss: 0.6924, \n",
      "Epoch [60/100], Train Loss: 0.6927, \n",
      "Epoch [61/100], Train Loss: 0.6919, \n",
      "Epoch [62/100], Train Loss: 0.6913, \n",
      "Epoch [63/100], Train Loss: 0.6926, \n",
      "Epoch [64/100], Train Loss: 0.6917, \n",
      "Epoch [65/100], Train Loss: 0.6928, \n",
      "Epoch [66/100], Train Loss: 0.6925, \n",
      "Epoch [67/100], Train Loss: 0.6931, \n",
      "Epoch [68/100], Train Loss: 0.6924, \n",
      "Epoch [69/100], Train Loss: 0.6928, \n",
      "Epoch [70/100], Train Loss: 0.6928, \n",
      "Epoch [71/100], Train Loss: 0.6929, \n",
      "Epoch [72/100], Train Loss: 0.6930, \n",
      "Epoch [73/100], Train Loss: 0.6935, \n",
      "Epoch [74/100], Train Loss: 0.6924, \n",
      "Epoch [75/100], Train Loss: 0.6927, \n",
      "Epoch [76/100], Train Loss: 0.6925, \n",
      "Epoch [77/100], Train Loss: 0.6927, \n",
      "Epoch [78/100], Train Loss: 0.6929, \n",
      "Epoch [79/100], Train Loss: 0.6938, \n",
      "Epoch [80/100], Train Loss: 0.6922, \n",
      "Epoch [81/100], Train Loss: 0.6929, \n",
      "Epoch [82/100], Train Loss: 0.6924, \n",
      "Epoch [83/100], Train Loss: 0.6928, \n",
      "Epoch [84/100], Train Loss: 0.6929, \n",
      "Epoch [85/100], Train Loss: 0.6928, \n",
      "Epoch [86/100], Train Loss: 0.6919, \n",
      "Epoch [87/100], Train Loss: 0.6925, \n",
      "Epoch [88/100], Train Loss: 0.6935, \n",
      "Epoch [89/100], Train Loss: 0.6921, \n",
      "Epoch [90/100], Train Loss: 0.6923, \n",
      "Epoch [91/100], Train Loss: 0.6923, \n",
      "Epoch [92/100], Train Loss: 0.6925, \n",
      "Epoch [93/100], Train Loss: 0.6918, \n",
      "Epoch [94/100], Train Loss: 0.6916, \n",
      "Epoch [95/100], Train Loss: 0.6925, \n",
      "Epoch [96/100], Train Loss: 0.6923, \n",
      "Epoch [97/100], Train Loss: 0.6923, \n",
      "Epoch [98/100], Train Loss: 0.6927, \n",
      "Epoch [99/100], Train Loss: 0.6925, \n",
      "Epoch [100/100], Train Loss: 0.6922, \n",
      "training loss at last epoch: 0.692\n",
      "seed = 1\n",
      "18000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 1254.6535, \n",
      "Epoch [2/100], Train Loss: 86.2524, \n",
      "Epoch [3/100], Train Loss: 186.3514, \n",
      "Epoch [4/100], Train Loss: 90.9046, \n",
      "Epoch [5/100], Train Loss: 437.1836, \n",
      "Epoch [6/100], Train Loss: 335.7159, \n",
      "Epoch [7/100], Train Loss: 244.2817, \n",
      "Epoch [8/100], Train Loss: 157.7316, \n",
      "Epoch [9/100], Train Loss: 82.4738, \n",
      "Epoch [10/100], Train Loss: 52.2289, \n",
      "Epoch [11/100], Train Loss: 99.4976, \n",
      "Epoch [12/100], Train Loss: 52.3226, \n",
      "Epoch [13/100], Train Loss: 231.8521, \n",
      "Epoch [14/100], Train Loss: 151.8436, \n",
      "Epoch [15/100], Train Loss: 85.2739, \n",
      "Epoch [16/100], Train Loss: 72.6361, \n",
      "Epoch [17/100], Train Loss: 455.5886, \n",
      "Epoch [18/100], Train Loss: 370.7258, \n",
      "Epoch [19/100], Train Loss: 295.2651, \n",
      "Epoch [20/100], Train Loss: 227.2839, \n",
      "Epoch [21/100], Train Loss: 159.7769, \n",
      "Epoch [22/100], Train Loss: 103.3548, \n",
      "Epoch [23/100], Train Loss: 59.7080, \n",
      "Epoch [24/100], Train Loss: 119.1361, \n",
      "Epoch [25/100], Train Loss: 67.7112, \n",
      "Epoch [26/100], Train Loss: 44.9270, \n",
      "Epoch [27/100], Train Loss: 390.9240, \n",
      "Epoch [28/100], Train Loss: 327.1786, \n",
      "Epoch [29/100], Train Loss: 266.7027, \n",
      "Epoch [30/100], Train Loss: 211.6697, \n",
      "Epoch [31/100], Train Loss: 160.2840, \n",
      "Epoch [32/100], Train Loss: 112.9173, \n",
      "Epoch [33/100], Train Loss: 79.1570, \n",
      "Epoch [34/100], Train Loss: 62.9044, \n",
      "Epoch [35/100], Train Loss: 65.0589, \n",
      "Epoch [36/100], Train Loss: 57.4270, \n",
      "Epoch [37/100], Train Loss: 41.6673, \n",
      "Epoch [38/100], Train Loss: 135.7815, \n",
      "Epoch [39/100], Train Loss: 322.3205, \n",
      "Epoch [40/100], Train Loss: 275.1365, \n",
      "Epoch [41/100], Train Loss: 231.0690, \n",
      "Epoch [42/100], Train Loss: 191.0363, \n",
      "Epoch [43/100], Train Loss: 153.8664, \n",
      "Epoch [44/100], Train Loss: 118.8553, \n",
      "Epoch [45/100], Train Loss: 86.7546, \n",
      "Epoch [46/100], Train Loss: 59.6616, \n",
      "Epoch [47/100], Train Loss: 42.8082, \n",
      "Epoch [48/100], Train Loss: 40.5138, \n",
      "Epoch [49/100], Train Loss: 37.1065, \n",
      "Epoch [50/100], Train Loss: 26.3886, \n",
      "Epoch [51/100], Train Loss: 39.9477, \n",
      "Epoch [52/100], Train Loss: 36.2853, \n",
      "Epoch [53/100], Train Loss: 22.5968, \n",
      "Epoch [54/100], Train Loss: 34.3829, \n",
      "Epoch [55/100], Train Loss: 23.4640, \n",
      "Epoch [56/100], Train Loss: 27.3135, \n",
      "Epoch [57/100], Train Loss: 26.1074, \n",
      "Epoch [58/100], Train Loss: 29.0316, \n",
      "Epoch [59/100], Train Loss: 23.5467, \n",
      "Epoch [60/100], Train Loss: 19.6473, \n",
      "Epoch [61/100], Train Loss: 26.9103, \n",
      "Epoch [62/100], Train Loss: 21.0164, \n",
      "Epoch [63/100], Train Loss: 49.2226, \n",
      "Epoch [64/100], Train Loss: 131.9330, \n",
      "Epoch [65/100], Train Loss: 107.3118, \n",
      "Epoch [66/100], Train Loss: 86.0265, \n",
      "Epoch [67/100], Train Loss: 65.3620, \n",
      "Epoch [68/100], Train Loss: 45.7226, \n",
      "Epoch [69/100], Train Loss: 28.5863, \n",
      "Epoch [70/100], Train Loss: 23.1202, \n",
      "Epoch [71/100], Train Loss: 15.9367, \n",
      "Epoch [72/100], Train Loss: 20.0305, \n",
      "Epoch [73/100], Train Loss: 12.1835, \n",
      "Epoch [74/100], Train Loss: 26.7800, \n",
      "Epoch [75/100], Train Loss: 18.1274, \n",
      "Epoch [76/100], Train Loss: 14.4223, \n",
      "Epoch [77/100], Train Loss: 20.4402, \n",
      "Epoch [78/100], Train Loss: 10.4596, \n",
      "Epoch [79/100], Train Loss: 21.6793, \n",
      "Epoch [80/100], Train Loss: 19.1894, \n",
      "Epoch [81/100], Train Loss: 17.7025, \n",
      "Epoch [82/100], Train Loss: 12.4094, \n",
      "Epoch [83/100], Train Loss: 43.6804, \n",
      "Epoch [84/100], Train Loss: 28.9447, \n",
      "Epoch [85/100], Train Loss: 18.4137, \n",
      "Epoch [86/100], Train Loss: 17.9573, \n",
      "Epoch [87/100], Train Loss: 9.6876, \n",
      "Epoch [88/100], Train Loss: 14.8683, \n",
      "Epoch [89/100], Train Loss: 11.3514, \n",
      "Epoch [90/100], Train Loss: 14.2369, \n",
      "Epoch [91/100], Train Loss: 13.9098, \n",
      "Epoch [92/100], Train Loss: 10.1659, \n",
      "Epoch [93/100], Train Loss: 22.3297, \n",
      "Epoch [94/100], Train Loss: 10.8561, \n",
      "Epoch [95/100], Train Loss: 11.0751, \n",
      "Epoch [96/100], Train Loss: 13.7801, \n",
      "Epoch [97/100], Train Loss: 14.0935, \n",
      "Epoch [98/100], Train Loss: 115.5800, \n",
      "Epoch [99/100], Train Loss: 100.3454, \n",
      "Epoch [100/100], Train Loss: 87.6302, \n",
      "training loss at last epoch: 87.630\n",
      "Epoch [1/100], Train Loss: 24361.5283, \n",
      "Epoch [2/100], Train Loss: 8973.7940, \n",
      "Epoch [3/100], Train Loss: 5089.0827, \n",
      "Epoch [4/100], Train Loss: 8850.2573, \n",
      "Epoch [5/100], Train Loss: 4228.9288, \n",
      "Epoch [6/100], Train Loss: 1814.4396, \n",
      "Epoch [7/100], Train Loss: 5892.4366, \n",
      "Epoch [8/100], Train Loss: 2911.8133, \n",
      "Epoch [9/100], Train Loss: 9161.4495, \n",
      "Epoch [10/100], Train Loss: 20792.0065, \n",
      "Epoch [11/100], Train Loss: 5364.1983, \n",
      "Epoch [12/100], Train Loss: 0.6929, \n",
      "Epoch [13/100], Train Loss: 0.6929, \n",
      "Epoch [14/100], Train Loss: 0.6926, \n",
      "Epoch [15/100], Train Loss: 0.6922, \n",
      "Epoch [16/100], Train Loss: 0.6924, \n",
      "Epoch [17/100], Train Loss: 0.6925, \n",
      "Epoch [18/100], Train Loss: 0.6926, \n",
      "Epoch [19/100], Train Loss: 0.6924, \n",
      "Epoch [20/100], Train Loss: 0.6925, \n",
      "Epoch [21/100], Train Loss: 0.6929, \n",
      "Epoch [22/100], Train Loss: 0.6929, \n",
      "Epoch [23/100], Train Loss: 0.6927, \n",
      "Epoch [24/100], Train Loss: 0.6928, \n",
      "Epoch [25/100], Train Loss: 0.6931, \n",
      "Epoch [26/100], Train Loss: 0.6927, \n",
      "Epoch [27/100], Train Loss: 0.6926, \n",
      "Epoch [28/100], Train Loss: 0.6926, \n",
      "Epoch [29/100], Train Loss: 0.6939, \n",
      "Epoch [30/100], Train Loss: 0.6930, \n",
      "Epoch [31/100], Train Loss: 0.6931, \n",
      "Epoch [32/100], Train Loss: 0.6929, \n",
      "Epoch [33/100], Train Loss: 0.6925, \n",
      "Epoch [34/100], Train Loss: 0.6928, \n",
      "Epoch [35/100], Train Loss: 0.6929, \n",
      "Epoch [36/100], Train Loss: 0.6931, \n",
      "Epoch [37/100], Train Loss: 0.6926, \n",
      "Epoch [38/100], Train Loss: 0.6936, \n",
      "Epoch [39/100], Train Loss: 0.6923, \n",
      "Epoch [40/100], Train Loss: 0.6935, \n",
      "Epoch [41/100], Train Loss: 0.6925, \n",
      "Epoch [42/100], Train Loss: 0.6927, \n",
      "Epoch [43/100], Train Loss: 0.6924, \n",
      "Epoch [44/100], Train Loss: 0.6932, \n",
      "Epoch [45/100], Train Loss: 0.6929, \n",
      "Epoch [46/100], Train Loss: 0.6923, \n",
      "Epoch [47/100], Train Loss: 0.6930, \n",
      "Epoch [48/100], Train Loss: 0.6928, \n",
      "Epoch [49/100], Train Loss: 0.6927, \n",
      "Epoch [50/100], Train Loss: 0.6934, \n",
      "Epoch [51/100], Train Loss: 0.6925, \n",
      "Epoch [52/100], Train Loss: 0.6927, \n",
      "Epoch [53/100], Train Loss: 0.6926, \n",
      "Epoch [54/100], Train Loss: 0.6928, \n",
      "Epoch [55/100], Train Loss: 0.6934, \n",
      "Epoch [56/100], Train Loss: 0.6927, \n",
      "Epoch [57/100], Train Loss: 0.6927, \n",
      "Epoch [58/100], Train Loss: 0.6933, \n",
      "Epoch [59/100], Train Loss: 0.6944, \n",
      "Epoch [60/100], Train Loss: 0.6931, \n",
      "Epoch [61/100], Train Loss: 0.6920, \n",
      "Epoch [62/100], Train Loss: 0.6931, \n",
      "Epoch [63/100], Train Loss: 0.6926, \n",
      "Epoch [64/100], Train Loss: 0.6922, \n",
      "Epoch [65/100], Train Loss: 0.6937, \n",
      "Epoch [66/100], Train Loss: 0.6931, \n",
      "Epoch [67/100], Train Loss: 0.6926, \n",
      "Epoch [68/100], Train Loss: 0.6926, \n",
      "Epoch [69/100], Train Loss: 0.6927, \n",
      "Epoch [70/100], Train Loss: 0.6926, \n",
      "Epoch [71/100], Train Loss: 0.6928, \n",
      "Epoch [72/100], Train Loss: 0.6926, \n",
      "Epoch [73/100], Train Loss: 0.6931, \n",
      "Epoch [74/100], Train Loss: 0.6937, \n",
      "Epoch [75/100], Train Loss: 0.6921, \n",
      "Epoch [76/100], Train Loss: 0.6932, \n",
      "Epoch [77/100], Train Loss: 0.6932, \n",
      "Epoch [78/100], Train Loss: 0.6927, \n",
      "Epoch [79/100], Train Loss: 0.6924, \n",
      "Epoch [80/100], Train Loss: 0.6928, \n",
      "Epoch [81/100], Train Loss: 0.6929, \n",
      "Epoch [82/100], Train Loss: 0.6928, \n",
      "Epoch [83/100], Train Loss: 0.6926, \n",
      "Epoch [84/100], Train Loss: 0.6936, \n",
      "Epoch [85/100], Train Loss: 0.6925, \n",
      "Epoch [86/100], Train Loss: 0.6931, \n",
      "Epoch [87/100], Train Loss: 0.6937, \n",
      "Epoch [88/100], Train Loss: 0.6925, \n",
      "Epoch [89/100], Train Loss: 0.6922, \n",
      "Epoch [90/100], Train Loss: 0.6935, \n",
      "Epoch [91/100], Train Loss: 0.6927, \n",
      "Epoch [92/100], Train Loss: 0.6923, \n",
      "Epoch [93/100], Train Loss: 0.6928, \n",
      "Epoch [94/100], Train Loss: 0.6923, \n",
      "Epoch [95/100], Train Loss: 0.6932, \n",
      "Epoch [96/100], Train Loss: 0.6924, \n",
      "Epoch [97/100], Train Loss: 0.6929, \n",
      "Epoch [98/100], Train Loss: 0.6930, \n",
      "Epoch [99/100], Train Loss: 0.6929, \n",
      "Epoch [100/100], Train Loss: 0.6926, \n",
      "training loss at last epoch: 0.693\n",
      "seed = 2\n",
      "18000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 1209.0381, \n",
      "Epoch [2/100], Train Loss: 293.3463, \n",
      "Epoch [3/100], Train Loss: 321.2224, \n",
      "Epoch [4/100], Train Loss: 387.7886, \n",
      "Epoch [5/100], Train Loss: 131.1847, \n",
      "Epoch [6/100], Train Loss: 192.3958, \n",
      "Epoch [7/100], Train Loss: 263.2710, \n",
      "Epoch [8/100], Train Loss: 247.7426, \n",
      "Epoch [9/100], Train Loss: 360.8358, \n",
      "Epoch [10/100], Train Loss: 537.1048, \n",
      "Epoch [11/100], Train Loss: 327.6555, \n",
      "Epoch [12/100], Train Loss: 151.3391, \n",
      "Epoch [13/100], Train Loss: 64.1015, \n",
      "Epoch [14/100], Train Loss: 42.7213, \n",
      "Epoch [15/100], Train Loss: 190.6375, \n",
      "Epoch [16/100], Train Loss: 293.8745, \n",
      "Epoch [17/100], Train Loss: 157.7410, \n",
      "Epoch [18/100], Train Loss: 67.4042, \n",
      "Epoch [19/100], Train Loss: 115.1079, \n",
      "Epoch [20/100], Train Loss: 151.8672, \n",
      "Epoch [21/100], Train Loss: 66.2516, \n",
      "Epoch [22/100], Train Loss: 43.4440, \n",
      "Epoch [23/100], Train Loss: 39.4286, \n",
      "Epoch [24/100], Train Loss: 35.9495, \n",
      "Epoch [25/100], Train Loss: 32.2862, \n",
      "Epoch [26/100], Train Loss: 35.8373, \n",
      "Epoch [27/100], Train Loss: 39.6017, \n",
      "Epoch [28/100], Train Loss: 26.8507, \n",
      "Epoch [29/100], Train Loss: 31.4804, \n",
      "Epoch [30/100], Train Loss: 27.2737, \n",
      "Epoch [31/100], Train Loss: 36.4148, \n",
      "Epoch [32/100], Train Loss: 95.4601, \n",
      "Epoch [33/100], Train Loss: 43.4678, \n",
      "Epoch [34/100], Train Loss: 18.1220, \n",
      "Epoch [35/100], Train Loss: 22.4725, \n",
      "Epoch [36/100], Train Loss: 31.1680, \n",
      "Epoch [37/100], Train Loss: 15.9428, \n",
      "Epoch [38/100], Train Loss: 17.8566, \n",
      "Epoch [39/100], Train Loss: 20.0161, \n",
      "Epoch [40/100], Train Loss: 20.4375, \n",
      "Epoch [41/100], Train Loss: 14.8600, \n",
      "Epoch [42/100], Train Loss: 16.6840, \n",
      "Epoch [43/100], Train Loss: 12.4460, \n",
      "Epoch [44/100], Train Loss: 22.5720, \n",
      "Epoch [45/100], Train Loss: 11.5509, \n",
      "Epoch [46/100], Train Loss: 10.1831, \n",
      "Epoch [47/100], Train Loss: 14.4251, \n",
      "Epoch [48/100], Train Loss: 10.8771, \n",
      "Epoch [49/100], Train Loss: 14.5380, \n",
      "Epoch [50/100], Train Loss: 14.3725, \n",
      "Epoch [51/100], Train Loss: 14.2267, \n",
      "Epoch [52/100], Train Loss: 11.0801, \n",
      "Epoch [53/100], Train Loss: 6.7421, \n",
      "Epoch [54/100], Train Loss: 14.5284, \n",
      "Epoch [55/100], Train Loss: 8.0313, \n",
      "Epoch [56/100], Train Loss: 8.9092, \n",
      "Epoch [57/100], Train Loss: 11.2329, \n",
      "Epoch [58/100], Train Loss: 5.5823, \n",
      "Epoch [59/100], Train Loss: 7.8995, \n",
      "Epoch [60/100], Train Loss: 7.0553, \n",
      "Epoch [61/100], Train Loss: 11.0681, \n",
      "Epoch [62/100], Train Loss: 5.7573, \n",
      "Epoch [63/100], Train Loss: 8.5653, \n",
      "Epoch [64/100], Train Loss: 42.3839, \n",
      "Epoch [65/100], Train Loss: 77.9358, \n",
      "Epoch [66/100], Train Loss: 52.1142, \n",
      "Epoch [67/100], Train Loss: 31.9513, \n",
      "Epoch [68/100], Train Loss: 15.2292, \n",
      "Epoch [69/100], Train Loss: 5.9726, \n",
      "Epoch [70/100], Train Loss: 6.2200, \n",
      "Epoch [71/100], Train Loss: 4.6187, \n",
      "Epoch [72/100], Train Loss: 2.1687, \n",
      "Epoch [73/100], Train Loss: 4.6005, \n",
      "Epoch [74/100], Train Loss: 4.7600, \n",
      "Epoch [75/100], Train Loss: 3.1193, \n",
      "Epoch [76/100], Train Loss: 3.7205, \n",
      "Epoch [77/100], Train Loss: 4.1542, \n",
      "Epoch [78/100], Train Loss: 2.0257, \n",
      "Epoch [79/100], Train Loss: 2.9191, \n",
      "Epoch [80/100], Train Loss: 2.0551, \n",
      "Epoch [81/100], Train Loss: 2.1315, \n",
      "Epoch [82/100], Train Loss: 1.8540, \n",
      "Epoch [83/100], Train Loss: 2.2368, \n",
      "Epoch [84/100], Train Loss: 3.4684, \n",
      "Epoch [85/100], Train Loss: 2.9134, \n",
      "Epoch [86/100], Train Loss: 1.6121, \n",
      "Epoch [87/100], Train Loss: 3.0665, \n",
      "Epoch [88/100], Train Loss: 2.1339, \n",
      "Epoch [89/100], Train Loss: 2.6229, \n",
      "Epoch [90/100], Train Loss: 0.8710, \n",
      "Epoch [91/100], Train Loss: 2.5345, \n",
      "Epoch [92/100], Train Loss: 0.9206, \n",
      "Epoch [93/100], Train Loss: 2.7870, \n",
      "Epoch [94/100], Train Loss: 1.2261, \n",
      "Epoch [95/100], Train Loss: 2.5306, \n",
      "Epoch [96/100], Train Loss: 2.2031, \n",
      "Epoch [97/100], Train Loss: 1.4472, \n",
      "Epoch [98/100], Train Loss: 1.7486, \n",
      "Epoch [99/100], Train Loss: 2.0595, \n",
      "Epoch [100/100], Train Loss: 2.3571, \n",
      "training loss at last epoch: 2.357\n",
      "Epoch [1/100], Train Loss: 14.7582, \n",
      "Epoch [2/100], Train Loss: 0.7204, \n",
      "Epoch [3/100], Train Loss: 0.7463, \n",
      "Epoch [4/100], Train Loss: 0.7322, \n",
      "Epoch [5/100], Train Loss: 0.7213, \n",
      "Epoch [6/100], Train Loss: 0.7097, \n",
      "Epoch [7/100], Train Loss: 0.6985, \n",
      "Epoch [8/100], Train Loss: 0.7045, \n",
      "Epoch [9/100], Train Loss: 0.7038, \n",
      "Epoch [10/100], Train Loss: 0.6984, \n",
      "Epoch [11/100], Train Loss: 0.6974, \n",
      "Epoch [12/100], Train Loss: 0.6964, \n",
      "Epoch [13/100], Train Loss: 0.6936, \n",
      "Epoch [14/100], Train Loss: 0.6963, \n",
      "Epoch [15/100], Train Loss: 0.6957, \n",
      "Epoch [16/100], Train Loss: 0.6949, \n",
      "Epoch [17/100], Train Loss: 0.6947, \n",
      "Epoch [18/100], Train Loss: 0.6931, \n",
      "Epoch [19/100], Train Loss: 0.6939, \n",
      "Epoch [20/100], Train Loss: 0.6940, \n",
      "Epoch [21/100], Train Loss: 0.6925, \n",
      "Epoch [22/100], Train Loss: 0.6928, \n",
      "Epoch [23/100], Train Loss: 0.6932, \n",
      "Epoch [24/100], Train Loss: 0.6934, \n",
      "Epoch [25/100], Train Loss: 0.6923, \n",
      "Epoch [26/100], Train Loss: 0.6929, \n",
      "Epoch [27/100], Train Loss: 0.6928, \n",
      "Epoch [28/100], Train Loss: 0.6928, \n",
      "Epoch [29/100], Train Loss: 0.6928, \n",
      "Epoch [30/100], Train Loss: 0.6940, \n",
      "Epoch [31/100], Train Loss: 0.6935, \n",
      "Epoch [32/100], Train Loss: 0.6935, \n",
      "Epoch [33/100], Train Loss: 0.6928, \n",
      "Epoch [34/100], Train Loss: 0.6933, \n",
      "Epoch [35/100], Train Loss: 0.6925, \n",
      "Epoch [36/100], Train Loss: 0.6924, \n",
      "Epoch [37/100], Train Loss: 0.6931, \n",
      "Epoch [38/100], Train Loss: 0.6929, \n",
      "Epoch [39/100], Train Loss: 0.6922, \n",
      "Epoch [40/100], Train Loss: 0.6923, \n",
      "Epoch [41/100], Train Loss: 0.6921, \n",
      "Epoch [42/100], Train Loss: 0.6939, \n",
      "Epoch [43/100], Train Loss: 0.6936, \n",
      "Epoch [44/100], Train Loss: 0.6938, \n",
      "Epoch [45/100], Train Loss: 0.6929, \n",
      "Epoch [46/100], Train Loss: 0.6929, \n",
      "Epoch [47/100], Train Loss: 0.6937, \n",
      "Epoch [48/100], Train Loss: 0.6928, \n",
      "Epoch [49/100], Train Loss: 0.6928, \n",
      "Epoch [50/100], Train Loss: 0.6931, \n",
      "Epoch [51/100], Train Loss: 0.6925, \n",
      "Epoch [52/100], Train Loss: 0.6931, \n",
      "Epoch [53/100], Train Loss: 0.6931, \n",
      "Epoch [54/100], Train Loss: 0.6936, \n",
      "Epoch [55/100], Train Loss: 0.6928, \n",
      "Epoch [56/100], Train Loss: 0.6932, \n",
      "Epoch [57/100], Train Loss: 0.6924, \n",
      "Epoch [58/100], Train Loss: 0.6925, \n",
      "Epoch [59/100], Train Loss: 0.6929, \n",
      "Epoch [60/100], Train Loss: 0.6930, \n",
      "Epoch [61/100], Train Loss: 0.6925, \n",
      "Epoch [62/100], Train Loss: 0.6931, \n",
      "Epoch [63/100], Train Loss: 0.6923, \n",
      "Epoch [64/100], Train Loss: 0.6935, \n",
      "Epoch [65/100], Train Loss: 0.6929, \n",
      "Epoch [66/100], Train Loss: 0.6934, \n",
      "Epoch [67/100], Train Loss: 0.6933, \n",
      "Epoch [68/100], Train Loss: 0.6922, \n",
      "Epoch [69/100], Train Loss: 0.6936, \n",
      "Epoch [70/100], Train Loss: 0.6926, \n",
      "Epoch [71/100], Train Loss: 0.6928, \n",
      "Epoch [72/100], Train Loss: 0.6928, \n",
      "Epoch [73/100], Train Loss: 0.6923, \n",
      "Epoch [74/100], Train Loss: 0.6929, \n",
      "Epoch [75/100], Train Loss: 0.6930, \n",
      "Epoch [76/100], Train Loss: 0.6933, \n",
      "Epoch [77/100], Train Loss: 0.6928, \n",
      "Epoch [78/100], Train Loss: 0.6926, \n",
      "Epoch [79/100], Train Loss: 0.6928, \n",
      "Epoch [80/100], Train Loss: 0.6930, \n",
      "Epoch [81/100], Train Loss: 0.6937, \n",
      "Epoch [82/100], Train Loss: 0.6929, \n",
      "Epoch [83/100], Train Loss: 0.6929, \n",
      "Epoch [84/100], Train Loss: 0.6926, \n",
      "Epoch [85/100], Train Loss: 0.6930, \n",
      "Epoch [86/100], Train Loss: 0.6928, \n",
      "Epoch [87/100], Train Loss: 0.6935, \n",
      "Epoch [88/100], Train Loss: 0.6928, \n",
      "Epoch [89/100], Train Loss: 0.6931, \n",
      "Epoch [90/100], Train Loss: 0.6935, \n",
      "Epoch [91/100], Train Loss: 0.6932, \n",
      "Epoch [92/100], Train Loss: 0.6930, \n",
      "Epoch [93/100], Train Loss: 0.6927, \n",
      "Epoch [94/100], Train Loss: 0.6921, \n",
      "Epoch [95/100], Train Loss: 0.6927, \n",
      "Epoch [96/100], Train Loss: 0.6932, \n",
      "Epoch [97/100], Train Loss: 0.6932, \n",
      "Epoch [98/100], Train Loss: 0.6929, \n",
      "Epoch [99/100], Train Loss: 0.6921, \n",
      "Epoch [100/100], Train Loss: 0.6928, \n",
      "training loss at last epoch: 0.693\n",
      "time t = 500\n",
      "seed = 0\n",
      "20000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 18743.8667, \n",
      "Epoch [2/100], Train Loss: 13036.4638, \n",
      "Epoch [3/100], Train Loss: 10229.2083, \n",
      "Epoch [4/100], Train Loss: 7738.5439, \n",
      "Epoch [5/100], Train Loss: 5279.5729, \n",
      "Epoch [6/100], Train Loss: 3025.8902, \n",
      "Epoch [7/100], Train Loss: 4634.2477, \n",
      "Epoch [8/100], Train Loss: 9386.0699, \n",
      "Epoch [9/100], Train Loss: 7092.0166, \n",
      "Epoch [10/100], Train Loss: 4947.6256, \n",
      "Epoch [11/100], Train Loss: 2985.4083, \n",
      "Epoch [12/100], Train Loss: 3136.4143, \n",
      "Epoch [13/100], Train Loss: 14211.5148, \n",
      "Epoch [14/100], Train Loss: 12093.3476, \n",
      "Epoch [15/100], Train Loss: 9945.6539, \n",
      "Epoch [16/100], Train Loss: 8138.3256, \n",
      "Epoch [17/100], Train Loss: 6394.3618, \n",
      "Epoch [18/100], Train Loss: 4740.3996, \n",
      "Epoch [19/100], Train Loss: 3215.0884, \n",
      "Epoch [20/100], Train Loss: 1757.5242, \n",
      "Epoch [21/100], Train Loss: 1034.6786, \n",
      "Epoch [22/100], Train Loss: 11029.9571, \n",
      "Epoch [23/100], Train Loss: 9350.1323, \n",
      "Epoch [24/100], Train Loss: 7833.1518, \n",
      "Epoch [25/100], Train Loss: 6492.1979, \n",
      "Epoch [26/100], Train Loss: 5174.5333, \n",
      "Epoch [27/100], Train Loss: 3983.6417, \n",
      "Epoch [28/100], Train Loss: 2870.0442, \n",
      "Epoch [29/100], Train Loss: 1843.5178, \n",
      "Epoch [30/100], Train Loss: 969.6866, \n",
      "Epoch [31/100], Train Loss: 3272.7031, \n",
      "Epoch [32/100], Train Loss: 2285.6152, \n",
      "Epoch [33/100], Train Loss: 1341.7262, \n",
      "Epoch [34/100], Train Loss: 1344.8658, \n",
      "Epoch [35/100], Train Loss: 1859.7186, \n",
      "Epoch [36/100], Train Loss: 974.5355, \n",
      "Epoch [37/100], Train Loss: 168.0307, \n",
      "Epoch [38/100], Train Loss: 394.8067, \n",
      "Epoch [39/100], Train Loss: 6441.1833, \n",
      "Epoch [40/100], Train Loss: 4189.3498, \n",
      "Epoch [41/100], Train Loss: 3350.3471, \n",
      "Epoch [42/100], Train Loss: 2569.3058, \n",
      "Epoch [43/100], Train Loss: 1812.4254, \n",
      "Epoch [44/100], Train Loss: 1126.6065, \n",
      "Epoch [45/100], Train Loss: 547.8804, \n",
      "Epoch [46/100], Train Loss: 1188.3176, \n",
      "Epoch [47/100], Train Loss: 555.4010, \n",
      "Epoch [48/100], Train Loss: 1091.5971, \n",
      "Epoch [49/100], Train Loss: 505.2421, \n",
      "Epoch [50/100], Train Loss: 524.3132, \n",
      "Epoch [51/100], Train Loss: 1683.1389, \n",
      "Epoch [52/100], Train Loss: 1067.9984, \n",
      "Epoch [53/100], Train Loss: 541.1528, \n",
      "Epoch [54/100], Train Loss: 541.7310, \n",
      "Epoch [55/100], Train Loss: 5056.5650, \n",
      "Epoch [56/100], Train Loss: 6988.9956, \n",
      "Epoch [57/100], Train Loss: 6158.8361, \n",
      "Epoch [58/100], Train Loss: 5408.7720, \n",
      "Epoch [59/100], Train Loss: 4737.6313, \n",
      "Epoch [60/100], Train Loss: 4155.9778, \n",
      "Epoch [61/100], Train Loss: 3610.5741, \n",
      "Epoch [62/100], Train Loss: 3144.3213, \n",
      "Epoch [63/100], Train Loss: 2727.5080, \n",
      "Epoch [64/100], Train Loss: 2349.3630, \n",
      "Epoch [65/100], Train Loss: 1986.6629, \n",
      "Epoch [66/100], Train Loss: 1679.7953, \n",
      "Epoch [67/100], Train Loss: 1395.9726, \n",
      "Epoch [68/100], Train Loss: 1132.7282, \n",
      "Epoch [69/100], Train Loss: 885.4113, \n",
      "Epoch [70/100], Train Loss: 655.3225, \n",
      "Epoch [71/100], Train Loss: 435.1346, \n",
      "Epoch [72/100], Train Loss: 230.9579, \n",
      "Epoch [73/100], Train Loss: 236.9822, \n",
      "Epoch [74/100], Train Loss: 2250.0831, \n",
      "Epoch [75/100], Train Loss: 1945.7280, \n",
      "Epoch [76/100], Train Loss: 1674.6675, \n",
      "Epoch [77/100], Train Loss: 1457.5089, \n",
      "Epoch [78/100], Train Loss: 1263.5561, \n",
      "Epoch [79/100], Train Loss: 1082.3815, \n",
      "Epoch [80/100], Train Loss: 914.2377, \n",
      "Epoch [81/100], Train Loss: 765.9232, \n",
      "Epoch [82/100], Train Loss: 624.6504, \n",
      "Epoch [83/100], Train Loss: 503.3487, \n",
      "Epoch [84/100], Train Loss: 383.3385, \n",
      "Epoch [85/100], Train Loss: 271.4978, \n",
      "Epoch [86/100], Train Loss: 167.8190, \n",
      "Epoch [87/100], Train Loss: 78.8621, \n",
      "Epoch [88/100], Train Loss: 110.1930, \n",
      "Epoch [89/100], Train Loss: 18.3992, \n",
      "Epoch [90/100], Train Loss: 113.9806, \n",
      "Epoch [91/100], Train Loss: 71.3055, \n",
      "Epoch [92/100], Train Loss: 0.7716, \n",
      "Epoch [93/100], Train Loss: 87.2097, \n",
      "Epoch [94/100], Train Loss: 86.5643, \n",
      "Epoch [95/100], Train Loss: 87.3068, \n",
      "Epoch [96/100], Train Loss: 9.0175, \n",
      "Epoch [97/100], Train Loss: 293.3305, \n",
      "Epoch [98/100], Train Loss: 182.5235, \n",
      "Epoch [99/100], Train Loss: 100.7578, \n",
      "Epoch [100/100], Train Loss: 54.7350, \n",
      "training loss at last epoch: 54.735\n",
      "Epoch [1/100], Train Loss: 57.7822, \n",
      "Epoch [2/100], Train Loss: 3.7456, \n",
      "Epoch [3/100], Train Loss: 0.8399, \n",
      "Epoch [4/100], Train Loss: 0.7750, \n",
      "Epoch [5/100], Train Loss: 0.7388, \n",
      "Epoch [6/100], Train Loss: 0.7240, \n",
      "Epoch [7/100], Train Loss: 0.7123, \n",
      "Epoch [8/100], Train Loss: 0.7057, \n",
      "Epoch [9/100], Train Loss: 0.7038, \n",
      "Epoch [10/100], Train Loss: 0.7008, \n",
      "Epoch [11/100], Train Loss: 0.7599, \n",
      "Epoch [12/100], Train Loss: 0.6996, \n",
      "Epoch [13/100], Train Loss: 0.6960, \n",
      "Epoch [14/100], Train Loss: 0.6984, \n",
      "Epoch [15/100], Train Loss: 0.6974, \n",
      "Epoch [16/100], Train Loss: 0.6957, \n",
      "Epoch [17/100], Train Loss: 0.6944, \n",
      "Epoch [18/100], Train Loss: 0.6955, \n",
      "Epoch [19/100], Train Loss: 0.6958, \n",
      "Epoch [20/100], Train Loss: 0.6952, \n",
      "Epoch [21/100], Train Loss: 0.6955, \n",
      "Epoch [22/100], Train Loss: 0.6954, \n",
      "Epoch [23/100], Train Loss: 0.6929, \n",
      "Epoch [24/100], Train Loss: 0.6940, \n",
      "Epoch [25/100], Train Loss: 0.6935, \n",
      "Epoch [26/100], Train Loss: 0.6956, \n",
      "Epoch [27/100], Train Loss: 0.6939, \n",
      "Epoch [28/100], Train Loss: 0.6936, \n",
      "Epoch [29/100], Train Loss: 0.6934, \n",
      "Epoch [30/100], Train Loss: 0.6940, \n",
      "Epoch [31/100], Train Loss: 0.6922, \n",
      "Epoch [32/100], Train Loss: 0.6929, \n",
      "Epoch [33/100], Train Loss: 0.6931, \n",
      "Epoch [34/100], Train Loss: 0.6926, \n",
      "Epoch [35/100], Train Loss: 0.6938, \n",
      "Epoch [36/100], Train Loss: 0.6938, \n",
      "Epoch [37/100], Train Loss: 0.6943, \n",
      "Epoch [38/100], Train Loss: 0.6925, \n",
      "Epoch [39/100], Train Loss: 0.6924, \n",
      "Epoch [40/100], Train Loss: 0.6931, \n",
      "Epoch [41/100], Train Loss: 0.6938, \n",
      "Epoch [42/100], Train Loss: 0.6931, \n",
      "Epoch [43/100], Train Loss: 0.6942, \n",
      "Epoch [44/100], Train Loss: 0.6938, \n",
      "Epoch [45/100], Train Loss: 0.6931, \n",
      "Epoch [46/100], Train Loss: 0.6935, \n",
      "Epoch [47/100], Train Loss: 0.6931, \n",
      "Epoch [48/100], Train Loss: 0.6927, \n",
      "Epoch [49/100], Train Loss: 0.6937, \n",
      "Epoch [50/100], Train Loss: 0.6933, \n",
      "Epoch [51/100], Train Loss: 0.6929, \n",
      "Epoch [52/100], Train Loss: 0.6931, \n",
      "Epoch [53/100], Train Loss: 0.6922, \n",
      "Epoch [54/100], Train Loss: 0.6930, \n",
      "Epoch [55/100], Train Loss: 0.6931, \n",
      "Epoch [56/100], Train Loss: 0.6927, \n",
      "Epoch [57/100], Train Loss: 0.6932, \n",
      "Epoch [58/100], Train Loss: 0.6935, \n",
      "Epoch [59/100], Train Loss: 0.6932, \n",
      "Epoch [60/100], Train Loss: 0.6925, \n",
      "Epoch [61/100], Train Loss: 0.6929, \n",
      "Epoch [62/100], Train Loss: 0.6931, \n",
      "Epoch [63/100], Train Loss: 0.6924, \n",
      "Epoch [64/100], Train Loss: 0.6925, \n",
      "Epoch [65/100], Train Loss: 0.6928, \n",
      "Epoch [66/100], Train Loss: 0.6930, \n",
      "Epoch [67/100], Train Loss: 0.6931, \n",
      "Epoch [68/100], Train Loss: 0.6944, \n",
      "Epoch [69/100], Train Loss: 0.6925, \n",
      "Epoch [70/100], Train Loss: 0.6923, \n",
      "Epoch [71/100], Train Loss: 0.6938, \n",
      "Epoch [72/100], Train Loss: 0.6932, \n",
      "Epoch [73/100], Train Loss: 0.6931, \n",
      "Epoch [74/100], Train Loss: 0.6925, \n",
      "Epoch [75/100], Train Loss: 0.6932, \n",
      "Epoch [76/100], Train Loss: 0.6935, \n",
      "Epoch [77/100], Train Loss: 0.6927, \n",
      "Epoch [78/100], Train Loss: 0.6924, \n",
      "Epoch [79/100], Train Loss: 0.6935, \n",
      "Epoch [80/100], Train Loss: 0.6931, \n",
      "Epoch [81/100], Train Loss: 0.6927, \n",
      "Epoch [82/100], Train Loss: 0.6928, \n",
      "Epoch [83/100], Train Loss: 0.6924, \n",
      "Epoch [84/100], Train Loss: 0.6930, \n",
      "Epoch [85/100], Train Loss: 0.6928, \n",
      "Epoch [86/100], Train Loss: 0.6932, \n",
      "Epoch [87/100], Train Loss: 0.6927, \n",
      "Epoch [88/100], Train Loss: 0.6924, \n",
      "Epoch [89/100], Train Loss: 0.6938, \n",
      "Epoch [90/100], Train Loss: 0.6922, \n",
      "Epoch [91/100], Train Loss: 0.6919, \n",
      "Epoch [92/100], Train Loss: 0.6922, \n",
      "Epoch [93/100], Train Loss: 0.6928, \n",
      "Epoch [94/100], Train Loss: 0.6938, \n",
      "Epoch [95/100], Train Loss: 0.6932, \n",
      "Epoch [96/100], Train Loss: 0.6936, \n",
      "Epoch [97/100], Train Loss: 0.6931, \n",
      "Epoch [98/100], Train Loss: 0.6929, \n",
      "Epoch [99/100], Train Loss: 0.6925, \n",
      "Epoch [100/100], Train Loss: 0.6934, \n",
      "training loss at last epoch: 0.693\n",
      "seed = 1\n",
      "20000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 2012.5805, \n",
      "Epoch [2/100], Train Loss: 426.9532, \n",
      "Epoch [3/100], Train Loss: 342.5431, \n",
      "Epoch [4/100], Train Loss: 263.0435, \n",
      "Epoch [5/100], Train Loss: 189.7114, \n",
      "Epoch [6/100], Train Loss: 119.9664, \n",
      "Epoch [7/100], Train Loss: 61.5053, \n",
      "Epoch [8/100], Train Loss: 180.7571, \n",
      "Epoch [9/100], Train Loss: 115.8245, \n",
      "Epoch [10/100], Train Loss: 58.7428, \n",
      "Epoch [11/100], Train Loss: 112.9951, \n",
      "Epoch [12/100], Train Loss: 52.9356, \n",
      "Epoch [13/100], Train Loss: 46.6799, \n",
      "Epoch [14/100], Train Loss: 178.6191, \n",
      "Epoch [15/100], Train Loss: 120.6009, \n",
      "Epoch [16/100], Train Loss: 65.7051, \n",
      "Epoch [17/100], Train Loss: 35.6326, \n",
      "Epoch [18/100], Train Loss: 73.5089, \n",
      "Epoch [19/100], Train Loss: 55.9809, \n",
      "Epoch [20/100], Train Loss: 77.6363, \n",
      "Epoch [21/100], Train Loss: 40.8307, \n",
      "Epoch [22/100], Train Loss: 76.4763, \n",
      "Epoch [23/100], Train Loss: 114.3869, \n",
      "Epoch [24/100], Train Loss: 471.9034, \n",
      "Epoch [25/100], Train Loss: 407.3521, \n",
      "Epoch [26/100], Train Loss: 350.1420, \n",
      "Epoch [27/100], Train Loss: 296.3250, \n",
      "Epoch [28/100], Train Loss: 252.2049, \n",
      "Epoch [29/100], Train Loss: 207.5916, \n",
      "Epoch [30/100], Train Loss: 167.0342, \n",
      "Epoch [31/100], Train Loss: 130.2995, \n",
      "Epoch [32/100], Train Loss: 95.2329, \n",
      "Epoch [33/100], Train Loss: 65.7650, \n",
      "Epoch [34/100], Train Loss: 39.0958, \n",
      "Epoch [35/100], Train Loss: 40.2015, \n",
      "Epoch [36/100], Train Loss: 41.5060, \n",
      "Epoch [37/100], Train Loss: 34.7801, \n",
      "Epoch [38/100], Train Loss: 30.0044, \n",
      "Epoch [39/100], Train Loss: 42.1617, \n",
      "Epoch [40/100], Train Loss: 403.1831, \n",
      "Epoch [41/100], Train Loss: 357.0026, \n",
      "Epoch [42/100], Train Loss: 314.3357, \n",
      "Epoch [43/100], Train Loss: 279.0526, \n",
      "Epoch [44/100], Train Loss: 244.5108, \n",
      "Epoch [45/100], Train Loss: 214.1732, \n",
      "Epoch [46/100], Train Loss: 187.3111, \n",
      "Epoch [47/100], Train Loss: 163.8234, \n",
      "Epoch [48/100], Train Loss: 142.0221, \n",
      "Epoch [49/100], Train Loss: 121.2681, \n",
      "Epoch [50/100], Train Loss: 103.3217, \n",
      "Epoch [51/100], Train Loss: 86.7088, \n",
      "Epoch [52/100], Train Loss: 71.9389, \n",
      "Epoch [53/100], Train Loss: 57.3544, \n",
      "Epoch [54/100], Train Loss: 44.3038, \n",
      "Epoch [55/100], Train Loss: 32.9286, \n",
      "Epoch [56/100], Train Loss: 25.6319, \n",
      "Epoch [57/100], Train Loss: 23.6852, \n",
      "Epoch [58/100], Train Loss: 20.4393, \n",
      "Epoch [59/100], Train Loss: 17.1155, \n",
      "Epoch [60/100], Train Loss: 17.7274, \n",
      "Epoch [61/100], Train Loss: 11.7213, \n",
      "Epoch [62/100], Train Loss: 18.1985, \n",
      "Epoch [63/100], Train Loss: 13.4784, \n",
      "Epoch [64/100], Train Loss: 13.3960, \n",
      "Epoch [65/100], Train Loss: 12.6790, \n",
      "Epoch [66/100], Train Loss: 9.9277, \n",
      "Epoch [67/100], Train Loss: 9.6120, \n",
      "Epoch [68/100], Train Loss: 6.1827, \n",
      "Epoch [69/100], Train Loss: 6.9608, \n",
      "Epoch [70/100], Train Loss: 9.8075, \n",
      "Epoch [71/100], Train Loss: 5.0168, \n",
      "Epoch [72/100], Train Loss: 8.3073, \n",
      "Epoch [73/100], Train Loss: 7.2006, \n",
      "Epoch [74/100], Train Loss: 5.0871, \n",
      "Epoch [75/100], Train Loss: 9.0210, \n",
      "Epoch [76/100], Train Loss: 4.1972, \n",
      "Epoch [77/100], Train Loss: 8.8869, \n",
      "Epoch [78/100], Train Loss: 6.9021, \n",
      "Epoch [79/100], Train Loss: 4.4585, \n",
      "Epoch [80/100], Train Loss: 7.9390, \n",
      "Epoch [81/100], Train Loss: 5.5365, \n",
      "Epoch [82/100], Train Loss: 3.1202, \n",
      "Epoch [83/100], Train Loss: 6.3908, \n",
      "Epoch [84/100], Train Loss: 2.2103, \n",
      "Epoch [85/100], Train Loss: 4.0178, \n",
      "Epoch [86/100], Train Loss: 5.4257, \n",
      "Epoch [87/100], Train Loss: 6.1018, \n",
      "Epoch [88/100], Train Loss: 3.1654, \n",
      "Epoch [89/100], Train Loss: 5.0530, \n",
      "Epoch [90/100], Train Loss: 4.5273, \n",
      "Epoch [91/100], Train Loss: 1.8663, \n",
      "Epoch [92/100], Train Loss: 2.8642, \n",
      "Epoch [93/100], Train Loss: 4.0970, \n",
      "Epoch [94/100], Train Loss: 7.0381, \n",
      "Epoch [95/100], Train Loss: 4.1296, \n",
      "Epoch [96/100], Train Loss: 5.7199, \n",
      "Epoch [97/100], Train Loss: 4.8040, \n",
      "Epoch [98/100], Train Loss: 3.7582, \n",
      "Epoch [99/100], Train Loss: 3.5806, \n",
      "Epoch [100/100], Train Loss: 4.3983, \n",
      "training loss at last epoch: 4.398\n",
      "Epoch [1/100], Train Loss: 368.0921, \n",
      "Epoch [2/100], Train Loss: 0.6934, \n",
      "Epoch [3/100], Train Loss: 0.6938, \n",
      "Epoch [4/100], Train Loss: 0.6933, \n",
      "Epoch [5/100], Train Loss: 0.6932, \n",
      "Epoch [6/100], Train Loss: 0.6923, \n",
      "Epoch [7/100], Train Loss: 0.6932, \n",
      "Epoch [8/100], Train Loss: 0.6936, \n",
      "Epoch [9/100], Train Loss: 0.6936, \n",
      "Epoch [10/100], Train Loss: 0.6938, \n",
      "Epoch [11/100], Train Loss: 0.6931, \n",
      "Epoch [12/100], Train Loss: 0.6927, \n",
      "Epoch [13/100], Train Loss: 0.6936, \n",
      "Epoch [14/100], Train Loss: 0.6929, \n",
      "Epoch [15/100], Train Loss: 0.6924, \n",
      "Epoch [16/100], Train Loss: 0.6929, \n",
      "Epoch [17/100], Train Loss: 0.6937, \n",
      "Epoch [18/100], Train Loss: 0.6930, \n",
      "Epoch [19/100], Train Loss: 0.6945, \n",
      "Epoch [20/100], Train Loss: 0.6933, \n",
      "Epoch [21/100], Train Loss: 0.6935, \n",
      "Epoch [22/100], Train Loss: 0.6934, \n",
      "Epoch [23/100], Train Loss: 0.6926, \n",
      "Epoch [24/100], Train Loss: 0.6934, \n",
      "Epoch [25/100], Train Loss: 0.6946, \n",
      "Epoch [26/100], Train Loss: 0.6932, \n",
      "Epoch [27/100], Train Loss: 0.6929, \n",
      "Epoch [28/100], Train Loss: 0.6925, \n",
      "Epoch [29/100], Train Loss: 0.6931, \n",
      "Epoch [30/100], Train Loss: 0.6933, \n",
      "Epoch [31/100], Train Loss: 0.6933, \n",
      "Epoch [32/100], Train Loss: 0.6930, \n",
      "Epoch [33/100], Train Loss: 0.6933, \n",
      "Epoch [34/100], Train Loss: 0.6935, \n",
      "Epoch [35/100], Train Loss: 0.6929, \n",
      "Epoch [36/100], Train Loss: 0.6931, \n",
      "Epoch [37/100], Train Loss: 0.6936, \n",
      "Epoch [38/100], Train Loss: 0.6928, \n",
      "Epoch [39/100], Train Loss: 0.6935, \n",
      "Epoch [40/100], Train Loss: 0.6932, \n",
      "Epoch [41/100], Train Loss: 0.6930, \n",
      "Epoch [42/100], Train Loss: 0.6933, \n",
      "Epoch [43/100], Train Loss: 0.6937, \n",
      "Epoch [44/100], Train Loss: 0.6929, \n",
      "Epoch [45/100], Train Loss: 0.6934, \n",
      "Epoch [46/100], Train Loss: 0.6936, \n",
      "Epoch [47/100], Train Loss: 0.6933, \n",
      "Epoch [48/100], Train Loss: 0.6929, \n",
      "Epoch [49/100], Train Loss: 0.6927, \n",
      "Epoch [50/100], Train Loss: 0.6932, \n",
      "Epoch [51/100], Train Loss: 0.6937, \n",
      "Epoch [52/100], Train Loss: 0.6942, \n",
      "Epoch [53/100], Train Loss: 0.6930, \n",
      "Epoch [54/100], Train Loss: 0.6931, \n",
      "Epoch [55/100], Train Loss: 0.6934, \n",
      "Epoch [56/100], Train Loss: 0.6923, \n",
      "Epoch [57/100], Train Loss: 0.6936, \n",
      "Epoch [58/100], Train Loss: 0.6932, \n",
      "Epoch [59/100], Train Loss: 0.6929, \n",
      "Epoch [60/100], Train Loss: 0.6940, \n",
      "Epoch [61/100], Train Loss: 0.6932, \n",
      "Epoch [62/100], Train Loss: 0.6932, \n",
      "Epoch [63/100], Train Loss: 0.6941, \n",
      "Epoch [64/100], Train Loss: 0.6930, \n",
      "Epoch [65/100], Train Loss: 0.6939, \n",
      "Epoch [66/100], Train Loss: 0.6933, \n",
      "Epoch [67/100], Train Loss: 0.6931, \n",
      "Epoch [68/100], Train Loss: 0.6934, \n",
      "Epoch [69/100], Train Loss: 0.6944, \n",
      "Epoch [70/100], Train Loss: 0.6926, \n",
      "Epoch [71/100], Train Loss: 0.6930, \n",
      "Epoch [72/100], Train Loss: 0.6929, \n",
      "Epoch [73/100], Train Loss: 0.6929, \n",
      "Epoch [74/100], Train Loss: 0.6931, \n",
      "Epoch [75/100], Train Loss: 0.6929, \n",
      "Epoch [76/100], Train Loss: 0.6938, \n",
      "Epoch [77/100], Train Loss: 0.6927, \n",
      "Epoch [78/100], Train Loss: 0.6932, \n",
      "Epoch [79/100], Train Loss: 0.6932, \n",
      "Epoch [80/100], Train Loss: 0.6931, \n",
      "Epoch [81/100], Train Loss: 0.6931, \n",
      "Epoch [82/100], Train Loss: 0.6938, \n",
      "Epoch [83/100], Train Loss: 0.6939, \n",
      "Epoch [84/100], Train Loss: 0.6935, \n",
      "Epoch [85/100], Train Loss: 0.6932, \n",
      "Epoch [86/100], Train Loss: 0.6934, \n",
      "Epoch [87/100], Train Loss: 0.6939, \n",
      "Epoch [88/100], Train Loss: 0.6933, \n",
      "Epoch [89/100], Train Loss: 0.6933, \n",
      "Epoch [90/100], Train Loss: 0.6935, \n",
      "Epoch [91/100], Train Loss: 0.6931, \n",
      "Epoch [92/100], Train Loss: 0.6933, \n",
      "Epoch [93/100], Train Loss: 0.6929, \n",
      "Epoch [94/100], Train Loss: 0.6934, \n",
      "Epoch [95/100], Train Loss: 0.6931, \n",
      "Epoch [96/100], Train Loss: 0.6934, \n",
      "Epoch [97/100], Train Loss: 0.6937, \n",
      "Epoch [98/100], Train Loss: 0.6939, \n",
      "Epoch [99/100], Train Loss: 0.6934, \n",
      "Epoch [100/100], Train Loss: 0.6927, \n",
      "training loss at last epoch: 0.693\n",
      "seed = 2\n",
      "20000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 317.8070, \n",
      "Epoch [2/100], Train Loss: 233.6057, \n",
      "Epoch [3/100], Train Loss: 270.7142, \n",
      "Epoch [4/100], Train Loss: 157.9336, \n",
      "Epoch [5/100], Train Loss: 144.5656, \n",
      "Epoch [6/100], Train Loss: 219.2650, \n",
      "Epoch [7/100], Train Loss: 147.0060, \n",
      "Epoch [8/100], Train Loss: 181.0399, \n",
      "Epoch [9/100], Train Loss: 123.2711, \n",
      "Epoch [10/100], Train Loss: 157.8864, \n",
      "Epoch [11/100], Train Loss: 205.1110, \n",
      "Epoch [12/100], Train Loss: 59.5390, \n",
      "Epoch [13/100], Train Loss: 86.9481, \n",
      "Epoch [14/100], Train Loss: 121.1569, \n",
      "Epoch [15/100], Train Loss: 61.8538, \n",
      "Epoch [16/100], Train Loss: 372.6833, \n",
      "Epoch [17/100], Train Loss: 602.8372, \n",
      "Epoch [18/100], Train Loss: 431.5062, \n",
      "Epoch [19/100], Train Loss: 301.0998, \n",
      "Epoch [20/100], Train Loss: 211.0461, \n",
      "Epoch [21/100], Train Loss: 136.0255, \n",
      "Epoch [22/100], Train Loss: 83.0687, \n",
      "Epoch [23/100], Train Loss: 45.8828, \n",
      "Epoch [24/100], Train Loss: 31.2437, \n",
      "Epoch [25/100], Train Loss: 22.5752, \n",
      "Epoch [26/100], Train Loss: 13.1666, \n",
      "Epoch [27/100], Train Loss: 19.6580, \n",
      "Epoch [28/100], Train Loss: 13.6164, \n",
      "Epoch [29/100], Train Loss: 12.9214, \n",
      "Epoch [30/100], Train Loss: 10.6420, \n",
      "Epoch [31/100], Train Loss: 9.9100, \n",
      "Epoch [32/100], Train Loss: 8.6517, \n",
      "Epoch [33/100], Train Loss: 7.8946, \n",
      "Epoch [34/100], Train Loss: 7.9582, \n",
      "Epoch [35/100], Train Loss: 6.8893, \n",
      "Epoch [36/100], Train Loss: 3.2930, \n",
      "Epoch [37/100], Train Loss: 3.5525, \n",
      "Epoch [38/100], Train Loss: 4.7413, \n",
      "Epoch [39/100], Train Loss: 5.6956, \n",
      "Epoch [40/100], Train Loss: 3.8899, \n",
      "Epoch [41/100], Train Loss: 5.4667, \n",
      "Epoch [42/100], Train Loss: 4.7711, \n",
      "Epoch [43/100], Train Loss: 3.2585, \n",
      "Epoch [44/100], Train Loss: 2.8701, \n",
      "Epoch [45/100], Train Loss: 4.9800, \n",
      "Epoch [46/100], Train Loss: 1.5849, \n",
      "Epoch [47/100], Train Loss: 2.6965, \n",
      "Epoch [48/100], Train Loss: 4.4897, \n",
      "Epoch [49/100], Train Loss: 1.9906, \n",
      "Epoch [50/100], Train Loss: 3.3673, \n",
      "Epoch [51/100], Train Loss: 1.8310, \n",
      "Epoch [52/100], Train Loss: 3.3541, \n",
      "Epoch [53/100], Train Loss: 3.5464, \n",
      "Epoch [54/100], Train Loss: 1.2352, \n",
      "Epoch [55/100], Train Loss: 3.8402, \n",
      "Epoch [56/100], Train Loss: 3.7048, \n",
      "Epoch [57/100], Train Loss: 2.6277, \n",
      "Epoch [58/100], Train Loss: 1.2723, \n",
      "Epoch [59/100], Train Loss: 3.8168, \n",
      "Epoch [60/100], Train Loss: 2.2475, \n",
      "Epoch [61/100], Train Loss: 2.1152, \n",
      "Epoch [62/100], Train Loss: 1.9948, \n",
      "Epoch [63/100], Train Loss: 2.2500, \n",
      "Epoch [64/100], Train Loss: 2.8031, \n",
      "Epoch [65/100], Train Loss: 2.8028, \n",
      "Epoch [66/100], Train Loss: 1.3610, \n",
      "Epoch [67/100], Train Loss: 2.1168, \n",
      "Epoch [68/100], Train Loss: 1.5932, \n",
      "Epoch [69/100], Train Loss: 2.2832, \n",
      "Epoch [70/100], Train Loss: 2.7714, \n",
      "Epoch [71/100], Train Loss: 1.6020, \n",
      "Epoch [72/100], Train Loss: 2.0978, \n",
      "Epoch [73/100], Train Loss: 2.0120, \n",
      "Epoch [74/100], Train Loss: 1.9753, \n",
      "Epoch [75/100], Train Loss: 2.7010, \n",
      "Epoch [76/100], Train Loss: 1.7173, \n",
      "Epoch [77/100], Train Loss: 2.3195, \n",
      "Epoch [78/100], Train Loss: 1.2614, \n",
      "Epoch [79/100], Train Loss: 2.1630, \n",
      "Epoch [80/100], Train Loss: 1.2916, \n",
      "Epoch [81/100], Train Loss: 1.6009, \n",
      "Epoch [82/100], Train Loss: 1.6673, \n",
      "Epoch [83/100], Train Loss: 1.2433, \n",
      "Epoch [84/100], Train Loss: 1.1264, \n",
      "Epoch [85/100], Train Loss: 1.6902, \n",
      "Epoch [86/100], Train Loss: 1.8775, \n",
      "Epoch [87/100], Train Loss: 1.4875, \n",
      "Epoch [88/100], Train Loss: 1.4906, \n",
      "Epoch [89/100], Train Loss: 1.1493, \n",
      "Epoch [90/100], Train Loss: 1.8279, \n",
      "Epoch [91/100], Train Loss: 2.0676, \n",
      "Epoch [92/100], Train Loss: 1.1734, \n",
      "Epoch [93/100], Train Loss: 1.3981, \n",
      "Epoch [94/100], Train Loss: 1.6698, \n",
      "Epoch [95/100], Train Loss: 1.9917, \n",
      "Epoch [96/100], Train Loss: 0.8451, \n",
      "Epoch [97/100], Train Loss: 1.7632, \n",
      "Epoch [98/100], Train Loss: 1.2279, \n",
      "Epoch [99/100], Train Loss: 1.2535, \n",
      "Epoch [100/100], Train Loss: 1.2416, \n",
      "training loss at last epoch: 1.242\n",
      "Epoch [1/100], Train Loss: 89.0873, \n",
      "Epoch [2/100], Train Loss: 0.8905, \n",
      "Epoch [3/100], Train Loss: 0.7120, \n",
      "Epoch [4/100], Train Loss: 0.7848, \n",
      "Epoch [5/100], Train Loss: 0.7413, \n",
      "Epoch [6/100], Train Loss: 0.7464, \n",
      "Epoch [7/100], Train Loss: 0.7366, \n",
      "Epoch [8/100], Train Loss: 0.7253, \n",
      "Epoch [9/100], Train Loss: 0.7171, \n",
      "Epoch [10/100], Train Loss: 0.7022, \n",
      "Epoch [11/100], Train Loss: 0.7022, \n",
      "Epoch [12/100], Train Loss: 0.7013, \n",
      "Epoch [13/100], Train Loss: 0.6947, \n",
      "Epoch [14/100], Train Loss: 0.6991, \n",
      "Epoch [15/100], Train Loss: 0.6954, \n",
      "Epoch [16/100], Train Loss: 0.6997, \n",
      "Epoch [17/100], Train Loss: 0.6970, \n",
      "Epoch [18/100], Train Loss: 0.6957, \n",
      "Epoch [19/100], Train Loss: 0.6956, \n",
      "Epoch [20/100], Train Loss: 0.6935, \n",
      "Epoch [21/100], Train Loss: 0.6967, \n",
      "Epoch [22/100], Train Loss: 0.6943, \n",
      "Epoch [23/100], Train Loss: 0.6940, \n",
      "Epoch [24/100], Train Loss: 0.6950, \n",
      "Epoch [25/100], Train Loss: 0.6933, \n",
      "Epoch [26/100], Train Loss: 0.6945, \n",
      "Epoch [27/100], Train Loss: 0.6937, \n",
      "Epoch [28/100], Train Loss: 0.6931, \n",
      "Epoch [29/100], Train Loss: 0.6927, \n",
      "Epoch [30/100], Train Loss: 0.6933, \n",
      "Epoch [31/100], Train Loss: 0.6942, \n",
      "Epoch [32/100], Train Loss: 0.6925, \n",
      "Epoch [33/100], Train Loss: 0.6929, \n",
      "Epoch [34/100], Train Loss: 0.6936, \n",
      "Epoch [35/100], Train Loss: 0.6931, \n",
      "Epoch [36/100], Train Loss: 0.6933, \n",
      "Epoch [37/100], Train Loss: 0.6937, \n",
      "Epoch [38/100], Train Loss: 0.6936, \n",
      "Epoch [39/100], Train Loss: 0.6936, \n",
      "Epoch [40/100], Train Loss: 0.6931, \n",
      "Epoch [41/100], Train Loss: 0.6932, \n",
      "Epoch [42/100], Train Loss: 0.6928, \n",
      "Epoch [43/100], Train Loss: 0.6929, \n",
      "Epoch [44/100], Train Loss: 0.6927, \n",
      "Epoch [45/100], Train Loss: 0.6931, \n",
      "Epoch [46/100], Train Loss: 0.6929, \n",
      "Epoch [47/100], Train Loss: 0.6933, \n",
      "Epoch [48/100], Train Loss: 0.6929, \n",
      "Epoch [49/100], Train Loss: 0.6936, \n",
      "Epoch [50/100], Train Loss: 0.6931, \n",
      "Epoch [51/100], Train Loss: 0.6938, \n",
      "Epoch [52/100], Train Loss: 0.6919, \n",
      "Epoch [53/100], Train Loss: 0.6929, \n",
      "Epoch [54/100], Train Loss: 0.6936, \n",
      "Epoch [55/100], Train Loss: 0.6926, \n",
      "Epoch [56/100], Train Loss: 0.6927, \n",
      "Epoch [57/100], Train Loss: 0.6926, \n",
      "Epoch [58/100], Train Loss: 0.6927, \n",
      "Epoch [59/100], Train Loss: 0.6938, \n",
      "Epoch [60/100], Train Loss: 0.6930, \n",
      "Epoch [61/100], Train Loss: 0.6941, \n",
      "Epoch [62/100], Train Loss: 0.6928, \n",
      "Epoch [63/100], Train Loss: 0.6931, \n",
      "Epoch [64/100], Train Loss: 0.6925, \n",
      "Epoch [65/100], Train Loss: 0.6929, \n",
      "Epoch [66/100], Train Loss: 0.6932, \n",
      "Epoch [67/100], Train Loss: 0.6938, \n",
      "Epoch [68/100], Train Loss: 0.6931, \n",
      "Epoch [69/100], Train Loss: 0.6935, \n",
      "Epoch [70/100], Train Loss: 0.6935, \n",
      "Epoch [71/100], Train Loss: 0.6930, \n",
      "Epoch [72/100], Train Loss: 0.6923, \n",
      "Epoch [73/100], Train Loss: 0.6931, \n",
      "Epoch [74/100], Train Loss: 0.6926, \n",
      "Epoch [75/100], Train Loss: 0.6936, \n",
      "Epoch [76/100], Train Loss: 0.6930, \n",
      "Epoch [77/100], Train Loss: 0.6931, \n",
      "Epoch [78/100], Train Loss: 0.6927, \n",
      "Epoch [79/100], Train Loss: 0.6927, \n",
      "Epoch [80/100], Train Loss: 0.6926, \n",
      "Epoch [81/100], Train Loss: 0.6930, \n",
      "Epoch [82/100], Train Loss: 0.6927, \n",
      "Epoch [83/100], Train Loss: 0.6926, \n",
      "Epoch [84/100], Train Loss: 0.6923, \n",
      "Epoch [85/100], Train Loss: 0.6928, \n",
      "Epoch [86/100], Train Loss: 0.6934, \n",
      "Epoch [87/100], Train Loss: 0.6921, \n",
      "Epoch [88/100], Train Loss: 0.6921, \n",
      "Epoch [89/100], Train Loss: 0.6928, \n",
      "Epoch [90/100], Train Loss: 0.6918, \n",
      "Epoch [91/100], Train Loss: 0.6921, \n",
      "Epoch [92/100], Train Loss: 0.6929, \n",
      "Epoch [93/100], Train Loss: 0.6931, \n",
      "Epoch [94/100], Train Loss: 0.6932, \n",
      "Epoch [95/100], Train Loss: 0.6930, \n",
      "Epoch [96/100], Train Loss: 0.6930, \n",
      "Epoch [97/100], Train Loss: 0.6924, \n",
      "Epoch [98/100], Train Loss: 0.6926, \n",
      "Epoch [99/100], Train Loss: 0.6920, \n",
      "Epoch [100/100], Train Loss: 0.6926, \n",
      "training loss at last epoch: 0.693\n",
      "time t = 550\n",
      "seed = 0\n",
      "22000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 103861.5126, \n",
      "Epoch [2/100], Train Loss: 240965.0720, \n",
      "Epoch [3/100], Train Loss: 195939.7659, \n",
      "Epoch [4/100], Train Loss: 154675.0447, \n",
      "Epoch [5/100], Train Loss: 116094.1534, \n",
      "Epoch [6/100], Train Loss: 80160.8087, \n",
      "Epoch [7/100], Train Loss: 46336.8558, \n",
      "Epoch [8/100], Train Loss: 45388.1625, \n",
      "Epoch [9/100], Train Loss: 248994.0337, \n",
      "Epoch [10/100], Train Loss: 210604.6205, \n",
      "Epoch [11/100], Train Loss: 175320.6572, \n",
      "Epoch [12/100], Train Loss: 143045.1124, \n",
      "Epoch [13/100], Train Loss: 112599.8298, \n",
      "Epoch [14/100], Train Loss: 85211.0767, \n",
      "Epoch [15/100], Train Loss: 59723.5722, \n",
      "Epoch [16/100], Train Loss: 35738.2396, \n",
      "Epoch [17/100], Train Loss: 44761.7917, \n",
      "Epoch [18/100], Train Loss: 126893.9202, \n",
      "Epoch [19/100], Train Loss: 102047.6444, \n",
      "Epoch [20/100], Train Loss: 78551.9768, \n",
      "Epoch [21/100], Train Loss: 57759.9688, \n",
      "Epoch [22/100], Train Loss: 37509.9972, \n",
      "Epoch [23/100], Train Loss: 17994.1390, \n",
      "Epoch [24/100], Train Loss: 16449.2770, \n",
      "Epoch [25/100], Train Loss: 174595.2652, \n",
      "Epoch [26/100], Train Loss: 151382.3528, \n",
      "Epoch [27/100], Train Loss: 128479.3994, \n",
      "Epoch [28/100], Train Loss: 109895.3347, \n",
      "Epoch [29/100], Train Loss: 91267.9726, \n",
      "Epoch [30/100], Train Loss: 75931.5816, \n",
      "Epoch [31/100], Train Loss: 60730.9148, \n",
      "Epoch [32/100], Train Loss: 46277.4365, \n",
      "Epoch [33/100], Train Loss: 33835.3738, \n",
      "Epoch [34/100], Train Loss: 21622.8359, \n",
      "Epoch [35/100], Train Loss: 10166.0803, \n",
      "Epoch [36/100], Train Loss: 37017.9735, \n",
      "Epoch [37/100], Train Loss: 25760.4923, \n",
      "Epoch [38/100], Train Loss: 14776.7662, \n",
      "Epoch [39/100], Train Loss: 30440.2821, \n",
      "Epoch [40/100], Train Loss: 67004.2448, \n",
      "Epoch [41/100], Train Loss: 55419.0214, \n",
      "Epoch [42/100], Train Loss: 44104.4416, \n",
      "Epoch [43/100], Train Loss: 34585.6789, \n",
      "Epoch [44/100], Train Loss: 25438.4834, \n",
      "Epoch [45/100], Train Loss: 16794.4053, \n",
      "Epoch [46/100], Train Loss: 8689.4864, \n",
      "Epoch [47/100], Train Loss: 17603.5023, \n",
      "Epoch [48/100], Train Loss: 24721.5304, \n",
      "Epoch [49/100], Train Loss: 16724.4496, \n",
      "Epoch [50/100], Train Loss: 9300.9128, \n",
      "Epoch [51/100], Train Loss: 2166.7253, \n",
      "Epoch [52/100], Train Loss: 8228.8409, \n",
      "Epoch [53/100], Train Loss: 70763.4290, \n",
      "Epoch [54/100], Train Loss: 61187.2600, \n",
      "Epoch [55/100], Train Loss: 52364.2437, \n",
      "Epoch [56/100], Train Loss: 44485.3310, \n",
      "Epoch [57/100], Train Loss: 38069.7325, \n",
      "Epoch [58/100], Train Loss: 31804.0661, \n",
      "Epoch [59/100], Train Loss: 25880.1095, \n",
      "Epoch [60/100], Train Loss: 20810.8961, \n",
      "Epoch [61/100], Train Loss: 15983.3800, \n",
      "Epoch [62/100], Train Loss: 11378.9730, \n",
      "Epoch [63/100], Train Loss: 7211.9963, \n",
      "Epoch [64/100], Train Loss: 3226.8267, \n",
      "Epoch [65/100], Train Loss: 7858.9896, \n",
      "Epoch [66/100], Train Loss: 3865.9221, \n",
      "Epoch [67/100], Train Loss: 10156.8595, \n",
      "Epoch [68/100], Train Loss: 15451.0794, \n",
      "Epoch [69/100], Train Loss: 11489.4297, \n",
      "Epoch [70/100], Train Loss: 7772.9315, \n",
      "Epoch [71/100], Train Loss: 4345.9013, \n",
      "Epoch [72/100], Train Loss: 1977.4126, \n",
      "Epoch [73/100], Train Loss: 2860.6901, \n",
      "Epoch [74/100], Train Loss: 2446.9935, \n",
      "Epoch [75/100], Train Loss: 2741.0104, \n",
      "Epoch [76/100], Train Loss: 5542.2222, \n",
      "Epoch [77/100], Train Loss: 2325.1044, \n",
      "Epoch [78/100], Train Loss: 4606.8539, \n",
      "Epoch [79/100], Train Loss: 1794.3889, \n",
      "Epoch [80/100], Train Loss: 24365.2516, \n",
      "Epoch [81/100], Train Loss: 20686.3057, \n",
      "Epoch [82/100], Train Loss: 17312.5571, \n",
      "Epoch [83/100], Train Loss: 14468.2982, \n",
      "Epoch [84/100], Train Loss: 11813.9342, \n",
      "Epoch [85/100], Train Loss: 9351.0578, \n",
      "Epoch [86/100], Train Loss: 7050.3101, \n",
      "Epoch [87/100], Train Loss: 4942.3364, \n",
      "Epoch [88/100], Train Loss: 2896.7026, \n",
      "Epoch [89/100], Train Loss: 1104.9714, \n",
      "Epoch [90/100], Train Loss: 4024.1183, \n",
      "Epoch [91/100], Train Loss: 1986.0333, \n",
      "Epoch [92/100], Train Loss: 1293.9316, \n",
      "Epoch [93/100], Train Loss: 7848.2813, \n",
      "Epoch [94/100], Train Loss: 5722.5494, \n",
      "Epoch [95/100], Train Loss: 4000.2155, \n",
      "Epoch [96/100], Train Loss: 2369.7921, \n",
      "Epoch [97/100], Train Loss: 937.9368, \n",
      "Epoch [98/100], Train Loss: 3123.5132, \n",
      "Epoch [99/100], Train Loss: 12525.6373, \n",
      "Epoch [100/100], Train Loss: 10421.5128, \n",
      "training loss at last epoch: 10421.513\n",
      "Epoch [1/100], Train Loss: 249.6678, \n",
      "Epoch [2/100], Train Loss: 15.2085, \n",
      "Epoch [3/100], Train Loss: 2.3358, \n",
      "Epoch [4/100], Train Loss: 0.9322, \n",
      "Epoch [5/100], Train Loss: 0.8347, \n",
      "Epoch [6/100], Train Loss: 0.8307, \n",
      "Epoch [7/100], Train Loss: 0.7433, \n",
      "Epoch [8/100], Train Loss: 0.7587, \n",
      "Epoch [9/100], Train Loss: 0.8013, \n",
      "Epoch [10/100], Train Loss: 0.7612, \n",
      "Epoch [11/100], Train Loss: 0.6945, \n",
      "Epoch [12/100], Train Loss: 0.7558, \n",
      "Epoch [13/100], Train Loss: 0.7418, \n",
      "Epoch [14/100], Train Loss: 0.7329, \n",
      "Epoch [15/100], Train Loss: 0.7246, \n",
      "Epoch [16/100], Train Loss: 0.7129, \n",
      "Epoch [17/100], Train Loss: 0.7056, \n",
      "Epoch [18/100], Train Loss: 0.7078, \n",
      "Epoch [19/100], Train Loss: 0.7115, \n",
      "Epoch [20/100], Train Loss: 0.7078, \n",
      "Epoch [21/100], Train Loss: 0.7034, \n",
      "Epoch [22/100], Train Loss: 0.7068, \n",
      "Epoch [23/100], Train Loss: 0.7074, \n",
      "Epoch [24/100], Train Loss: 0.7006, \n",
      "Epoch [25/100], Train Loss: 0.7014, \n",
      "Epoch [26/100], Train Loss: 0.6980, \n",
      "Epoch [27/100], Train Loss: 0.6999, \n",
      "Epoch [28/100], Train Loss: 0.6947, \n",
      "Epoch [29/100], Train Loss: 0.6999, \n",
      "Epoch [30/100], Train Loss: 0.6963, \n",
      "Epoch [31/100], Train Loss: 0.6975, \n",
      "Epoch [32/100], Train Loss: 0.6939, \n",
      "Epoch [33/100], Train Loss: 0.6966, \n",
      "Epoch [34/100], Train Loss: 0.6950, \n",
      "Epoch [35/100], Train Loss: 0.6934, \n",
      "Epoch [36/100], Train Loss: 0.6928, \n",
      "Epoch [37/100], Train Loss: 0.6936, \n",
      "Epoch [38/100], Train Loss: 0.6937, \n",
      "Epoch [39/100], Train Loss: 0.6936, \n",
      "Epoch [40/100], Train Loss: 0.6953, \n",
      "Epoch [41/100], Train Loss: 0.6944, \n",
      "Epoch [42/100], Train Loss: 0.6929, \n",
      "Epoch [43/100], Train Loss: 0.6931, \n",
      "Epoch [44/100], Train Loss: 0.6929, \n",
      "Epoch [45/100], Train Loss: 0.6930, \n",
      "Epoch [46/100], Train Loss: 0.6935, \n",
      "Epoch [47/100], Train Loss: 0.6932, \n",
      "Epoch [48/100], Train Loss: 0.6928, \n",
      "Epoch [49/100], Train Loss: 0.6926, \n",
      "Epoch [50/100], Train Loss: 0.6925, \n",
      "Epoch [51/100], Train Loss: 0.6936, \n",
      "Epoch [52/100], Train Loss: 0.6929, \n",
      "Epoch [53/100], Train Loss: 0.6929, \n",
      "Epoch [54/100], Train Loss: 0.6927, \n",
      "Epoch [55/100], Train Loss: 0.6930, \n",
      "Epoch [56/100], Train Loss: 0.6929, \n",
      "Epoch [57/100], Train Loss: 0.6930, \n",
      "Epoch [58/100], Train Loss: 0.6930, \n",
      "Epoch [59/100], Train Loss: 0.6926, \n",
      "Epoch [60/100], Train Loss: 0.6930, \n",
      "Epoch [61/100], Train Loss: 0.6929, \n",
      "Epoch [62/100], Train Loss: 0.6929, \n",
      "Epoch [63/100], Train Loss: 0.6928, \n",
      "Epoch [64/100], Train Loss: 0.6922, \n",
      "Epoch [65/100], Train Loss: 0.6936, \n",
      "Epoch [66/100], Train Loss: 0.6928, \n",
      "Epoch [67/100], Train Loss: 0.6928, \n",
      "Epoch [68/100], Train Loss: 0.6932, \n",
      "Epoch [69/100], Train Loss: 0.6927, \n",
      "Epoch [70/100], Train Loss: 0.6932, \n",
      "Epoch [71/100], Train Loss: 0.6932, \n",
      "Epoch [72/100], Train Loss: 0.6928, \n",
      "Epoch [73/100], Train Loss: 0.6933, \n",
      "Epoch [74/100], Train Loss: 0.6933, \n",
      "Epoch [75/100], Train Loss: 0.6930, \n",
      "Epoch [76/100], Train Loss: 0.6932, \n",
      "Epoch [77/100], Train Loss: 0.6929, \n",
      "Epoch [78/100], Train Loss: 0.6930, \n",
      "Epoch [79/100], Train Loss: 0.6927, \n",
      "Epoch [80/100], Train Loss: 0.6924, \n",
      "Epoch [81/100], Train Loss: 0.6931, \n",
      "Epoch [82/100], Train Loss: 0.6934, \n",
      "Epoch [83/100], Train Loss: 0.6921, \n",
      "Epoch [84/100], Train Loss: 0.6919, \n",
      "Epoch [85/100], Train Loss: 0.6921, \n",
      "Epoch [86/100], Train Loss: 0.6923, \n",
      "Epoch [87/100], Train Loss: 0.6919, \n",
      "Epoch [88/100], Train Loss: 0.6925, \n",
      "Epoch [89/100], Train Loss: 0.6931, \n",
      "Epoch [90/100], Train Loss: 0.6929, \n",
      "Epoch [91/100], Train Loss: 0.6919, \n",
      "Epoch [92/100], Train Loss: 0.6949, \n",
      "Epoch [93/100], Train Loss: 0.6930, \n",
      "Epoch [94/100], Train Loss: 0.6933, \n",
      "Epoch [95/100], Train Loss: 0.6944, \n",
      "Epoch [96/100], Train Loss: 0.6929, \n",
      "Epoch [97/100], Train Loss: 0.6938, \n",
      "Epoch [98/100], Train Loss: 0.6937, \n",
      "Epoch [99/100], Train Loss: 0.6936, \n",
      "Epoch [100/100], Train Loss: 0.6934, \n",
      "training loss at last epoch: 0.693\n",
      "seed = 1\n",
      "22000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 6157.3494, \n",
      "Epoch [2/100], Train Loss: 527.6456, \n",
      "Epoch [3/100], Train Loss: 308.0625, \n",
      "Epoch [4/100], Train Loss: 168.1218, \n",
      "Epoch [5/100], Train Loss: 263.9281, \n",
      "Epoch [6/100], Train Loss: 151.5692, \n",
      "Epoch [7/100], Train Loss: 252.8552, \n",
      "Epoch [8/100], Train Loss: 504.5210, \n",
      "Epoch [9/100], Train Loss: 834.0114, \n",
      "Epoch [10/100], Train Loss: 629.5086, \n",
      "Epoch [11/100], Train Loss: 442.0440, \n",
      "Epoch [12/100], Train Loss: 265.7907, \n",
      "Epoch [13/100], Train Loss: 166.1597, \n",
      "Epoch [14/100], Train Loss: 146.6708, \n",
      "Epoch [15/100], Train Loss: 324.5258, \n",
      "Epoch [16/100], Train Loss: 178.3578, \n",
      "Epoch [17/100], Train Loss: 83.4845, \n",
      "Epoch [18/100], Train Loss: 468.5448, \n",
      "Epoch [19/100], Train Loss: 315.0190, \n",
      "Epoch [20/100], Train Loss: 168.1460, \n",
      "Epoch [21/100], Train Loss: 493.7151, \n",
      "Epoch [22/100], Train Loss: 1067.4904, \n",
      "Epoch [23/100], Train Loss: 891.5758, \n",
      "Epoch [24/100], Train Loss: 740.4250, \n",
      "Epoch [25/100], Train Loss: 600.2515, \n",
      "Epoch [26/100], Train Loss: 471.0898, \n",
      "Epoch [27/100], Train Loss: 345.2186, \n",
      "Epoch [28/100], Train Loss: 235.9730, \n",
      "Epoch [29/100], Train Loss: 154.9730, \n",
      "Epoch [30/100], Train Loss: 118.3503, \n",
      "Epoch [31/100], Train Loss: 105.4432, \n",
      "Epoch [32/100], Train Loss: 144.7770, \n",
      "Epoch [33/100], Train Loss: 553.6409, \n",
      "Epoch [34/100], Train Loss: 447.8889, \n",
      "Epoch [35/100], Train Loss: 343.5455, \n",
      "Epoch [36/100], Train Loss: 251.2127, \n",
      "Epoch [37/100], Train Loss: 164.2095, \n",
      "Epoch [38/100], Train Loss: 100.6273, \n",
      "Epoch [39/100], Train Loss: 59.2469, \n",
      "Epoch [40/100], Train Loss: 689.7903, \n",
      "Epoch [41/100], Train Loss: 586.7135, \n",
      "Epoch [42/100], Train Loss: 493.1359, \n",
      "Epoch [43/100], Train Loss: 410.9950, \n",
      "Epoch [44/100], Train Loss: 332.0172, \n",
      "Epoch [45/100], Train Loss: 260.3870, \n",
      "Epoch [46/100], Train Loss: 191.1832, \n",
      "Epoch [47/100], Train Loss: 142.6185, \n",
      "Epoch [48/100], Train Loss: 106.8603, \n",
      "Epoch [49/100], Train Loss: 84.5141, \n",
      "Epoch [50/100], Train Loss: 76.6387, \n",
      "Epoch [51/100], Train Loss: 71.9463, \n",
      "Epoch [52/100], Train Loss: 73.0506, \n",
      "Epoch [53/100], Train Loss: 71.5086, \n",
      "Epoch [54/100], Train Loss: 51.1917, \n",
      "Epoch [55/100], Train Loss: 52.2999, \n",
      "Epoch [56/100], Train Loss: 77.8674, \n",
      "Epoch [57/100], Train Loss: 46.2899, \n",
      "Epoch [58/100], Train Loss: 55.5438, \n",
      "Epoch [59/100], Train Loss: 48.4973, \n",
      "Epoch [60/100], Train Loss: 54.2470, \n",
      "Epoch [61/100], Train Loss: 69.7889, \n",
      "Epoch [62/100], Train Loss: 29.2718, \n",
      "Epoch [63/100], Train Loss: 68.6474, \n",
      "Epoch [64/100], Train Loss: 37.9547, \n",
      "Epoch [65/100], Train Loss: 44.5069, \n",
      "Epoch [66/100], Train Loss: 43.8968, \n",
      "Epoch [67/100], Train Loss: 34.4299, \n",
      "Epoch [68/100], Train Loss: 42.3107, \n",
      "Epoch [69/100], Train Loss: 40.3429, \n",
      "Epoch [70/100], Train Loss: 40.3282, \n",
      "Epoch [71/100], Train Loss: 31.5136, \n",
      "Epoch [72/100], Train Loss: 39.8765, \n",
      "Epoch [73/100], Train Loss: 24.6844, \n",
      "Epoch [74/100], Train Loss: 46.3485, \n",
      "Epoch [75/100], Train Loss: 29.6872, \n",
      "Epoch [76/100], Train Loss: 48.1186, \n",
      "Epoch [77/100], Train Loss: 22.4368, \n",
      "Epoch [78/100], Train Loss: 55.6505, \n",
      "Epoch [79/100], Train Loss: 38.0411, \n",
      "Epoch [80/100], Train Loss: 26.6619, \n",
      "Epoch [81/100], Train Loss: 33.2110, \n",
      "Epoch [82/100], Train Loss: 28.5524, \n",
      "Epoch [83/100], Train Loss: 29.0200, \n",
      "Epoch [84/100], Train Loss: 20.4410, \n",
      "Epoch [85/100], Train Loss: 57.4264, \n",
      "Epoch [86/100], Train Loss: 31.2509, \n",
      "Epoch [87/100], Train Loss: 22.5417, \n",
      "Epoch [88/100], Train Loss: 23.4282, \n",
      "Epoch [89/100], Train Loss: 53.9749, \n",
      "Epoch [90/100], Train Loss: 33.6571, \n",
      "Epoch [91/100], Train Loss: 22.1199, \n",
      "Epoch [92/100], Train Loss: 29.4695, \n",
      "Epoch [93/100], Train Loss: 18.5692, \n",
      "Epoch [94/100], Train Loss: 31.3769, \n",
      "Epoch [95/100], Train Loss: 18.3191, \n",
      "Epoch [96/100], Train Loss: 27.2390, \n",
      "Epoch [97/100], Train Loss: 16.2399, \n",
      "Epoch [98/100], Train Loss: 23.1473, \n",
      "Epoch [99/100], Train Loss: 23.1355, \n",
      "Epoch [100/100], Train Loss: 54.8432, \n",
      "training loss at last epoch: 54.843\n",
      "Epoch [1/100], Train Loss: 47919.6588, \n",
      "Epoch [2/100], Train Loss: 271557.2568, \n",
      "Epoch [3/100], Train Loss: 142214.6774, \n",
      "Epoch [4/100], Train Loss: 56801.3098, \n",
      "Epoch [5/100], Train Loss: 0.6941, \n",
      "Epoch [6/100], Train Loss: 0.6936, \n",
      "Epoch [7/100], Train Loss: 0.6937, \n",
      "Epoch [8/100], Train Loss: 0.6927, \n",
      "Epoch [9/100], Train Loss: 0.6930, \n",
      "Epoch [10/100], Train Loss: 0.6938, \n",
      "Epoch [11/100], Train Loss: 0.6936, \n",
      "Epoch [12/100], Train Loss: 0.6935, \n",
      "Epoch [13/100], Train Loss: 0.6932, \n",
      "Epoch [14/100], Train Loss: 0.6935, \n",
      "Epoch [15/100], Train Loss: 0.6934, \n",
      "Epoch [16/100], Train Loss: 0.6931, \n",
      "Epoch [17/100], Train Loss: 0.6944, \n",
      "Epoch [18/100], Train Loss: 0.6935, \n",
      "Epoch [19/100], Train Loss: 0.6932, \n",
      "Epoch [20/100], Train Loss: 0.6943, \n",
      "Epoch [21/100], Train Loss: 0.6934, \n",
      "Epoch [22/100], Train Loss: 0.6938, \n",
      "Epoch [23/100], Train Loss: 0.6942, \n",
      "Epoch [24/100], Train Loss: 0.6933, \n",
      "Epoch [25/100], Train Loss: 0.6937, \n",
      "Epoch [26/100], Train Loss: 0.6936, \n",
      "Epoch [27/100], Train Loss: 0.6931, \n",
      "Epoch [28/100], Train Loss: 0.6931, \n",
      "Epoch [29/100], Train Loss: 0.6937, \n",
      "Epoch [30/100], Train Loss: 0.6933, \n",
      "Epoch [31/100], Train Loss: 0.6933, \n",
      "Epoch [32/100], Train Loss: 0.6935, \n",
      "Epoch [33/100], Train Loss: 0.6940, \n",
      "Epoch [34/100], Train Loss: 0.6932, \n",
      "Epoch [35/100], Train Loss: 0.6936, \n",
      "Epoch [36/100], Train Loss: 0.6938, \n",
      "Epoch [37/100], Train Loss: 0.6932, \n",
      "Epoch [38/100], Train Loss: 0.6941, \n",
      "Epoch [39/100], Train Loss: 0.6933, \n",
      "Epoch [40/100], Train Loss: 0.6937, \n",
      "Epoch [41/100], Train Loss: 0.6938, \n",
      "Epoch [42/100], Train Loss: 0.6935, \n",
      "Epoch [43/100], Train Loss: 0.6933, \n",
      "Epoch [44/100], Train Loss: 0.6935, \n",
      "Epoch [45/100], Train Loss: 0.6932, \n",
      "Epoch [46/100], Train Loss: 0.6930, \n",
      "Epoch [47/100], Train Loss: 0.6934, \n",
      "Epoch [48/100], Train Loss: 0.6932, \n",
      "Epoch [49/100], Train Loss: 0.6939, \n",
      "Epoch [50/100], Train Loss: 0.6931, \n",
      "Epoch [51/100], Train Loss: 0.6932, \n",
      "Epoch [52/100], Train Loss: 0.6930, \n",
      "Epoch [53/100], Train Loss: 0.6936, \n",
      "Epoch [54/100], Train Loss: 0.6936, \n",
      "Epoch [55/100], Train Loss: 0.6934, \n",
      "Epoch [56/100], Train Loss: 0.6929, \n",
      "Epoch [57/100], Train Loss: 0.6927, \n",
      "Epoch [58/100], Train Loss: 0.6927, \n",
      "Epoch [59/100], Train Loss: 0.6932, \n",
      "Epoch [60/100], Train Loss: 0.6939, \n",
      "Epoch [61/100], Train Loss: 0.6936, \n",
      "Epoch [62/100], Train Loss: 0.6937, \n",
      "Epoch [63/100], Train Loss: 0.6942, \n",
      "Epoch [64/100], Train Loss: 0.6928, \n",
      "Epoch [65/100], Train Loss: 0.6927, \n",
      "Epoch [66/100], Train Loss: 0.6928, \n",
      "Epoch [67/100], Train Loss: 0.6932, \n",
      "Epoch [68/100], Train Loss: 0.6940, \n",
      "Epoch [69/100], Train Loss: 0.6936, \n",
      "Epoch [70/100], Train Loss: 0.6940, \n",
      "Epoch [71/100], Train Loss: 0.6942, \n",
      "Epoch [72/100], Train Loss: 0.6929, \n",
      "Epoch [73/100], Train Loss: 0.6936, \n",
      "Epoch [74/100], Train Loss: 0.6931, \n",
      "Epoch [75/100], Train Loss: 0.6935, \n",
      "Epoch [76/100], Train Loss: 0.6929, \n",
      "Epoch [77/100], Train Loss: 0.6941, \n",
      "Epoch [78/100], Train Loss: 0.6937, \n",
      "Epoch [79/100], Train Loss: 0.6932, \n",
      "Epoch [80/100], Train Loss: 0.6934, \n",
      "Epoch [81/100], Train Loss: 0.6936, \n",
      "Epoch [82/100], Train Loss: 0.6933, \n",
      "Epoch [83/100], Train Loss: 0.6932, \n",
      "Epoch [84/100], Train Loss: 0.6935, \n",
      "Epoch [85/100], Train Loss: 0.6933, \n",
      "Epoch [86/100], Train Loss: 0.6934, \n",
      "Epoch [87/100], Train Loss: 0.6932, \n",
      "Epoch [88/100], Train Loss: 0.6941, \n",
      "Epoch [89/100], Train Loss: 0.6935, \n",
      "Epoch [90/100], Train Loss: 0.6941, \n",
      "Epoch [91/100], Train Loss: 0.6933, \n",
      "Epoch [92/100], Train Loss: 0.6938, \n",
      "Epoch [93/100], Train Loss: 0.6942, \n",
      "Epoch [94/100], Train Loss: 0.6939, \n",
      "Epoch [95/100], Train Loss: 0.6936, \n",
      "Epoch [96/100], Train Loss: 0.6932, \n",
      "Epoch [97/100], Train Loss: 0.6931, \n",
      "Epoch [98/100], Train Loss: 0.6936, \n",
      "Epoch [99/100], Train Loss: 0.6934, \n",
      "Epoch [100/100], Train Loss: 0.6939, \n",
      "training loss at last epoch: 0.694\n",
      "seed = 2\n",
      "22000\n",
      "(3, 80000, 1) (3, 80000)\n",
      "(3, 80000, 1) (3, 80000)\n",
      "Epoch [1/100], Train Loss: 786.4094, \n",
      "Epoch [2/100], Train Loss: 128.3149, \n",
      "Epoch [3/100], Train Loss: 588.0429, \n",
      "Epoch [4/100], Train Loss: 211.2034, \n",
      "Epoch [5/100], Train Loss: 149.0546, \n",
      "Epoch [6/100], Train Loss: 132.1505, \n",
      "Epoch [7/100], Train Loss: 387.8923, \n",
      "Epoch [8/100], Train Loss: 303.6390, \n",
      "Epoch [9/100], Train Loss: 242.3176, \n",
      "Epoch [10/100], Train Loss: 296.1703, \n",
      "Epoch [11/100], Train Loss: 122.1752, \n",
      "Epoch [12/100], Train Loss: 103.6264, \n",
      "Epoch [13/100], Train Loss: 51.6679, \n",
      "Epoch [14/100], Train Loss: 62.2559, \n",
      "Epoch [15/100], Train Loss: 262.1698, \n",
      "Epoch [16/100], Train Loss: 83.1971, \n",
      "Epoch [17/100], Train Loss: 51.0630, \n",
      "Epoch [18/100], Train Loss: 58.3003, \n",
      "Epoch [19/100], Train Loss: 78.6952, \n",
      "Epoch [20/100], Train Loss: 62.9871, \n",
      "Epoch [21/100], Train Loss: 103.3609, \n",
      "Epoch [22/100], Train Loss: 39.0424, \n",
      "Epoch [23/100], Train Loss: 146.9712, \n",
      "Epoch [24/100], Train Loss: 232.9402, \n",
      "Epoch [25/100], Train Loss: 105.1276, \n",
      "Epoch [26/100], Train Loss: 47.7366, \n",
      "Epoch [27/100], Train Loss: 44.2889, \n",
      "Epoch [28/100], Train Loss: 35.0830, \n",
      "Epoch [29/100], Train Loss: 37.1009, \n",
      "Epoch [30/100], Train Loss: 59.4520, \n",
      "Epoch [31/100], Train Loss: 37.9857, \n",
      "Epoch [32/100], Train Loss: 70.5225, \n",
      "Epoch [33/100], Train Loss: 30.1861, \n",
      "Epoch [34/100], Train Loss: 34.8550, \n",
      "Epoch [35/100], Train Loss: 19.4422, \n",
      "Epoch [36/100], Train Loss: 24.7012, \n",
      "Epoch [37/100], Train Loss: 15.4757, \n",
      "Epoch [38/100], Train Loss: 143.1140, \n",
      "Epoch [39/100], Train Loss: 68.4366, \n",
      "Epoch [40/100], Train Loss: 29.8281, \n",
      "Epoch [41/100], Train Loss: 19.1396, \n",
      "Epoch [42/100], Train Loss: 26.7198, \n",
      "Epoch [43/100], Train Loss: 19.6806, \n",
      "Epoch [44/100], Train Loss: 21.1200, \n",
      "Epoch [45/100], Train Loss: 21.9351, \n",
      "Epoch [46/100], Train Loss: 26.3927, \n",
      "Epoch [47/100], Train Loss: 23.7250, \n",
      "Epoch [48/100], Train Loss: 20.5602, \n",
      "Epoch [49/100], Train Loss: 15.0523, \n",
      "Epoch [50/100], Train Loss: 13.2638, \n",
      "Epoch [51/100], Train Loss: 15.4627, \n",
      "Epoch [52/100], Train Loss: 13.9266, \n",
      "Epoch [53/100], Train Loss: 12.5144, \n",
      "Epoch [54/100], Train Loss: 11.5960, \n",
      "Epoch [55/100], Train Loss: 15.1722, \n",
      "Epoch [56/100], Train Loss: 15.7804, \n",
      "Epoch [57/100], Train Loss: 13.0378, \n",
      "Epoch [58/100], Train Loss: 11.2606, \n",
      "Epoch [59/100], Train Loss: 8.6114, \n",
      "Epoch [60/100], Train Loss: 19.3479, \n",
      "Epoch [61/100], Train Loss: 58.4650, \n",
      "Epoch [62/100], Train Loss: 25.2746, \n",
      "Epoch [63/100], Train Loss: 12.4898, \n",
      "Epoch [64/100], Train Loss: 10.0243, \n",
      "Epoch [65/100], Train Loss: 11.2490, \n",
      "Epoch [66/100], Train Loss: 6.6235, \n",
      "Epoch [67/100], Train Loss: 9.1924, \n",
      "Epoch [68/100], Train Loss: 5.7094, \n",
      "Epoch [69/100], Train Loss: 6.4119, \n",
      "Epoch [70/100], Train Loss: 8.8968, \n",
      "Epoch [71/100], Train Loss: 8.5740, \n",
      "Epoch [72/100], Train Loss: 9.1077, \n",
      "Epoch [73/100], Train Loss: 6.8989, \n",
      "Epoch [74/100], Train Loss: 3.6240, \n",
      "Epoch [75/100], Train Loss: 5.9716, \n",
      "Epoch [76/100], Train Loss: 8.3874, \n",
      "Epoch [77/100], Train Loss: 3.7517, \n",
      "Epoch [78/100], Train Loss: 5.4218, \n",
      "Epoch [79/100], Train Loss: 3.9361, \n",
      "Epoch [80/100], Train Loss: 4.7201, \n",
      "Epoch [81/100], Train Loss: 5.2680, \n",
      "Epoch [82/100], Train Loss: 4.0072, \n",
      "Epoch [83/100], Train Loss: 3.0603, \n",
      "Epoch [84/100], Train Loss: 3.5936, \n",
      "Epoch [85/100], Train Loss: 5.2569, \n",
      "Epoch [86/100], Train Loss: 5.1458, \n",
      "Epoch [87/100], Train Loss: 2.8621, \n",
      "Epoch [88/100], Train Loss: 3.0146, \n",
      "Epoch [89/100], Train Loss: 4.4600, \n",
      "Epoch [90/100], Train Loss: 3.0056, \n",
      "Epoch [91/100], Train Loss: 1.9993, \n",
      "Epoch [92/100], Train Loss: 2.4382, \n",
      "Epoch [93/100], Train Loss: 4.6597, \n",
      "Epoch [94/100], Train Loss: 5.3488, \n",
      "Epoch [95/100], Train Loss: 3.1211, \n",
      "Epoch [96/100], Train Loss: 3.7542, \n",
      "Epoch [97/100], Train Loss: 2.1382, \n",
      "Epoch [98/100], Train Loss: 3.0176, \n",
      "Epoch [99/100], Train Loss: 2.2952, \n",
      "Epoch [100/100], Train Loss: 2.7554, \n",
      "training loss at last epoch: 2.755\n",
      "Epoch [1/100], Train Loss: 50.6542, \n",
      "Epoch [2/100], Train Loss: 0.7498, \n",
      "Epoch [3/100], Train Loss: 0.7114, \n",
      "Epoch [4/100], Train Loss: 0.7503, \n",
      "Epoch [5/100], Train Loss: 0.7188, \n",
      "Epoch [6/100], Train Loss: 0.7040, \n",
      "Epoch [7/100], Train Loss: 0.7175, \n",
      "Epoch [8/100], Train Loss: 0.7054, \n",
      "Epoch [9/100], Train Loss: 0.7029, \n",
      "Epoch [10/100], Train Loss: 0.6997, \n",
      "Epoch [11/100], Train Loss: 0.6997, \n",
      "Epoch [12/100], Train Loss: 0.6990, \n",
      "Epoch [13/100], Train Loss: 0.6961, \n",
      "Epoch [14/100], Train Loss: 0.6961, \n",
      "Epoch [15/100], Train Loss: 0.6965, \n",
      "Epoch [16/100], Train Loss: 0.6974, \n",
      "Epoch [17/100], Train Loss: 0.6946, \n",
      "Epoch [18/100], Train Loss: 0.6944, \n",
      "Epoch [19/100], Train Loss: 0.6932, \n",
      "Epoch [20/100], Train Loss: 0.6937, \n",
      "Epoch [21/100], Train Loss: 0.6942, \n",
      "Epoch [22/100], Train Loss: 0.6942, \n",
      "Epoch [23/100], Train Loss: 0.6942, \n",
      "Epoch [24/100], Train Loss: 0.6938, \n",
      "Epoch [25/100], Train Loss: 0.6935, \n",
      "Epoch [26/100], Train Loss: 0.6937, \n",
      "Epoch [27/100], Train Loss: 0.6938, \n",
      "Epoch [28/100], Train Loss: 0.6933, \n",
      "Epoch [29/100], Train Loss: 0.6938, \n",
      "Epoch [30/100], Train Loss: 0.6938, \n",
      "Epoch [31/100], Train Loss: 0.6933, \n",
      "Epoch [32/100], Train Loss: 0.6923, \n",
      "Epoch [33/100], Train Loss: 0.6927, \n",
      "Epoch [34/100], Train Loss: 0.6937, \n",
      "Epoch [35/100], Train Loss: 0.6930, \n",
      "Epoch [36/100], Train Loss: 0.6933, \n",
      "Epoch [37/100], Train Loss: 0.6932, \n",
      "Epoch [38/100], Train Loss: 0.6933, \n",
      "Epoch [39/100], Train Loss: 0.6939, \n",
      "Epoch [40/100], Train Loss: 0.6935, \n",
      "Epoch [41/100], Train Loss: 0.6931, \n",
      "Epoch [42/100], Train Loss: 0.6931, \n",
      "Epoch [43/100], Train Loss: 0.6936, \n",
      "Epoch [44/100], Train Loss: 0.6936, \n",
      "Epoch [45/100], Train Loss: 0.6931, \n",
      "Epoch [46/100], Train Loss: 0.6931, \n",
      "Epoch [47/100], Train Loss: 0.6931, \n",
      "Epoch [48/100], Train Loss: 0.6935, \n",
      "Epoch [49/100], Train Loss: 0.6930, \n",
      "Epoch [50/100], Train Loss: 0.6931, \n",
      "Epoch [51/100], Train Loss: 0.6931, \n",
      "Epoch [52/100], Train Loss: 0.6933, \n",
      "Epoch [53/100], Train Loss: 0.6937, \n",
      "Epoch [54/100], Train Loss: 0.6932, \n",
      "Epoch [55/100], Train Loss: 0.6930, \n",
      "Epoch [56/100], Train Loss: 0.6931, \n",
      "Epoch [57/100], Train Loss: 0.6931, \n",
      "Epoch [58/100], Train Loss: 0.6937, \n",
      "Epoch [59/100], Train Loss: 0.6937, \n",
      "Epoch [60/100], Train Loss: 0.6933, \n",
      "Epoch [61/100], Train Loss: 0.6930, \n",
      "Epoch [62/100], Train Loss: 0.6939, \n",
      "Epoch [63/100], Train Loss: 0.6934, \n",
      "Epoch [64/100], Train Loss: 0.6936, \n",
      "Epoch [65/100], Train Loss: 0.6931, \n",
      "Epoch [66/100], Train Loss: 0.6934, \n",
      "Epoch [67/100], Train Loss: 0.6933, \n",
      "Epoch [68/100], Train Loss: 0.6934, \n",
      "Epoch [69/100], Train Loss: 0.6931, \n",
      "Epoch [70/100], Train Loss: 0.6937, \n",
      "Epoch [71/100], Train Loss: 0.6940, \n",
      "Epoch [72/100], Train Loss: 0.6934, \n",
      "Epoch [73/100], Train Loss: 0.6932, \n",
      "Epoch [74/100], Train Loss: 0.6939, \n",
      "Epoch [75/100], Train Loss: 0.6936, \n",
      "Epoch [76/100], Train Loss: 0.6934, \n",
      "Epoch [77/100], Train Loss: 0.6930, \n",
      "Epoch [78/100], Train Loss: 0.6939, \n",
      "Epoch [79/100], Train Loss: 0.6930, \n",
      "Epoch [80/100], Train Loss: 0.6938, \n",
      "Epoch [81/100], Train Loss: 0.6929, \n",
      "Epoch [82/100], Train Loss: 0.6930, \n",
      "Epoch [83/100], Train Loss: 0.6936, \n",
      "Epoch [84/100], Train Loss: 0.6937, \n",
      "Epoch [85/100], Train Loss: 0.6926, \n",
      "Epoch [86/100], Train Loss: 0.6930, \n",
      "Epoch [87/100], Train Loss: 0.6942, \n",
      "Epoch [88/100], Train Loss: 0.6932, \n",
      "Epoch [89/100], Train Loss: 0.6932, \n",
      "Epoch [90/100], Train Loss: 0.6937, \n",
      "Epoch [91/100], Train Loss: 0.6934, \n",
      "Epoch [92/100], Train Loss: 0.6936, \n",
      "Epoch [93/100], Train Loss: 0.6934, \n",
      "Epoch [94/100], Train Loss: 0.6932, \n",
      "Epoch [95/100], Train Loss: 0.6926, \n",
      "Epoch [96/100], Train Loss: 0.6934, \n",
      "Epoch [97/100], Train Loss: 0.6931, \n",
      "Epoch [98/100], Train Loss: 0.6936, \n",
      "Epoch [99/100], Train Loss: 0.6931, \n",
      "Epoch [100/100], Train Loss: 0.6932, \n",
      "training loss at last epoch: 0.693\n"
     ]
    }
   ],
   "source": [
    "# configure and obtain the data generating process\n",
    "cfg = ProcessConfig(\n",
    "    seq_len=2000,\n",
    "    num_seeds=3,\n",
    "    num_sampel_per_task = 20\n",
    ")\n",
    "dp = DataGeneratingProcess(cfg)\n",
    "dp.generate_data()\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# methods being considered\n",
    "methods = [\"FTL\", \"Prospective\"]\n",
    "\n",
    "t_list = np.arange(50, 600, 50) # list of time steps \n",
    "instant_risk = {method: [] for method in methods} # store instant risk\n",
    "prospective_risk = {method: [] for method in methods} # store prospective risk\n",
    "\n",
    "# run experiment\n",
    "for t in t_list:\n",
    "    instant_loss = {method: [] for method in methods}\n",
    "    prospective_loss = {method: [] for method in methods}\n",
    "    print(f\"time t = {t}\")\n",
    "\n",
    "    for seed in range(cfg.num_seeds):\n",
    "        print(f\"seed = {seed}\")\n",
    "        acorn = seed * 1000 + 1998\n",
    "        set_seed(acorn)\n",
    "        t_idx = t*2*cfg.num_sampel_per_task\n",
    "        print(t_idx)\n",
    "        \n",
    "        trainloader, testloader, ttestloader = get_dataloaders(dp, t_idx, seed)\n",
    "        \n",
    "        for method in methods:\n",
    "            prospective = True if \"Prospective\" in method else False\n",
    "            model = MLP(prospective=prospective)\n",
    "            model.to(device)\n",
    "\n",
    "            optimizer = torch.optim.SGD(\n",
    "                model.parameters(), lr=0.1,\n",
    "                momentum=0.9, nesterov=True,\n",
    "                weight_decay=0.00001)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            trainer = Trainer(model, trainloader, testloader, ttestloader, criterion, optimizer, device)\n",
    "            trainer.train(num_epochs=100)\n",
    "            iloss, ploss = trainer.evaluate()\n",
    "\n",
    "            instant_loss[method].append(iloss)\n",
    "            prospective_loss[method].append(ploss)\n",
    "    \n",
    "    for method in methods:\n",
    "        instant_risk[method].append(np.mean(instant_loss[method]))\n",
    "        prospective_risk[method].append(np.mean(prospective_loss[method]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FTL': [np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5)],\n",
       " 'Prospective': [np.float32(0.50016665),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5),\n",
       "  np.float32(0.5)]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prospective_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "font = {'size':16}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 7), sharex=True)\n",
    "colors = ['#377eb8', '#e41a1c']\n",
    "for i, method in enumerate(methods):\n",
    "    ax = axes[0]\n",
    "    ax.plot(t_list, instant_risk[method], color=colors[i], lw=2, label=method)\n",
    "    ax.set_ylabel(\"Instantaneous Risk\")\n",
    "    ax.set_yticks([0, 0.5, 1])\n",
    "    ax.set_ylim([-0.05, 1])\n",
    "    ax.set_xlim([t_list[0], t_list[-1]])\n",
    "\n",
    "    ax = axes[1]\n",
    "    ax.plot(t_list, prospective_risk[method], color=colors[i], lw=2)\n",
    "    ax.set_ylabel(\"Prospective Risk\")\n",
    "    ax.set_yticks([0, 0.5, 1])\n",
    "    ax.set_ylim([-0.05, 1])\n",
    "    ax.set_xlim([t_list[0], t_list[-1]])\n",
    "\n",
    "    ax.set_xlabel(\"Time (t)\")\n",
    "\n",
    "# T = 25\n",
    "# for i in range(50, 600, T*2):\n",
    "#     task_start = i + T\n",
    "#     task_end = i + 2 * T\n",
    "#     for j in range(0, 2):\n",
    "#         ax = axes[j]\n",
    "#         ax.fill_betweenx([-0.1, 1.1], task_start, task_end, color='lightgray', alpha=0.3)\n",
    "#         ax.fill_betweenx([-0.1, 1.1], task_start, task_end, color='lightgray', alpha=0.3)\n",
    "        \n",
    "for j in range(0, 2):\n",
    "    ax = axes[j]\n",
    "    ax.plot(t_list, np.zeros_like(t_list), lw=2, ls='dashed', color='k', label=\"Bayes Risk\")\n",
    "\n",
    "ax = axes[0]\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 0.1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prolearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
